[
  {
    "objectID": "build/index.html",
    "href": "build/index.html",
    "title": "Week 2: Build mizer models",
    "section": "",
    "text": "You are welcome to use your own model system during this week, assuming you have the data. Alternatively, we will focus on a Celtic Sea. The Celtic Seas is characterized by a diversity of habitats, such as an extensive slope, canyons, ridges, and seamounts. The commercial fisheries in the Celtic Sea target a large number of stocks. We will only focus on 17 species and confine our modelling for ICES (International Council for Exploration of the Seas) areas 7b,c,e-k. For those participants who will focus on the Celtic Sea model, our goal at the end of the week is for each participant to develop their own model parameterisation. We will then collect these alternative parameter sets and use them as a model ensemble next week.\nThe material is split into 4 tutorials:\n\nFinding species parameters\nHere we will explore the main species parameters that should be provided by the user to start building a multi-species model. We will also look at assumptions and defaults that mizer uses to fill non-essential parameter values. Your task will be to collect essential parameters from FishBase or other sources.\nCreate your first model\nNow that you have species parameters you can build the first model. In this part we will focus on achieving the correct species abundances and growth rates.\nRefine your model: diet data\nIn this tutorial we will introduce the tuneParams() shiny gadget which makes it much easier to make changes to model parameters and observe their effects on the system. We will use it to explore how the diet emerges in the model from the interplay between predation preference and prey abundance and adjust the model parameters to reproduce observed diets.\nRefine your model: landings data\nFinally we will tune the model parameters to make the model predictions for the catches agree with landings data, in particular the size distribution of the landings. We will again be using the tuneParams() gadget.\n\nTo get your worksheet repository for this week, follow this link:\nhttps://classroom.github.com/a/gS1LgX3B"
  },
  {
    "objectID": "build/find-species-parameters.html",
    "href": "build/find-species-parameters.html",
    "title": "Finding species parameters",
    "section": "",
    "text": "In this tutorial we will discuss how to find the species-level information that goes into a mizer model. Perfect knowledge of the correct parameter values is impossible and judgement calls have to be made. We will invite you to make your own choices for the parameter values with which you will then build your first mizer model in the next tutorial.\nAs always we start with installing and loading the latest version of mizerExperimental and of the tidyverse.\nIn this tutorial we will also use functions from the rfishbase package which we will use to extract parameters from the huge FishBase data base. The following code will install it if necessary so that later we can use specific functions from the package."
  },
  {
    "objectID": "build/find-species-parameters.html#selecting-model-species",
    "href": "build/find-species-parameters.html#selecting-model-species",
    "title": "Finding species parameters",
    "section": "Selecting model species",
    "text": "Selecting model species\nHow do we decide which species to include in the model? There are many ways to approach this and no clearly set rules. Of course you want to include species that you are interested in, but then also perhaps some other important species in the ecosystem. You could select key ecosystem fish species that are commonly observed in scientific monitoring surveys, and which live and reproduce in the ecosystem (and ignore migratory species, which can be abundant briefly but don’t have a big role in the ecosystem overall).\nIf you only have information on a very small number of species, mizer has a powerful framework that allows you to explicitly model only your focus species and represent the rest of the ecosystem with ‘background’ species. The sizes and abundances of these ‘background’ species are assumed to follow the power law, so that the total community biomass approximately represents the Sheldon spectrum. This is only mentioned here for your information, as we will not go into these details during this week.\nOne good approach is to build on the efforts of others. There may already be a multi-species model in existence for your ecosystem and initially you could keep some of the choices made for that model. That is what we do in this tutorial. We want to build a model for the Celtic Sea. We build on a mizer model described in Spence et al. (2021). The model parameters are given in the supplementary material of that paper. James Martindale had the species parameters in a file and shared that with us. Let’s load that and print the list of parameter names.\n\nsp_spence <- readRDS(\"species_params_spence_et_al.rds\")\nnames(sp_spence)\n\n [1] \"species\" \"beta\"    \"sigma\"   \"F0\"      \"w_inf\"   \"w_mat\"   \"h\"      \n [8] \"ks\"      \"k_vb\"    \"Rmax\"   \n\n\nWe are currently interested in the choice of species to include:\n\nsp_spence$species\n\n [1] Herring        Sprat          Cod            Haddock        Whiting       \n [6] Blue whiting   Norway Pout    Poor Cod       European Hake  Monkfish      \n[11] Horse Mackerel Mackerel       Common Dab     Plaice         Megrim        \n[16] Sole           Boarfish      \n17 Levels: Blue whiting Boarfish Cod Common Dab European Hake ... Whiting\n\n\nWe see that Spence et.al. chose to model 17 fish species. This may not be the choice you would have made. For example they chose not to include any crustaceans. If Nephrops, lobsters or crabs play an important role in your fishery, you may want to add them. Feel free to add other species. But of course increasing the number of species increases the amount of work that you have to put into choosing species parameters.\nYou may wonder why we don’t simply stick with their model. Why do we want to build a model from scratch if one is already in existence? One answer is that we do not agree with all the choices made. For example the published model produces size spectra that are incompatible with observations. But even if you have no reason to doubt someone else’s model, you should still go through all the parameter choices yourself. In this spirit, we would also like to ask you to not follow all the choices we make in this tutorial but instead make choices following your own judgement.\nThe species parameters go into a data frame that must have one row for each species and should have one column named species which contains the name by which you like to refer to this species. These species names will be used in plot legends for example, so do not make them too long. We will just stick with the names chosen by Spence et.al. So let’s start to create our species parameter data frame by just selecting the species column from the data frame of Spence et.al.\n\nsp <- select(sp_spence, species)\n\nWe may later perhaps also choose to reuse some of the other parameters chosen by Spence et.al.\nNow that we have our first column in our species parameter data frame we should already start a habit that will serve us well in the long run: always comment on how we chose the parameter values. So we’ll put the following comment on the species column:\n\ncomment(sp$species) <- \"We follow the choice of species made by Spence et.al (2021) https://doi.org/10.1111/faf.12543\"\n\nThat way if years later we are wondering what made us choose to include these species, we can simply do\n\ncomment(sp$species)\n\n[1] \"We follow the choice of species made by Spence et.al (2021) https://doi.org/10.1111/faf.12543\"\n\n\nWhile common names are convenient for presentation, they are ambiguous. We can use rfishbase::common_to_sci() to look up all the latin names of all the species that might correspond to a common name. For example\n\nherring_latin <- common_to_sci(\"Herring\")\n\nJoining, by = c(\"Subfamily\", \"GenCode\", \"FamCode\")\nJoining, by = \"FamCode\"\nJoining, by = c(\"Order\", \"Ordnum\", \"Class\", \"ClassNum\")\nJoining, by = c(\"Class\", \"ClassNum\")\n\nherring_latin\n\n\n\n  \n\n\n\nAn easy way to find the latin name we want for our common species is to sort this table by SpecCode which will put the more common species towards the top.\n\narrange(herring_latin, SpecCode)\n\n\n\n  \n\n\n\nWe see that the non-uniqueness actually goes both ways. There are also several common names for the same scientific species.\nAfter a little work we arrive at the correct scientific names of all our species and for later convenience we put them into our species data frame as well even though mizer will ignore them.\n\nsp$latin_name <- c(\"Clupea harengus\", # Herring\n                   \"Sprattus sprattus\", # Sprat\n                   \"Gadus morhua\", # Cod\n                   \"Melanogrammus aeglefinus\", # Haddock\n                   \"Merlangius merlangus\", # Whiting\n                   \"Micromesistius poutassou\", # Blue whiting\n                   \"Trisopterus esmarkii\", # Norway Pout\n                   \"Trisopterus minutus\", # Poor Cod\n                   \"Merluccius merluccius\", # European Hake\n                   \"Lophius piscatorius\", # Monkfish\n                   \"Trachurus trachurus\", # Horse Mackerel\n                   \"Scomber scombrus\", # Mackerel\n                   \"Limanda limanda\", # Common Dab\n                   \"Pleuronectes platessa\", # Plaice\n                   \"Lepidorhombus whiffiagonis\", # Megrim\n                   \"Solea solea\", # Sole\n                   \"Capros aper\") # Boarfish"
  },
  {
    "objectID": "build/find-species-parameters.html#summary-of-species-parameters",
    "href": "build/find-species-parameters.html#summary-of-species-parameters",
    "title": "Finding species parameters",
    "section": "Summary of species parameters",
    "text": "Summary of species parameters\nThe following picture gives a summary of the most important species parameters. The colour of the labels indicates whether a parameter, needs to be provided (red), should be provided if possible (blue), or can be left at mizer’s default values (black).\n\nAt this point it might be useful to go back and re-watch the second half of Ken Andersen’s introductory lecture which explains species parameters used in mizer. It is great how mizer can start building a model with only very few species parameters! For most other parameters, if values are not supplied by the user, mizer will fill them with default values using size-based theory or species averages.\nIf you don’t like defaults you can change them all. You can find the complete list of species parameters used in mizer in the help page of species_params(). Advanced users can also overrule the way mizer uses allometric scaling relations. You can read about all the details in the help page for setParams()."
  },
  {
    "objectID": "build/find-species-parameters.html#parameters-you-should-provide",
    "href": "build/find-species-parameters.html#parameters-you-should-provide",
    "title": "Finding species parameters",
    "section": "Parameters you should provide",
    "text": "Parameters you should provide\nAsymptotic size\nThe asymptotic size w_inf is the size (in grams) at which all individuals of the species invest 100% of their energy income into reproduction and hence all growth stops. Due to variation between individuals, some individuals may stop growing earlier. So the w_inf parameter in mizer is not the asymptotic size of an average individual but the maximum asymptotic size.\nThe best way to estimate this parameter is probably to look at what the largest fish is that has been caught in your study area. You may of course be fishing so hard that none of the fish grow to their asymptotic size and then the size of the largest caught fish would be an underestimate of the asymptotic size. But our estimate does not have to be perfect.\nWe have a data frame with observations of sizes of caught fish and can look through it for the largest sized fish of each species. TODO: give origin of the data.\n\ncatch <- read.csv(\"catch.csv\")\n\nmax_size <- catch |>\n    group_by(species) |>\n    summarise(l_max = max(length))\nmax_size\n\n\n\n  \n\n\n\nWe see that we only had data for 12 of our 17 species. The species for which we still don’t have an estimate for the asymptotic size are\n\nmissing <- !(sp$species %in% max_size$species)\nsp$species[missing]\n\n[1] Norway Pout Poor Cod    Mackerel    Megrim      Boarfish   \n17 Levels: Blue whiting Boarfish Cod Common Dab European Hake ... Whiting\n\n\nFor these we can use the maximum length recorded on FishBase in the “species” table.\n\nmax_size_fishbase <- rfishbase::species(sp$latin_name[missing]) |>\n    select(latin_name = Species, l_max = Length)\n\nJoining, by = c(\"Subfamily\", \"GenCode\", \"FamCode\")\nJoining, by = \"FamCode\"\nJoining, by = c(\"Order\", \"Ordnum\", \"Class\", \"ClassNum\")\nJoining, by = c(\"Class\", \"ClassNum\")\n\nmax_size_fishbase\n\n\n\n  \n\n\n\nTo combine these two tables we first need them to have a common column. So we add a species column to max_size_fishbase . Then we stack the two tables with bind_rows() and keep only the species and l_max columns\n\nmax_size_fishbase <- max_size_fishbase |>\n    left_join(select(sp, species, latin_name),\n              by = \"latin_name\")\nmax_size <- bind_rows(max_size, max_size_fishbase) |>\n    select(species, l_max)\nmax_size\n\n\n\n  \n\n\n\nThis table gives us the largest length for each species but mizer likes to use weight instead of length. To convert from length to weight we use the allometric length-weight relationship which says that the length l in cm and the weight w in grams of an average individual are related as:\nw = a \\cdot l^b\nFor many species the length-weight conversion coefficients a and b can be found on FishBase in the “estimates” table.\n\nlength_weight <- estimate(sp$latin_name, fields = c(\"Species\", \"a\", \"b\"))\n\nJoining, by = c(\"Subfamily\", \"GenCode\", \"FamCode\")\nJoining, by = \"FamCode\"\nJoining, by = c(\"Order\", \"Ordnum\", \"Class\", \"ClassNum\")\nJoining, by = c(\"Class\", \"ClassNum\")\n\nlength_weight\n\n\n\n  \n\n\n\nWe can now add all this information to our species parameter data frame and use it to calculate the column we actually need, namely w_inf.\n\nsp <- sp |>\n    left_join(length_weight, by = c(\"latin_name\" = \"Species\")) |>\n    left_join(max_size) |>\n    mutate(w_inf = a * l_max ^ b)\n\nJoining, by = \"species\"\n\nsp\n\n\n\n  \n\n\n\nEven though mizer will never use the l_max column, it does not hurt to keep it around.\nNow it is time again to add comments to remind us of the origin of our parameters:\n\ncomment(sp$a) <- \"Taken from the `a` column in the 'estimates' table on FishBase.\"\ncomment(sp$a) <- \"Taken from the `b` column in the 'estimates' table on FishBase.\"\ncomment(sp$l_max) <- \"See https://mizer.course.nov22.sizespectrum.org/build/find-species-parameters.html#asymptotic-size \"\n# Due to a bug in the released version of mizer, we should not comment on `w_inf`.\n# This will be fixed in the next release.\n# comment(sp$w_inf) <- \"Calculated from `l_max` using weight-length parameters `a` and `b`.\"\n\nGrowth parameters\nMizer needs some information about how fast a species grows. This is determined by the maximum intake rate and the feeding level. Mizer chooses a sensible default for the feeding level and you only need to give the coefficient h of the maximum intake rate. As Ken Andersen explains in his video at around minute 22:00, h is a nicer parameter for specifying growth than for example the von Bertalanffy K parameter. A species with an h larger than 22 is a fast-growing species, a species with h smaller than 22 is a slow-growing species.\nThe problem is that the values for h are not given on FishBase and you may thus struggle to find the appropriate value. I therefore propose that you specify instead both the size and the age at maturity. Mizer can then determine for you the value for h that allows the species to reach its maturity size at its maturity age.\nWe can get estimates of the maturity size and the maturity age from the “maturity” table on FishBase:\n\nmaturity_tbl <- rfishbase::maturity(sp$latin_name)\n\nJoining, by = c(\"Subfamily\", \"GenCode\", \"FamCode\")\nJoining, by = \"FamCode\"\nJoining, by = c(\"Order\", \"Ordnum\", \"Class\", \"ClassNum\")\nJoining, by = c(\"Class\", \"ClassNum\")\n\nmaturity_tbl\n\n\n\n  \n\n\n\nYou can see that the table has many entries for each species with estimates from various locations and times and it is not clear how to combine all these estimates into a good estimate for our particular area. I am sure there will be a lot of debate about this at the course meetings.\nRather than with working with the above table inside R it might be a good idea to explore it on the FishBase website. For example here is the maturity page for Cod.\nHere we will do something rather simple: we’ll just take the median values over all the observations where both the length at maturity Lm and the age at maturity tm are given:\n\nmedian_maturity <- maturity_tbl |>\n    group_by(Species) |>\n    filter(!is.na(tm), !is.na(Lm)) |>\n    summarise(age_mat = median(tm),\n              l_mat = median(Lm))\nmedian_maturity\n\n\n\n  \n\n\n\nWe add this information to our species parameter data frame and also add a w_mat column.\n\nsp <- sp |>\n    left_join(median_maturity, by = c(\"latin_name\" = \"Species\")) |>\n    mutate(w_mat = a * l_mat ^ b)\n\ncomment(sp$l_mat) <- \"Median of `Lm` over all observations on the 'maturity' table on FishBase that had both `Lm` and `tm`.\"\ncomment(sp$age_mat) <- \"Median of `tm` over all observations on the 'maturity' table on FishBase that had both `Lm` and `tm`.\"\ncomment(sp$w_mat) <- \"Calculated from `l_mat` using weight-length parameters `a` and `b`.\"\n\nIn the current version of mizer we still need to add the resulting h column to the species parameter data frame ourselves. In the next version the following step will not be necessary:\n\nsp$h <- get_h_default(sp)\ncomment(sp$h) <- \"Calculated from `age_mat` and `w_mat` using `get_h_default()`.\"\n\nPredation kernel\nWe discussed the importance of the predation kernel last week. When thinking about the predation kernel it is important to realise that it expresses the degree to which a predator prefers to eat prey of a particular size. It does not express the size-distribution of the predator’s diet. That is obtained as the product of the size preference and the size-dependent abundance of prey. The predator may prefer to eat larger prey, but it will nevertheless end up eating more smaller prey because smaller prey are so much more abundant than larger prey.\nBy default the predation kernel looks like a bell curve on the log w axis and we will keep this default for now. The most important parameter describing the bell curve is beta which gives the preferred predator/prey mass ratio. The default value for beta in mizer is beta = 30, which means that a predator has the highest preference for prey that weighs 30 times less than itself. However, higher beta values are appropriate for fish that feed on plankton or benthic invertebrates. The other parameter sigma describes the width of the bell curve on the logarithmic w axis.\nFor the Celtic Sea model we’ll initially just use the beta and sigma values that were used by Spence et.al.\n\nsp <- left_join(sp, select(sp_spence, species, beta, sigma))\n\nJoining, by = \"species\"\n\ncomment(sp$beta) <- comment(sp$sigma) <- \"Taken from Spence et.al (2021) https://doi.org/10.1111/faf.12543\"\n\nWe will revisit our preliminary choices in a later tutorial when we can visualise what the resulting diets will look like.\nAbundances\nTo calibrate the rate of reproduction (the rate at which eggs are entering the first size class in each species) in the steady state, mizer needs some information about species abundances or biomasses in the steady state. Of course the steady state is never observed in practice. However, it is reasonable to view the real world system as varying around the steady state so that averaging real-world observations over a number of years gives an estimate of the steady state.\nObserved biomasses could be derived from scientific surveys, underwater surveys or other observations or knowledge about relative biomasses of species. In well studied systems you might have biomass estimates from stock assessments. These type of data are often used to calibrate mizer models, although we need to be aware of the fact that stock assessment estimates are also model estimates and come with their own assumptions (e.g. they are single species estimates).\nIf you do not know the biomass of a species, all is not lost. You can then assume that the abundance of that species is such that it combines correctly with the the other species to create a community spectrum that follows the Sheldon power law. For now you would just put NA into the corresponding entry in the biomass_observed column.\nFor our Celtic Sea model we will use the ICES stock assessment reports by averaging the spawning stock biomass over a 10-year period (2012 - 2021). We decided to convert these biomasses to grams per square metre, which is the same as tonnes per square kilometre. Mizer is agnostic about the choice of area over which you want to measure biomasses. You just need to be consistent (see section Units in mizer in the mizer documentation).\nTODO: We will post code to extract these average spawning stock biomasses from the ICES database shortly. For now we just load the results from a file. The biomass estimates go into a biomass_observed column in the species parameter data frame.\n\nsp$biomass_observed <- readRDS(\"celtic_sea_ssb.rds\")\ncomment(sp$biomass_observed) <- \"Average of spawning stock biomass over the years 2012--2021 taken from ICES stock assessment reports.\"\n\nUsually your biomass estimate will only include individuals above a certain size, for example because the smaller individuals are not retained by our fishing gear. This cutoff size in grams you specify in the biomass_cutoff parameter. Because we are using an estimate of the spawning stock biomass, which includes individuals above the maturity size, we set biomass_cutoff to w_mat.\n\nsp$biomass_cutoff <- sp$w_mat\ncomment(sp$biomass_cutoff) <- \"Set to `w_mat` because `biomass_observed` represents spawning stock biomass.\""
  },
  {
    "objectID": "build/find-species-parameters.html#exercise",
    "href": "build/find-species-parameters.html#exercise",
    "title": "Finding species parameters",
    "section": "Exercise",
    "text": "Exercise\nThis mizer school gives us a chance to explore how sensitive the mizer model predictions will be to different choices of model parameters. If every participant tries to make their choices as different from ours as they can while being able to argue that their choice is at least as justifiable as ours then we are going to end up with a wide range of models all describing the same situation. Next week then we can collect all these models into a model ensemble.\nSo perhaps you want to pick different length-weight relationship parameters from fishbase or perhaps you have your own. Perhaps instead of maximum length you want to pick maximum weight from FishBase. Perhaps instead of taking the median over all observations of maturity size and maturity age on FishBase you first want to throw out some dubious ones. Or perhaps use a mean rather than a median. Or perhaps you want to directly pick values from studies particularly relevant to the Celtic Sea. Perhaps you know which values were used in the stock assessments for a species and can use those. Use your expertise and your intuition. Please comment your choices with explanations in this worksheet and/or comments on the columns of the species parameter data frame.\nDon’t worry too much about the predation kernel parameters because we will return to those in the fourth tutorial this week where we will look at the predator diets.\nWhen you are happy with the species parameters, save them with\n\nsaveRDS(sp, \"celticx_species_params.rds\")\n\nAlso save this worksheet and commit both to your worksheet repository and push to GitHub."
  },
  {
    "objectID": "build/find-species-parameters.html#default-parameters",
    "href": "build/find-species-parameters.html#default-parameters",
    "title": "Finding species parameters",
    "section": "Default parameters",
    "text": "Default parameters\nThere are many other parameters that are used to describe species properties, but which we have not provided in our species parameter data frame because mizer has default ways to calculate them based on the size theory expectations. You can read about the theory in various publications or in the excellent Ken H Andersen book “Fish Ecology, Evolution, and Exploitation” (2019). So you don’t need to provide them, but you do need to understand the defaults and think whether you are happy with them. Mizer help pages provide a good summary of species parameters and links to functions that use these parameters.\n\nThere are four important allometric exponents used by mizer:\n\n\nThe maximum intake rate has a scaling exponent n. Default is 2/3.\nThe metabolic rate has a scaling exponent p. Default is 0.7.\nThe search volume has a scaling exponent q. Default is lambda - 2 + n.\n\nThe investment into reproduction by mature individuals as a scaling exponent m. Default is 1.\nThere is a lot of debate about the correct values for these exponents. Some schools of thought argue that energy intake should scale with individual’s surface area (exponent of 2/3) whereas energy expenditure should scale with body volume (exponent of 1). Others suggest that food intake and metabolism exponents should both scale with 3/4. There are no clear rules and these exponents in reality are likely to vary across species.\n\n\n\nThe species search volume is set from the search rate constant gamma and its body size scaling exponent q. If no value is provided, gamma is set so that when prey abundance is described by the power law with the exponent lambda, the search volume will lead to a juvenile feeding level of f0 = 0.6.\nThe species metabolic rate is set from the constants ks and body size scaling exponent p. If no value is provided the coefficient ks is set so that at maturation size metabolic expenditure requires a critical feeding level of fc = 0.2. Maintenance expenditure can also include activity related energetic costs, using species activity coefficient k which scales linearly with body size (exponent of 1). By default this value is set to 0 and most mizer models do not include it.\nThe external mortality rate (also called background or baseline mortality) is by default set to a size-independent constant z0. If no values are provided mizer assumes that species with small maximum body sizes have much higher baseline mortality rate. For example, a species with w_inf = 35 g will have z0 = 0.18, a species with w_inf = 150g will have z0 = 0.11 and a species with w_inf = 14kg will have z0 = 0.025.\nWe already discussed the parameters involved in setting the investment into reproduction last week. The reproduction investment parameter m determines the scaling of the investment into reproduction for mature individuals. By default m = 1 which means that after maturation the rate at which individual fish invests energy into reproduction scales linearly with size (if you want more information, you can find it here). This default can be changed to another value if different scaling is preferred (e.g. in case you might want to explore hyper-allometric reproduction investment options). The steepness of population level energy allocation to reproduction is determined by w_mat25, the size at which 25% of individuals are mature.\nThe species minimum body size in the model w_min is by default set to 0.001 in grams.\nWe discussed the parameters R_max and erepro last week in the section on How reproduction is modelled.\nYou can also modify availability of the resource to each of your species, as we have learned during week 1. This is set by the parameter interaction_resource and this value is set to 1 by default.\nSpecies food assimilation efficiency alpha. If no value is provided mizer assumes 0.6.\n\nIf you want to change the default values for any of these parameters for any of the species, you just need to add a corresponding column to your species parameter data frame. You can put NA into those columns for the species where you want mizer to keep the default."
  },
  {
    "objectID": "build/find-species-parameters.html#species-interaction-matrix",
    "href": "build/find-species-parameters.html#species-interaction-matrix",
    "title": "Finding species parameters",
    "section": "Species interaction matrix",
    "text": "Species interaction matrix\nBy default, mizer assumes that all species can interact with each other equally and that predation is determined solely by size. To change this assumption we need to provide a species interaction matrix. This matrix can include three different aspects (or a combination of all of them):\n\n\nSpatial and temporal overlap of species in a large ecosystem. This way the interaction matrix is set based on species co-occurrences in various fisheries surveys or observations. In other words we observe how often a pair of species is found in same surveys. This is how species interactions are set up in the model by Spence et.al.(2021) and we will use their interaction matrix for our model:\n\n\nceltic_interaction <-  read.csv(\"celtic_interaction.csv\")\nceltic_interaction\n\n\n\n  \n\n\n\nWe use rownames = 1 to let read.csv know that the first column in the spreadsheet in “celtic_interaction.csv”, which contains the predator names, should be used as the names of the rows of the interaction matrix.\n\nSpecies diet preferences or trophic groups. Sometimes we know that certain species do not eat other species. For example, some species are strictly bentivorous or herbivorous and they never eat any other fish, not even their larvae. In other cases we might have good evidence for specific diet preferences, although ideally such evidence should come from food selection experiments and these are very rare and maybe too specific to certain conditions. It is important to know that diet contents do not necessarily reflect preferences, but realised feeding. A species might prefer to eat bananas, but if nothing else is available it will eat other fish. The species interaction matrix, if reflecting diet preferences, should reflect preferred diets, not realised diets.\nSpecies predator avoidance behaviour or vulnerability. Some species may be less available to other species because they are good at hiding, have spikes, or live in large schools which reduces their vulnerability to predation compared to solitary species. This could also be included in the species interaction matrix, but in the prey column.\n\nIf you do not have any information about such effects that modify species interactions then you should stay with the default interaction matrix which has all entries equal to 1."
  },
  {
    "objectID": "build/find-species-parameters.html#gear-parameters",
    "href": "build/find-species-parameters.html#gear-parameters",
    "title": "Finding species parameters",
    "section": "Gear parameters",
    "text": "Gear parameters\nBecause most ecosystems are fished and we are calibrating to biomasses observed under some fishing level, we usually also need to include information on fishing intensity and fishing gear.\nIn mizer you can implement an arbitrary number of different gears, each with its own fishing effort, fishing different species with different selectivity and catchability. Gear selectivity curves can have different shapes (logistic, knife-edge and others). You can read more about this here.\nYou provide the information about the gears in a data frame similar to the species parameter data frame. However the gear parameter data frame has one row for each gear-species combination. The data frame needs to have a column gear for the name of the gear and a column species for the name of the species. There are then further columns holding the information about how that gear selects that species. For details see the help page of gear_params().\nFor our initial model we have set up a simple gear parameter data frame describing only a single gear that we call “Commercial”. It targets all species in our model. The choice of parameters is again inspired by the paper by [Spence et al.(2021)](https://onlinelibrary.wiley.com/doi/10.1111/faf.12543)\n\nceltic_gear_params <- read.csv(\"celtic_gear_params.csv\")\nceltic_gear_params\n\n\n\n  \n\n\n\nWe model the size selectivity of the gear by a sigmoidal curve that is specified by giving the length l50 in cm at which 50% of the individuals are selected by the gear and the length l25 in cm at which 25% of the individuals are selected by the gear. For l50 we choose the maturity size l_mat and we set l25 to 95% of that to get a very steep selectivity curve.\nThe catchability column specifies how vulnerable the species are to commercial fishing. The fishing mortality rate at size for each gear is the product of the size-dependent selectivity, the catchability and the fishing effort. We will use the above gear with a fishing effort of 1, which means that the fishing mortality for the fully selected individuals will be equal to the catchability."
  },
  {
    "objectID": "build/find-species-parameters.html#summary",
    "href": "build/find-species-parameters.html#summary",
    "title": "Finding species parameters",
    "section": "Summary",
    "text": "Summary\n1) The species parameters are specified in a data frame with one row for each species and one column for each species parameter.\n2) Only a species name and the maximum size w_inf of each species is strictly required. But for a realistic model you should try to also provide estimates of the maturity size w_mat, the maturity age age_mat, the preferred predator prey mass ratio beta and the observed biomasses biomass_observed.\n3) We briefly explained how mizer chooses defaults for many other parameters, often using allometric scaling assumptions.\n4) If predation is determined not solely by size but also by species identity, we need to specify this in the interaction matrix.\n5) Fishing can be set up with multiple gears, each possibly targeting multiple species. The parameters for these fishing gears are specified in a data frame with one row for each gear-species pair and one column for each parameter."
  },
  {
    "objectID": "build/refine-landings.html",
    "href": "build/refine-landings.html",
    "title": "Refine model: Landings",
    "section": "",
    "text": "We will now continue to refine our model by matching it to observed landings.\nAs always, we start by updating and loading packages.\nWe load the model we created in the previous tutorial."
  },
  {
    "objectID": "build/refine-landings.html#landings-data",
    "href": "build/refine-landings.html#landings-data",
    "title": "Refine model: Landings",
    "section": "Landings data",
    "text": "Landings data\nWe will load data on the size distribution of catches. Such data is often collected in data-poor fisheries, so it will be useful to see how we can use such data for model calibration. This specific dataset was sourced from Scientific, Technical and Economic Committee for Fisheries (STECF) and was restricted to England and Wales.\n\ncatch_lengths <- read.csv(\"catch.csv\")\nhead(catch_lengths)\n\n\n\n  \n\n\n\nFor each species we have numbers of individuals observed in 1cm wide length bins (the dl column indicates the width of each bin).\nIn addition to this information about the size distribution of the catches we have the total biomass of the annual commercial landings for each species, i.e., the fisheries yield. Like the spawning stock biomass estimates we used in the tutorial on finding species parameters, we obtained the values for the yield in tonnes per square kilometre (or, equivalently, grams per square metre) from the 2021 ICES stock assessment database by dividing the total yield of the assessed stock by the area of the assessment region in square kilometres and taking the geometric mean over the time period from 2012 to 2021. Here we just load them in from a file we prepared and store them in a yield_observed column in the species parameter dataframe of our model:\n\nspecies_params(cel_model)$yield_observed <- readRDS(\"celtic_yields.rds\")\n\nWe can now use plotYieldVsSpecies() to make a plot that for each species compares the observed yield to the yield currently achieved in the steady state of our model.\n\nplotYieldVsSpecies(cel_model)\n\n\n\n\nWe’ll have to do something about those yield values in the model. But first let’s have a look at the size distribution of the catches."
  },
  {
    "objectID": "build/refine-landings.html#exploring-catch-size-distributions",
    "href": "build/refine-landings.html#exploring-catch-size-distributions",
    "title": "Refine model: Landings",
    "section": "Exploring catch size distributions",
    "text": "Exploring catch size distributions\nThe plotYieldVsSize() function lets us see how well our modelled and the observed catch size distributions agree. Let’s take a look at the case of cod:\n\nplotYieldVsSize(cel_model, species = \"Cod\", catch = catch_lengths, \n                x_var = \"Length\")\n\n\n\n\nWe see that the red curve (model) and the blue curve (observations) match surprisingly well. This means that the selectivity parameters for cod are already chosen quite well in our model. However the match could be made even better by steepening the selectivity curve.\nLet us look at the current gear parameter data frame:\n\n# Let's look at our gear params first \ngear_params(cel_model)\n\n\n\n  \n\n\n\nWe notice that the row names are made up of the species name and the gear name, separated by a comma. So we can change the selectivity parameters specifically for cod with\n\n# Modify the l50 and l25 for cod\ngear_params(cel_model)[\"Cod, Commercial\", \"l50\"] <- 44\ngear_params(cel_model)[\"Cod, Commercial\", \"l25\"] <- 39.5\n\n#check the match between model and observed catch size distributions\nplotYieldVsSize(cel_model, species = \"Cod\", catch = catch_lengths, \n                x_var = \"Length\")\n\n\n\n\nThis looks better. We should have no scruples adjusting the gear selectivity parameters using our mizer model because they are hard to estimate outside a model.\nNow that we have changed fishing selectivity we need to find a new steady state. It is important to run steady() frequently, while making small changes to the model parameters. If we accumulate too many changes, finding a new steady state might be harder.\n\ncel_model <- steady(cel_model)\n\nYou probably wondered how I knew what the right values for the l50 and l25 parameter were for cod. The answer is that I used trial and error with the help of the tuneParams(). We’ll do some more of that in the following video. We pass the catch length data into the tuneParams() function via the catch argument:\n\ncel_model <- tuneParams(cel_model, catch = catch_lengths)\n\nNote how we assign the return value from the tuneParams() function back to the cel_model variable. That way we capture the changes that we make in the gadget.\nThe following is an old video. The new one is in preparation.\n\n\n\n\n\n\n\n\n\nThe tuneParams() gadget has a lot of useful panels and allows you to play with the parameters interactively. But most of these plots are also available as separate plot functions in mizer or in mizerExperimental."
  },
  {
    "objectID": "build/refine-landings.html#exercise-use-tuneparams-gadget-to-refine-your-model",
    "href": "build/refine-landings.html#exercise-use-tuneparams-gadget-to-refine-your-model",
    "title": "Refine model: Landings",
    "section": "Exercise: Use tuneParams gadget to refine your model",
    "text": "Exercise: Use tuneParams gadget to refine your model\nIn our video we only started refining the model by adjusting some parameters for a few species. We ask you to do something similar but for more species in order to refine the model you have built in the previous tutorial. But don’t spend too much time on this until we have improved the fit of the model to diet data."
  },
  {
    "objectID": "build/refine-diet.html",
    "href": "build/refine-diet.html",
    "title": "Refine your model: Diet",
    "section": "",
    "text": "In this tutorial we will start to refine the mizer model that we created in the previous tutorial. That model already has the broad features correct: In all the species we decided to include are coexisting in a steady state with the desired biomasses and growth rates. Mizer itself determined the size distribution of the species. We did not need to specify many parameters to achieve that. For most of the parameters that we did supply we said that it did not matter that we could only make educated guesses for their values or even just put NA, because we could refine the model later. We will start this refinement process in this tutorial and continue it in the next.\nAs always, we start by updating and loading packages.\n\ntry(unload(\"mizerExperimental\"), silent = TRUE)\nremotes::install_github(\"sizespectrum/mizerExperimental\", quiet = TRUE)\nlibrary(mizerExperimental)\nlibrary(tidyverse)\n\nWe load the model we created in the previous tutorial.\n\ncel_model <- readParams(\"cel_model.rds\")\n\nWhen you work through this material in worksheet 3 in your worksheet repository for this week you will be using your own model that you created in worksheet 2."
  },
  {
    "objectID": "build/refine-diet.html#resource-abundance",
    "href": "build/refine-diet.html#resource-abundance",
    "title": "Refine your model: Diet",
    "section": "Resource abundance",
    "text": "Resource abundance\nOne bit of information that we did not supply when we set up the model was the abundance of the resource. Let us take a look at the size-spectrum plot to see what value mizer chose:\n\nplotlySpectra(cel_model, power = 2, total = TRUE)\n\n\n\n\n\nWe have put total = TRUE to include the total community spectrum in the plot in black. At the smallest sizes the community is comprised of the resource only, plotted in green, but then at larger sizes the fish contribute. Sheldon’s observation was that the community size spectrum would be approximately flat all the way from bacteria to whales. We notice that the above plot does not quite conform to that observation. Instead, the spectrum is quite a bit lower at small sizes, then rises at the sizes where the fish dominate. It then drops off again because we have not included anything larger than cod in our model. No whales here. To get a community spectrum more in line with Sheldon’s observation we should increase the resource abundance\nThere is another plot that shows us that our model currently has too little resource. We plot the feeding level:\n\nplotFeedingLevel(cel_model)\n\n\n\n\nRecall from the section on the feeding level last week that the feeding level is the ratio between the maximum intake rate and the actual intake rate, so can never exceed 1. The closer it is to 1 the more satiated the fish is and the less of the encountered prey it will consume. The reason the feeding levels in the above plot is higher at larger sizes than at smaller sizes is that at larger sizes the fish start feeding on other fish while at smaller sizes they have to rely on the resource, and the resource is not as abundant as it should be.\nWe will now want to increase the abundance of resource, both to get the community abundance more in line with Sheldon’s observation and to give the fish a more constant feeding level throughout their life. We will first start doing this the tedious way in code and then introduce the tuneParams() shiny gadget to do it with point and click.\nCode\nWe don’t know by exactly what factor we need to scale up the resource. Let’s try increasing it by a factor of 2:\n\ncel_model <- scaleDownBackground(cel_model, factor = 1/2)\n\nThat the function scales down rather than up, so that we need to set the scaling factor to 1/2 rather than 2, is a historical accident. Let’s look at the spectrum plot now:\n\nplotlySpectra(cel_model, power = 2, total = TRUE)\n\n\n\n\n\nThe resource has increased by a factor of 2, even if this is not very noticeable on this logarithmic y axis. But we are now no longer in steady state. As always after we have made a modification, we need to run the dynamics to get back to steady state. But before we do that, we also want to match the growth rates again because they will of course have increased by increasing the resource abundance. So we do\n\ncel_model <- cel_model |> matchGrowth() |> steady()\n\nThis has now messed up the biomasses in the model:\n\nplotBiomassVsSpecies(cel_model)\n\n\n\n\nSo we also do\n\ncel_model <- cel_model |> matchGrowth() |> steady()\n\nThis is what the feeding levels look like now:\n\nplotFeedingLevel(cel_model)\n\n\n\n\nA little bit better but clearly not enough. So we need to do it again. But you will already have gotten the sense that this is going to be tedious: making the change, running to steady state, plotting the result, trying again ….\nShiny gadget\nWe will now introduce a shiny gadget (that is a technical term) that greatly facilitates this iterative tuning of the model. The gadget allows quick experimentation with changes to model parameters. It provides sliders for adjusting model parameters and tabs with various plots to immediately see the result of the changes. You can choose which parameter sliders and which plot tabs to include.\nWe start the gadget by calling the tuneParams() function.\n\ncel_model <- tuneParams(cel_model)\n\nThis will open the gadget in your web browser with our current model cel_model loaded. The following video shows what we do on that web page. After making the changes we want to make, we click the “Return” button in the gadget and the tuneParams() function returns the model in that updated state. The above code then assigns that updated model to the variable cel_model.\n\n\n\n\n\n\n\n\n\nNext we will use the gadget to refine our model using diet data."
  },
  {
    "objectID": "build/refine-diet.html#diet-data",
    "href": "build/refine-diet.html#diet-data",
    "title": "Refine your model: Diet",
    "section": "Diet data",
    "text": "Diet data"
  },
  {
    "objectID": "build/refine-diet.html#in-preparation",
    "href": "build/refine-diet.html#in-preparation",
    "title": "Refine your model: Diet",
    "section": "In preparation",
    "text": "In preparation\nWe’ll skip this for now and just save the model in its present state\n\nsaveParams(cel_model, \"cel_model_diet.rds\")"
  },
  {
    "objectID": "build/create-first-model.html",
    "href": "build/create-first-model.html",
    "title": "Create your first model",
    "section": "",
    "text": "Setting up a mizer model that agrees with observations used to be really difficult. That is not a surprise, because we have seen how all the species influence each other, as well as the resource, and how the reproduction rates of all species depend on the size spectra of all species and vice versa. So if you make changes in one corner of the model to make it agree with some observation, things change at another corner to mess things up again.\nThere are three dynamic processes in action in a mizer model at the same time: size-spectrum dynamics, reproduction dynamics and resource dynamics. These are fully interacting with each other, with feedback loops. So for example the resource spectrum depends on the consumption by fish, which depends on the fish size spectra, which depend on the fish growth rates, which depends on the resource spectrum. Similarly the reproduction rate depends on the number of mature fish and on their energy income, which depends among other things on the rate at which new individuals are recruited, which depends among other things on the reproduction rate. And all of these feedbacks depend on the model parameters that we are supposed to choose in a way that reproduces observed behaviour. It seems hopeless!\nThe way we have arrived at a simple process for the creation of a viable mizer model is to decouple the tuning of the size spectrum dynamics from the tuning of the reproduction dynamics and resource dynamics. So, as we have done last week, initially we turn off reproduction dynamics and resource dynamics. We set the constant reproduction rate to a level that produces the observed biomasses and we set the constant resource spectrum according to observations or, in the absence of observations, we set it to a Sheldon power law. We then use that size spectrum dynamics on its own. The size spectrum usually quickly settles down to its steady state, so that we can interactively tune parameters to get the steady state to agree with observations.\nOnce we are happy with the steady state of the model, we turn the reproduction and resource dynamics back on, but with parameter choices that do not modify the steady state of the size spectra in a now coupled system. We then have to tune the remaining parameters of the reproduction dynamics and resource dynamics to achieve the correct sensitivity of the system to perturbations away from its steady state. By separating tuning of the dynamics from the tuning of the steady state, the whole process becomes much more manageable.\nWe will concentrate on building models with the correct steady state this week and then tune the behaviour away from steady state next week.\nIn this tutorial we will take the species parameters that we assembled in the previous tutorial for the Celtic Sea ICES (International Council for Exploration of the Seas) areas 7e-j, and use the newMultispeciesParams() function to build a mizer model with them. We will let mizer choose most of the defaults and then adjust a few things so that the model has a steady state that has the observed species biomasses and growth rates. We will then do the fine-tuning in the following tutorials.\nAs always, we start by updating and loading packages.\n\ntry(unload(\"mizerExperimental\"), silent = TRUE)\nremotes::install_github(\"sizespectrum/mizerExperimental\", quiet = TRUE)\nlibrary(mizerExperimental)\nlibrary(tidyverse)\n\nNow the creation of the mizer model is an 8-step process."
  },
  {
    "objectID": "build/create-first-model.html#step-0-collect-parameters",
    "href": "build/create-first-model.html#step-0-collect-parameters",
    "title": "Create your first model",
    "section": "Step 0: Collect parameters",
    "text": "Step 0: Collect parameters\nWe did this in the previous tutorial. We now have a species parameter data frame, a species interaction matrix (optional) and a gear paramter data frame. So here we only need to read in those files.\n\nceltic_species_params <- readRDS(\"celtic_species_params.rds\")\nceltic_gear_params <- read.csv(\"celtic_gear_params.csv\")\nceltic_interaction <- read.csv(\"celtic_interaction.csv\", row.names = 1)\n\nWhen you repeat this work in your worksheet, you can check that the data was read in correctly by clicking on celtic_species_params, celtic_gear_params and celtic_interaction in the “Environment” tab. That will open the data frames in your editor window for you to inspect."
  },
  {
    "objectID": "build/create-first-model.html#step-1-create-mizerparams-object",
    "href": "build/create-first-model.html#step-1-create-mizerparams-object",
    "title": "Create your first model",
    "section": "Step 1: Create MizerParams object",
    "text": "Step 1: Create MizerParams object\nWe will now set up a multi-species mizer model using the function newMultispeciesParams(). Besides the species parameters, the gear parameters and the interaction matrix, the other information that flows into a multi-species model are the resource parameters, the allometric exponents n and p and the fishing effort.\nWe let mizer choose defaults for the resource parameters. By default, the resource carrying capacity will be set to a power law N_R(w) = \\kappa w^{-\\lambda} with \\lambda = 2.05, as we are already familiar with from week 1.\nLast week we discussed that our choice for the allometric exponents n (growth exponent) and p (metabolic exponent) is to take them both equal to 3/4. By default these exponents in multi-species models are set to different values, so we will overwrite the defaults in our newMultispeciesParams() command.\nWith this information we call the function newMultispeciesParams() which returns a MizerParams object that we save in the variable cel_model (lazy shorthand for “Celtic Sea model”):\n\ncel_model <- newMultispeciesParams(species_params = celtic_species_params,\n                                   gear_params = celtic_gear_params,\n                                   interaction = celtic_interaction, \n                                   initial_effort = 1,\n                                   lambda = 2.05, n = 3/4, p = 3/4)\n\nNote: Dimnames of interaction matrix do not match the order of species names in the species data.frame. I am now ignoring your dimnames so your interaction matrix may be in the wrong order.\n\n\nNo ks column so calculating from critical feeding level.\nUsing z0 = z0pre * w_inf ^ z0exp for missing z0 values.\n\n\nPlease ignore the note about “Dimnames”. It is due to a bug in the released version that will be fixed in the next release. The last two messages however are supposed to be there and they tell you that the newMultispeciesParams() function has made choices for some model parameters based on the information we supplied.\nIn order to always know what a mizer model is about, it is a good idea to give it some metadata. This is of course optional.\n\ncel_model <- \n    setMetadata(cel_model, \n                title = \"Celtic Sea model from mizer course in Nov 2022\",\n                description = \"See https://mizer.course.nov22.sizespectrum.org/build\")\n\nYou can get that metadata back later with getMetadata()."
  },
  {
    "objectID": "build/create-first-model.html#step-2-project-to-steady-state",
    "href": "build/create-first-model.html#step-2-project-to-steady-state",
    "title": "Create your first model",
    "section": "Step 2: Project to steady state",
    "text": "Step 2: Project to steady state\nThe newMultispeciesParams() function does not currently put much effort into choosing a good initial community configuration. Let’s have a look at what it has set up:\n\nplotlySpectra(cel_model, power = 2)\n\n\n\n\n\nThere is a lot wrong here. The species spectra lack the characteristic bulge at adult sizes. Also the species spectra do not line up nicely with the abundance of the resource. But most importantly, these spectra are not close to their steady state values.\nWe will now project to the steady state, which will finally give us realistic species spectra. To do this we use the special function steady() which implements our trick of keeping the reproduction rate and the resource spectrum constant while running the dynamics until the system has settled down in its steady state.\n\ncel_model2 <- steady(cel_model)\n\nConvergence was achieved in 70.5 years.\n\n\nWarning in setBevertonHolt(params, reproduction_level = old_reproduction_level):\nThe following species require an unrealistic reproductive efficiency greater\nthan 1: Boarfish\n\n\nWe can ignore the warning from the setBevertonHolt() function about unrealistic reproductive efficiencies. Those warnings are an artefact of how the reproduction level is set by default. We could fix those defaults, but we are not yet concerned with the reproduction dynamics so we don’t have to do that and just ignore the warnings.\nNow let us look at the spectra in the steady state:\n\nplotlySpectra(cel_model2, power = 2)\n\n\n\n\n\nThey look a lot more like species size spectra should look like, although there are still clearly some oddities, like the very low abundance of Monkfish among others.\n\n\n\n\n\n\nIf this step fails\n\n\n\n\n\nThe steady() function is not guaranteed to find the steady state. By default it stops after running the dynamics for a maximum of 99 years. If it warns you that it has not reached a steady state, then you should first try to run it again to see if within the next 99 years it reaches steay state. But if that still does not help, it may be that the steady state is actually unstable. In that case the system evolves towards an oscillating state instead. Luckily, this is rare for realistic parameters, but may well happen while you are still trying to find the correct parameters. If you encounter this phenomenon with your parameter choices, please let us know in the comments. We can then use your example to discuss the solution."
  },
  {
    "objectID": "build/create-first-model.html#step-3-calibrate-the-model-scale",
    "href": "build/create-first-model.html#step-3-calibrate-the-model-scale",
    "title": "Create your first model",
    "section": "Step 3: Calibrate the model scale",
    "text": "Step 3: Calibrate the model scale\nMizer is agnostic of whether you want to measure biomass per square meter, or per square kilometer, or for the entire area of the fishery or whatever. So initially it had set things up on an arbitrarily chosen scale. We can see this if we compare the biomasses of the species in the model with the observed biomasses from your species parameter file with the plotBiomassVsSpecies() function:\n\nplotBiomassVsSpecies(cel_model2)\n\n\n\n\nThis shows for each species the model biomass (open circle) and the observed biomass (filled square, if available) on a logarithmic y-axis. The line connecting model value and observed value is for visual purposes only. We see that model values and observed values are many orders of magnitude apart.\nUsing your supplied biomass observations, mizer can now change the scale of our model so that the total biomass in the model coincides with the total observed biomass, summed over all species.\n\ncel_model3 <- calibrateBiomass(cel_model2)\n\nOf course for the individual species the model biomasses will still disagree with the observed biomasses, with some being too high while others are too low. Just the total summed over all species agrees between model and observation.\n\nplotBiomassVsSpecies(cel_model3)\n\n\n\n\nWe see that the biomasses of Monkfish, European Hake and Cod are far too low in the model, as was already apparent from the size spectrum plot. So we should fix this in the next step."
  },
  {
    "objectID": "build/create-first-model.html#step-4-match-biomasses",
    "href": "build/create-first-model.html#step-4-match-biomasses",
    "title": "Create your first model",
    "section": "Step 4: Match biomasses",
    "text": "Step 4: Match biomasses\nTo fix the discrepancy between the model biomasses and the observed biomasses we simply need to rescale the model abundance of each species by the appropriate factor. The matchBiomasses() function does this for us.\n\ncel_model4 <- matchBiomasses(cel_model3)\nplotBiomassVsSpecies(cel_model4)\n\n\n\n\nNow the circles and squares lie exactly on top of each other. This is expected, because we simply changed the relative biomasses of species in the model. The size spectrum plot also look more healthy now, although the size spectrum of Herring looks surprisingly high. I wonder whether we mis-estimated its observed biomass.\n\nplotlySpectra(cel_model4, power = 2)\n\n\n\n\n\nThere are similar functions matchNumbers() and matchYields() that you would use in case either total numbers of individuals or fisheries yields are known instead of total biomasses."
  },
  {
    "objectID": "build/create-first-model.html#step-5-project-to-steady-state",
    "href": "build/create-first-model.html#step-5-project-to-steady-state",
    "title": "Create your first model",
    "section": "Step 5: Project to steady state",
    "text": "Step 5: Project to steady state\nAfter we have rescaled the spectra of the individual species to reproduce the observed biomasses and have rescaled the rate parameters to reproduce the observed growth rate, the system is no longer in a steady state. All species now experience a new prey distribution and a new predator distribution and so their growth and death rates have changed, which requires us to run the dynamics again to find the new steady state:\n\ncel_model5 <- steady(cel_model4)\nplotlySpectra(cel_model5, power = 2, total = TRUE)\n\n\n\n\n\n(You can ignore the message about the resource carrying capacity. That is only an artefact of how we have currently set up the constant resource and the confusing message will be removed in the next mizer release.)\nOf course running to steady state has now messed up our biomasses again:\n\nplotBiomassVsSpecies(cel_model5)\n\n\n\n\nLuckily the discrepancies are now much smaller than they were before. Before we deal with that, there is another issue we need to attend to in the next step.\nIf this step fails\nIt may be that the change in biomasses needed is so great that the system has difficulties finding its steady state again after calling matchBiomasses(). In that case you may want to try to not adjust all species in one go. You can use the species argument to matchBiomasses() to only adjust a subset of species, then call steady() then adjust the rest and then call steady() again. :::"
  },
  {
    "objectID": "build/create-first-model.html#step-6-calibrate-growth",
    "href": "build/create-first-model.html#step-6-calibrate-growth",
    "title": "Create your first model",
    "section": "Step 6: Calibrate growth",
    "text": "Step 6: Calibrate growth\nThe growth rates in the model are not quite right yet. We can see that by calculating the age at which the fish in the steady state of the model would reach maturity size, using the age_mat() function, and comparing it to the observed age at maturity in the real world that we extracted from FishBase in the previous tutorial and saved in the species parameters.\n\nage_mat_model = age_mat(cel_model5)\nage_mat_observed = celtic_species_params$age_mat\ndata.frame(age_mat_model, age_mat_observed)\n\n\n\n  \n\n\n\nWe can fix that with the matchGrowth() function which rescales the search volume, the maximum consumption rate and the metabolic rate all by the appropriate factor while keeping the feeding level and the critical feeding level unchanged.\n\ncel_model6 <- matchGrowth(cel_model5)\n\nWarning in setBevertonHolt(params): For the following species `erepro`\nhas been increased to the smallest possible value: erepro[Cod] = 0.00209;\nerepro[Monkfish] = 0.000144\n\nage_mat_model = age_mat(cel_model6)\ndata.frame(age_mat_model, age_mat_observed)"
  },
  {
    "objectID": "build/create-first-model.html#step-7-project-to-steady-state",
    "href": "build/create-first-model.html#step-7-project-to-steady-state",
    "title": "Create your first model",
    "section": "Step 7: Project to steady state",
    "text": "Step 7: Project to steady state\nNow that we have corrected the growth rates, the system is of course again out of its steady state. So again we run the dynamics until the system has settled into its new steady state.\n\ncel_model7 <- steady(cel_model6) \nplotlySpectra(cel_model7, power = 2, total = TRUE)\n\n\n\n\n\nYou see a pattern emerging. Whenever we have made a change to the system we have to run the dynamics with the steady() function to get to the new steady state."
  },
  {
    "objectID": "build/create-first-model.html#step-8-rinse-and-repeat",
    "href": "build/create-first-model.html#step-8-rinse-and-repeat",
    "title": "Create your first model",
    "section": "Step 8: Rinse and repeat",
    "text": "Step 8: Rinse and repeat\nRunning to steady state has again messed up our biomasses:\n\nplotBiomassVsSpecies(cel_model7)\n\n\n\n\nAnd it has also slightly messed up our growth rates:\n\nage_mat_model = age_mat(cel_model7)\ndata.frame(age_mat_model, age_mat_observed)\n\n\n\n  \n\n\n\nWe appear to be in a bind: If we match the biomasses and growth rates we are no longer at steady state, if we run to steady state we no longer match the biomasses and growth rates. But notice that the discrepancies are not as big as previously. So we don’t give up but simply keep iterating.\n\ncel_model8 <- cel_model7 |>\n    calibrateBiomass() |> matchBiomasses() |> matchGrowth() |> steady() |>\n    calibrateBiomass() |> matchBiomasses() |> matchGrowth() |> steady() \n\n(There are possible variations of this. You could leave out the calibrateBiomass() steps. You could insert an additional steady() step between matchBiomasses() and matchGrowth(). Some variants may converge faster than others, but it really makes no practical difference because this is so fast anyway. ) It turns out that in this example iterating twice more was enough. Even in the steady state the biomasses are now spot on:\n\nplotBiomassVsSpecies(cel_model8)\n\n\n\n\nAnd the growth rates too are matched much more precisely than really necessary:\n\nage_mat_model = age_mat(cel_model8)\ndata.frame(age_mat_model, age_mat_observed)\n\n\n\n  \n\n\n\nWe can now save the resulting model to disk for future use.\n\nsaveParams(cel_model8, \"cel_model.rds\")\n\nOf course there are still things wrong with this model. We will improve the model in the next two tutorials. But I want to stress that building a multi-species model where all the species coexist at the observed abundances and grow at the observed growth rates is no mean feat. In the past it took a lot of work to get to this stage."
  },
  {
    "objectID": "build/create-first-model.html#exercise",
    "href": "build/create-first-model.html#exercise",
    "title": "Create your first model",
    "section": "Exercise",
    "text": "Exercise\nNow use your species parameter data frame that you assembled in the exercise in the previous tutorial. Use the worksheet for this tutorial “worksheet-2-create-first-model.Rmd” to go through the 8 steps that we went through above to build your own mizer model based on your species parameters.\nThere are ways how the above method can fail. If that happens, there are various ways to rescue the situation. But rather than discussing such eventualities in the abstract, we will wait to see if you run into concrete difficulties. If you do, please save your code and email gustav.delius@gmail.com. We will then use your example to discuss the solutions."
  },
  {
    "objectID": "build/create-first-model.html#summary",
    "href": "build/create-first-model.html#summary",
    "title": "Create your first model",
    "section": "Summary",
    "text": "Summary\nWe have gone through the 8-step process of building a mizer model from your species parameters and your interaction matrix. The 8 steps were:\n\nCreate a MizerParams object with newMultispeciesParams().\nFind a coexistence steady state with steady().\nSet the scale of the model to agree with the observed total biomass with calibrateBiomass(). This does not spoil the steady state.\nUse matchBiomass() to move the size spectra of the species up or down to match the observed biomasses. This will spoil the steady state.\nProject back to steady state with steady().\nUse matchGrowth() to adjust the physiological rates so that the species reach their maturity size at maturity age.\nProject back to steady state with steady().\nIterate steps 4 through 7 as often as you like to get the steady-state biomasses to agree as precisely with your observations as you like."
  },
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Troubleshooting",
    "section": "",
    "text": "On this page we will collect issues that people have come across while working on the course, together with the solutions. If you paste your error message into the search box on this course website, it should find the appropriate issue on this page in case it has been reported by someone else already.\nIf you can’t find your issue resolved on this page, make sure to post a comment.\nYou can help out by editing this page when you come across an issue and its solution. For example if you managed to find the solution yourself, please nevertheless edit this page to add your issue and your solution because it will save others time."
  },
  {
    "objectID": "troubleshooting.html#long-pathnames",
    "href": "troubleshooting.html#long-pathnames",
    "title": "Troubleshooting",
    "section": "Long pathnames",
    "text": "Long pathnames\nIf your R project is located inside a directory with a very long path name, you might get an error message because R will not be able to access the path.\n\n‘Warning in gzfile(file, “wb”): cannot open the compressed file …’\n\nSolution: make sure you create your R project in a higher directory with a shorter path"
  },
  {
    "objectID": "troubleshooting.html#github-keeps-asking-for-password",
    "href": "troubleshooting.html#github-keeps-asking-for-password",
    "title": "Troubleshooting",
    "section": "Github keeps asking for password",
    "text": "Github keeps asking for password\nFor some users, Github asks for username and password (or personal access token) every time you want to push your commits to Github. This can happen if your Git version is too old.\nSolution: install the latest version of Git."
  },
  {
    "objectID": "understand/dynamics-of-spectra.html",
    "href": "understand/dynamics-of-spectra.html",
    "title": "Dynamics of size spectra",
    "section": "",
    "text": "In previous tutorials we have concentrated on the steady state of the mizer model, where for each size class and each species, the rate at which individuals grow into the size class balances the rate at which individuals grow out of the size class or die, thus keeping the size spectrum constant. In this tutorial we explore the dynamic that takes place when this balance is changed.\nSize-spectrum dynamics is described by the beautiful partial differential equation\n\n\\frac{\\partial N(w)}{\\partial t} + \\frac{\\partial g(w) N(w)}{\\partial w}\n  = -\\mu(w) N(w)\n\ntogether with the boundary condition\n\nN(w_{min}) = \\frac{R_{dd}}{g(w_{min})},\n\nwhere N(w) is the number density at size w, g(w) is the growth rate and \\mu(w) is the death rate of individuals of size w, w_{min} is the egg size and R_{dd} is the birth rate. Luckily it is easy to describe in words what these equations are saying.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nSize spectrum dynamics is very intuitive: The rate at which the number of individuals in a size class changes is the difference between the rate at which individuals are entering the size class and the rate at which they are leaving the size class. Individuals can enter a size class by growing in or, in the case of the smallest size class, by being born into it. They can leave by growing out or by dying.\n\n\n\nWhat makes these seemingly obvious dynamics interesting is how the growth rate and the death rate are determined in terms of the abundance of prey and predators and the feeding preferences and physiological parameters of the individuals. We have discussed a bit of that in previous tutorials and will discuss it much more in upcoming tutorials. We will discuss the birth rate R_{dd} below in the section on how reproduction is modelled. But first we want to look at the results of simulating the size spectrum dynamics.\nYou will be doing your own work for this tutorial in the accompanying worksheet file “worksheet5-dynamics-of-spectra.Rmd”. You will find this file in the worksheet repository for this week that you already used in previous tutorials.\nAs always, we start by making sure we have the latest version of the mizerExperimental package and load it as well as the tidyverse.\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\nlibrary(mizerExperimental)\nlibrary(tidyverse)\n\n\nIn the previous tutorial, in the section on trophic cascades, we already simulated the size-spectrum dynamics to find the new steady state. But we only looked at the final outcome once the dynamics had settled down to the new steady state. We reproduce the code here:\n\n# Create trait-based model\nmp <- newTraitParams() |> \n    # run to steady state with constant reproduction rate\n    steady() |>\n    # turn of reproduction and instead keep egg abundance constant\n    setRateFunction(\"RDI\", \"constantEggRDI\") |>\n    setRateFunction(\"RDD\", \"noRDD\")\n\n# We make a copy of the model\nmp_lessRes <- mp\n# and set the resource interaction to 0.8 for species 8 to 11\nspecies_params(mp_lessRes)$interaction_resource[8:11] <- 0.8\n\n# We run the dynamics until we reach steady state\nmp_lessRes_steady <- projectToSteady(mp_lessRes)\n\n# We compare the steady states\nplotSpectra2(mp_lessRes_steady, name1 = \"less resource\", \n             mp, name2 = \"original\",\n             total = TRUE, power = 2,\n             ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\nBut we can also save and then display the spectra of all the species at intermediate times. This is what the project() function does. It projects the current state forward in time and saves the result of that simulation in a larger object, a MizerSim object, which contains the resulting time series of size spectra. Let’s use it to project forward by 24 years.\n\nsim_lessRes <- project(mp_lessRes, t_max = 24)\n\nWe can now use this MizerSim object in the animateSpectra() function to create an animation showing the change in the size spectra over time.\n\nanimateSpectra(sim_lessRes, total = TRUE, power = 2, \n               ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\n\nGo ahead, press the Play button.\nNote, for some species size spectra at the largest size class drop all the way to very small values (e.g. 10^-7) and for others they stop higher. This is just a discretisation artefact and is not important. Try to ignore it.\nOf course we can also get at the numeric values of the spectra at different times. First of all the function getTimes() gives the times at which simulation results are available in the MizerSim object:\n\ngetTimes(sim_lessRes)\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n\n\nThe function N() returns a three-dimensional array (time x species x size) with the number density of consumers. To get for example the number density for the 2nd species after 5 years in the 1st size class we do\n\nN(sim_lessRes)[6, 2, 1]\n\n[1] 2.621407\n\n\nIf the function getBiomass() is supplied with a MizerSim object then it returns an array (time x species) containing the biomass in grams at each time step for all species. So for example the biomass in grams of the 2nd species after 5 years is\n\ngetBiomass(sim_lessRes)[6, 2]\n\n[1] 0.003434511\n\n\nThe biomass time series can be plotted with plotBiomass():\n\nplotBiomass(sim_lessRes)\n\n\n\n\nMizer provides many more functions to analyse the results of a simulation, some of which you will learn later about in this course."
  },
  {
    "objectID": "understand/dynamics-of-spectra.html#reproduction-dynamics",
    "href": "understand/dynamics-of-spectra.html#reproduction-dynamics",
    "title": "Dynamics of size spectra",
    "section": "Reproduction dynamics",
    "text": "Reproduction dynamics\nThe above simulation was run with constant abundance in the smallest size class for each species. This of course is not realistic. The abundance of the smallest individuals depends on the rate at which mature individuals spawn offspring, and this in turn depends, among other things, on the abundance of mature individuals. So if the abundance of mature individuals goes down drastically, as it did for species 8 to 11 above, then the abundance of offsprings for those species will go down as well.\nTo see the effect we run the same code as above after deleting the two lines that turned off the reproduction dynamics. We also specify with t_save = 2 that we want to save the spectrum only every second year, which speeds up the display of the animation.\n\n# Create trait-based model\nmp <- newTraitParams() |> \n    # run to steady state with constant reproduction rate\n    steady()\n\n# We make a copy of the model\nmp_lessRes <- mp\n# and set the resource interaction to 0.8 for species 8 to 11\nspecies_params(mp_lessRes)$interaction_resource[8:11] <- 0.8\n\n# We simulate the dynamics for 30 years, saving only every 2nd year\nsim_lessRes <- project(mp_lessRes, t_max = 30, t_save = 2)\n\n# We animate the result\nanimateSpectra(sim_lessRes, total = TRUE, power = 2, \n               ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\n\nI think you might be surprised at the result when you press the Play button now.\nWhat is going on with species 1?"
  },
  {
    "objectID": "understand/dynamics-of-spectra.html#how-reproduction-is-modelled",
    "href": "understand/dynamics-of-spectra.html#how-reproduction-is-modelled",
    "title": "Dynamics of size spectra",
    "section": "How reproduction is modelled",
    "text": "How reproduction is modelled\nEnergy invested into reproduction\nWe already discussed the investment into reproduction in an earlier tutorial. As mature individuals grow they invest an increasing proportion of their income into reproduction and at their asymptotic size they would be investing all income into reproduction. Summing up all these investments from mature individuals of a particular species gives the total rate E_R at which that species invests energy into reproduction. This total rate of investment is multiplied by a reproduction efficiency factor erepro, divided by a factor of 2 to take into account that only females reproduce, and then divided by the egg weight w_min to convert it into the rate at which eggs are produced. The equation is:\n\nR_{di} = \\frac{\\rm{erepro}}{2 w_{min}} E_R.\n\nThis is calculated in mizer with getRDI():\n\ngetRDI(mp)\n\n          1           2           3           4           5           6 \n0.344090412 0.211705188 0.130253809 0.080140004 0.049306967 0.030336622 \n          7           8           9          10          11 \n0.018664921 0.011483786 0.007065518 0.004347133 0.002674619 \n\n\nThe erepro parameter or reproduction efficiency can vary between 0 and 1 (although 0 would be bad) and reflects the fact that only a fraction of energy invested into reproduction can make into viable eggs or larvae.\nDensity-dependence in reproduction\nNote that mizer models the rate of egg production. The size spectrum dynamics then determine how many of those larvae grow up and survive to be recruited to the fishery.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThe stock-recruitment relationship is an emergent phenomenon in mizer, with several sources of density dependence. Firstly, the amount of energy invested into reproduction depends on the energy income of the spawners, which is density-dependent due to competition for prey. Secondly, the proportion of larvae that grow up to recruitment size depends on the larval mortality, which depends on the density of predators, and on larval growth rate, which depends on density of prey.\n\n\n\nHowever there are other sources of density dependence that are not explicitly modelled mechanistically in mizer. An example would be a limited carrying capacity of suitable spawning grounds and other spatial effects. So mizer has another species parameter R_{max} that gives the maximum possible rate of recruitment. Imposing a finite maximum reproduction rate leads to a non-linear relationship between energy invested and eggs hatched. This density-dependent reproduction rate R_{dd} is given by a Beverton-Holt type function:\n R_{dd} = R_{di} \\frac{R_{max}}{R_{di} + R_{max}}\nRather than looking at the formula, let’s look at a figure:\n\n\n\n\n\nThis figure shows two graphs of R_{dd} (solid lines), one for higher R_{max} (black) and one for lower R_{max} (blue). The values of R_{max} are indicated by the dotted lines. The dashed lines show the density-independent rate R_{di}. Both graphs are for the same amount E_R of energy invested into reproduction.\nThe important fact to observe is that the solid curves becomes more shallow as R_{max} gets closer to the actual reproduction rate R_{dd}. This slope determines how big the effect of a change in investment into reproduction (for example due to a change in spawning stock biomass) is on the reproduction rate. As the energy invested in reproduction changes away from the steady state value E_R on the x-axis, the the solid curves shows how much the reproduction rate changes on the y-axis. The change is smaller along the shallower blue line, the one that corresponds to the R_{max} value that is closer to R_{dd}. The result is that a species with a low ratio between R_{max} and R_{dd} will be less impacted by depletion of its spawning stock by fishing, for example. This ratio we will refer to as the reproduction level and we will discuss it in the next section.\nThis density-dependent rate of reproduction is calculated in mizer with getRDD():\n\ngetRDD(mp)\n\n          1           2           3           4           5           6 \n0.258067809 0.158778891 0.097690357 0.060105003 0.036980226 0.022752467 \n          7           8           9          10          11 \n0.013998691 0.008612839 0.005299139 0.003260350 0.002005964 \n\n\nThis is the rate at which new individuals are entering the smallest size class. The actual number density in the smallest size class is then determined by the usual size-spectrum dynamics."
  },
  {
    "objectID": "understand/dynamics-of-spectra.html#reproduction-level",
    "href": "understand/dynamics-of-spectra.html#reproduction-level",
    "title": "Dynamics of size spectra",
    "section": "Reproduction level",
    "text": "Reproduction level\nWe have seen the two species parameters that determine how the energy invested into reproduction is converted to the number of eggs produced: erepro and R_max. For neither of these is it obvious what value they should have. The choice of values influences two important properties of a model: the steady state abundances of the species and the density-dependence in reproduction. It is therefore useful to change to a new set of two parameters that reflect these two properties better. These are:\n\nThe birth rate R_{dd} at steady state. This determines the abundance of a species.\nThe ratio between R_{dd} and R_{max} at steady state. This determines the degree of density dependence.\n\nThe ratio R_{dd} / R_{max} we denote as the reproduction level. This name may remind you of the feeding level, which was the ratio between the actual feeding rate and the maximum feeding rate and described the level of density dependence coming from satiation. It takes a value between 0 and 1. It follows from our discussion in the previous section that a species with a high reproduction level is more resilient to changes.\nWe can get the reproduction levels of the different species with getReproductionLevel():\n\ngetReproductionLevel(mp)\n\n   1    2    3    4    5    6    7    8    9   10   11 \n0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 \n\n\nWe see that by default newTraitParams() had given all species the same reproduction level. We can change the reproduction level with the setBevertonHolt() function. We can set different reproduction levels for each species, but here we will simply set it to 0.9 for all species:\n\nmp9 <- setBevertonHolt(mp, reproduction_level = 0.9)\n\nChanging the reproduction level has no effect on the steady state, because that only depends on the rate of egg production R_dd and that is kept fixed when changing the reproduction level. We can check that by running our new model to steady state and plotting that steady state together with the original steady state. They overlap perfectly.\n\nmp9 <- projectToSteady(mp9)\n\nConvergence was achieved in 3 years.\n\nplotSpectra2(mp, name1 = \"reproduction_level = 0.25\",\n             mp9, name2 = \"reproduction_level = 0.9\",\n             total = TRUE, power = 2, ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\nHowever the reproduction level has an effect on how sensitive the system is to changes. As an example, let us look at the dynamics that is triggered by the reduction in interaction with the resource by species 8 through 11.\n\n# We make a copy of the model\nmp_lessRes9 <- mp9\n# and set the resource interaction to 0.8 for species 8 to 11\nspecies_params(mp_lessRes9)$interaction_resource[8:11] <- 0.8\n\nsim_lessRes9 <- project(mp_lessRes9, t_max = 30, t_save = 2)\n\nanimateSpectra(sim_lessRes9, total = TRUE, power = 2, \n               ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\n\nNotice how the species have settled down to a new steady state after 30 years without any extinctions and the impact on species 1 is much less extreme. As expected, the higher reproduction level has made the species more resilient to perturbations.\nThe problem of course is that in practice the reproduction level is hardly ever known. Instead one will need to use any information one has about the sensitivity of the system from observed past perturbations to calibrate the reproduction levels. We’ll discuss this again in week 3.\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nGo back to the example with fishing on individuals above 1kg from the section on fishing-induced cascades. Impose the same fishing, but now on the trait-based model with reproduction dynamics left turned on and with a reproduction level of 0.5 for all species. Project the model for 20 years. How many species have a reduced total biomass after 20 years? What is the total biomass of species 1 after 20 years?"
  },
  {
    "objectID": "understand/dynamics-of-spectra.html#resource-dynamics",
    "href": "understand/dynamics-of-spectra.html#resource-dynamics",
    "title": "Dynamics of size spectra",
    "section": "Resource dynamics",
    "text": "Resource dynamics\nThe resource spectrum is not described by size spectrum dynamics, because in reality it is typically not made up of individuals that grow over a large size range during their life time. In mizer, the resource number density in each size class is describe by semichemostat dynamics: the resource number density in each size class recovers after depletion, and this biomass growth or recovery rate will decrease as the number density gets close to a carrying capacity. If you want the mathematical details, you can find them in the mizer model description in the section on resource density.\nThe effect of these dynamics is that if the number of fish consuming the resource in a certain size range increases, the resource abundance in that size range will decrease, if it cannot recover quickly enough (regeneration rate of the resource is set by the user). So there is competition for the resource, which provides a stabilising influence on the fish abundances. We will be discussing this more in week 3."
  },
  {
    "objectID": "understand/dynamics-of-spectra.html#summary-and-recap",
    "href": "understand/dynamics-of-spectra.html#summary-and-recap",
    "title": "Dynamics of size spectra",
    "section": "Summary and recap",
    "text": "Summary and recap\n1) Size spectrum dynamics is very intuitive: the rate at which the number of individuals in a size class changes is the difference between the rate at which individuals grow into (or are born into) the size class and the rate at which individuals grow out of or the size class or die in the size class.\n2) The project() function simulates the dynamics and creates a MizerSim object that contains the resulting time series of size spectra.\n3) Mizer provides many functions for extracting, analysing and plotting the results of a simulation, some of which we will be using in week 3.\n4) Instead of a stock-recruitment relationship as used in other fisheries models, a mizer model relates the energy invested into reproduction to the number of eggs produced. The growth and mortality that the larvae experience until they are recruited to the fishery lead to density-dependence in the recruitment. Additional density dependence is applied to the egg production.\n5) The relation between energy invested in reproduction and the actual birth rate is described by two parameters: the density independent reproduction efficiency erepro and the maximum birth rate R_max.\n6) In practice a more useful way to parametrise the reproduction is by two other parameters: the birth rate R_{dd} at steady state (which determines the total abundance of a species) and the reproduction level (which determines the amount the amount of density dependence that applies to egg production).\n7) A change in the reproduction level does not change the steady state but it changes the sensitivity of a species and the system to changes."
  },
  {
    "objectID": "understand/index.html",
    "href": "understand/index.html",
    "title": "Week 1: Understand size-spectrum modelling",
    "section": "",
    "text": "Your goal in this first week of the course is to gain a thorough understanding of size spectra and their dynamics. This means that at the end of the week you will understand the parameters that shape the size spectra and how size spectra respond to changes. You will have a feel for how size-spectrum dynamics is different from usual single-species age-based dynamics.\nIt is worth spending an entire week on building this understanding, because it will enable you to build more reliable models in the second week and to appropriately explore the model predictions in the third week.\nWe will revisit many of the concepts introduced in Ken Andersen’s guest lecture that you may have seen in the Prepare section, but our approach here will be much more hands-on, with exercises dotted around the tutorials to consolidate your understanding."
  },
  {
    "objectID": "understand/index.html#tutorials",
    "href": "understand/index.html#tutorials",
    "title": "Week 1: Understand size-spectrum modelling",
    "section": "Tutorials",
    "text": "Tutorials\nThe material for this week is split into 5 tutorials:\n\nObserved size spectra\nBecause many of the physiological rates in fish (like growth, mortality, metabolism, reproduction) depend on the size of the individuals, a mizer model needs to keep track of the size distributions of the populations, the so-called size spectra. To get a feel for size spectra, in this first tutorial you will take observational data and make plots of size spectra. There is confusion in the size spectrum literature because there are different ways to represent the size spectra and this tutorial will introduce these, so that you can cut through the confusion.\nSingle-species spectra\nAt the community level, size spectra tend to look like power laws. But the size spectrum of each individual species making up the community will look different. In this tutorial we will investigate how the shape of the single species spectrum is determined by an interplay of growth and mortality.\nPredation, growth and mortality\nA particular strength of a mizer model is that growth curves and mortality rates are not fixed externally but are emergent and dependent on the availability of prey and the presence of predators. In this tutorial we explore how predation is modelled in mizer and how it effects growth and mortality.\nSpecies interactions\nIn a mizer model all the species in the community interact with each other through size-based predation. So any changes in one species’ size spectrum affects the size spectra of the other species, which in turn affects that first species. In this tutorial we start investigating some of the effects this has.\nDynamics of spectra\nIn previous tutorials we have concentrated on the steady state of the mizer model, where for each size class and each species, the rate at which individuals grow into the size class balances the rate at which individuals grow out of the size class or die, thus keeping the size spectrum constant. In this tutorial we explore the dynamic that takes place when this balance is changed."
  },
  {
    "objectID": "understand/index.html#worksheets",
    "href": "understand/index.html#worksheets",
    "title": "Week 1: Understand size-spectrum modelling",
    "section": "Worksheets",
    "text": "Worksheets\nEach tutorial comes with exercises and a worksheet in which to complete the exercises. These worksheets are contained in a dedicated repository on GitHub to which you will push your work to get feedback. This will work the same way as we discussed in the tutorial Use Git and GitHub. If you did not yet get a chance to work through that tutorial, please do so now before continuing with this week’s tutorials.\n\n\n\n\n\n\n\n\n\nTo get your worksheet repository for this week, follow this link:\nhttps://classroom.github.com/a/pbejAX-P\nOnce you have cloned your worksheet repository to your computer, open the file “worksheet1-observed-size-spectra.Rmd” by clicking on it in the “Files” tab of RStudio. It will open in the Editor tab and you can start working through it. It contains essentially the same material as the first tutorial on this website. The difference is that on this website the code has already been run for you and the output of the code is already displayed whereas in the tutorial you run the code yourself. That allows you to get a more intimate understanding of what is going on by experimenting with making changes to the code or adding extra code of your own. You will need to do that for example in order to complete the tutorial exercises.\nDo save the worksheet frequently and commit all those experiments of yours to your repository. You never know whether you may not want to revisit some of them later.\nIf you feel that you do not have the time to engage with the worksheets and the exercises and only want to read through the tutorials on this website then that is fine too. You are entirely free to choose the level of engagement to fit your needs. Similarly, even if you do not have the time to absorb everything in tutorials and have only read the “Summary and recap” that you find at the end of each tutorial, you are still welcome at any of the daily meetings. Furthermore you should feel free drop in and out of the meetings at any time, as you schedule allows. It may well be that the conversations with other participants at the meetings turn out to be more valuable to you then the tutorials or the worksheets."
  },
  {
    "objectID": "understand/species-interactions.html",
    "href": "understand/species-interactions.html",
    "title": "Species interactions",
    "section": "",
    "text": "In the previous tutorials we studied a single species interacting with a fixed background community. In this tutorial we want to acknowledge that there is no such thing as a fixed background community. Instead, all species form part of a dynamical ecosystem in which changes to any species has knock-on effects on other species. Furthermore, the resulting changes in the other species will react back on the first species, which now finds its prey community and its predator community changed. This is where we realise that we need multi-species models, because without a model we cannot calculate or easily predict how all these changes will affect each other.\nYou will be doing your own work for this tutorial in the accompanying worksheet file “worksheet4-species-interactions.Rmd”. You will find this file in the worksheet repository for this week that you already used in previous tutorials.\nAs always, we start by making sure we have the latest version of the mizerExperimental package and load it, as well as the tidyverse."
  },
  {
    "objectID": "understand/species-interactions.html#trait-based-model",
    "href": "understand/species-interactions.html#trait-based-model",
    "title": "Species interactions",
    "section": "Trait-based model",
    "text": "Trait-based model\nIn this first week we aim for understanding, not realism. So in this tutorial we investigate the tangled web of interactions in an idealised multi-species system. We choose a trait-based model in which the species making up the community differ from each other only in a single trait: their asymptotic body size (sometimes it is also called maximum body size).\nWe use the newTraitParams() function to create our idealised trait-based multi-species model. The function has many parameters, but we will just keep the defaults. Unlike the newSingleSpeciesParams() function, the newTraitParams() function does not set the initial spectra to their steady state values. We thus need to run the result through the steady() function (we’ll discuss that function more next week). We assign the resulting MizerParams object to the variable mp.\n\nmp <- newTraitParams() |> steady()\n\nLet us look at the biomass density in log weight.\n\nplotSpectra(mp, power = 2, total = TRUE)\n\n\n\n\nWe see 11 species spectra and a resource spectrum. The resource spectrum starts at a smaller size than the fish spectra, in order to provide food also for the smallest individuals (larvae) of the fish spectra. Each species spectrum has a shape of the type we expect, given what we have seen in the tutorial on single species spectra. The spectra of the different species all look essentially the same, except for being shifted along the size axis. This is because in this trait-based model the species differ only through their asymptotic size. This regularity will of course not be present in a real-world ecosystem, but it makes it easier for us to build an intuition about the effects of species interactions.\nNote how the community size spectrum, plotted in black, that is obtained by summing together all the individual species and resource spectra, approximately follows a power law (i.e., approximately follows a straight line in the log-log plot).\nTurn off reproduction dynamics\nAs in previous tutorials, we want to concentrate on the shapes of the size spectra and we do not yet want to look at what determines the overall abundance of each species. Therefore we modify the model so that it keeps the abundances at egg size fixed (i.e. numbers in the first size bin). You do not need to look in detail at the following code, except to note that a mizer model is very customisable in the sense that an advanced user can overwrite almost any behaviour with custom behaviour.\n\nmp <- mp |>\n    setRateFunction(\"RDI\", \"constantEggRDI\") |>\n    setRateFunction(\"RDD\", \"noRDD\")\n\nThe functionality for customising and extending mizer could be the subject of an entire extra week, and we will not have time for it. But during the course you can certainly let us know what kinds of customisation you would like to make and we can give pointers. You can also look at a recent blog post where Phoebe Woodworth-Jefcoats shows how to use custom rate functions to implement temperature-dependent rates in mizer."
  },
  {
    "objectID": "understand/species-interactions.html#mortality-from-other-species",
    "href": "understand/species-interactions.html#mortality-from-other-species",
    "title": "Species interactions",
    "section": "Mortality from other species",
    "text": "Mortality from other species\nThe species interact with each other via predator-prey interactions. These interactions shape both mortality and energy income. In this section we look at mortality imposed on a particular species by its predators. We choose to look at species 8. The following graph shows the relative contributions to the mortality rate for species 8 from all the other species:\n\nplotlyDeath(mp, species = \"8\")\n\n\n\n\n\nThe horizontal axis shows the size of the individual whose mortality we are looking at. Towards the left we see the mortality of the small larvae, as we move towards the right we move to larger individuals. So the main important message from this graph is that as an individual grows up their main predators change.\nYou might have expected that species 8 would be predated upon by the larger species 9, 10 and 11. And for large individuals of species 8, these three species do indeed form the dominant source of predation mortality, but we see also that smaller individuals of species 8 are predominantly predated upon by predators from smaller species. This arises because each predator prefers to feed at a certain fraction of its own size (which is set to 1/100th in this model), so the larger predators loose interest in the larvae and concentrate on the larger prey.\nThis ontogenetic diet shift as an individual grows up is the main reason why standard food-web models, where interaction between predator and prey is entirely determined by their species, are inappropriate for modelling fish communities.\nIn the above graph you also see that the smallest individuals and the largest individuals get the majority of their mortality from “external” sources, by which we designate all the mortality that is not from predation by the modelled species. So it is “external” in the sense that its sources are not represented inside the model. For large individuals this external mortality would include predation from mammals and senescence mortality. For small individuals this external mortality comes from predation by small, possibly planktonic, organisms that are not explicitly modelled.\nIn the absence of other information, our simple trait-based model just assumes that this external mortality is such that the total mortality scales allometrically with an individual’s size to the power of -1/4. This is why larval mortality is actually quite high. We can see this in the following plot which instead of proportions shows the actual mortality rates:\n\nplotDeath(mp, species = \"8\", proportion = FALSE)\n\n\n\n\nThe plotDeath() function is extremely useful when building your own model. It is important to know where the majority of mortality on your species and its various sizes come from. So make sure you remember it and use it a lot."
  },
  {
    "objectID": "understand/species-interactions.html#income-from-other-species",
    "href": "understand/species-interactions.html#income-from-other-species",
    "title": "Species interactions",
    "section": "Income from other species",
    "text": "Income from other species\nNow that we have investigated who eats species 8, we also want to know who is eaten by species 8. We can check that by plotting the diet of this species:\n\nplotDiet(mp, species = \"8\")\n\n\n\n\nThe diet looks quite reasonable. Small individuals of species 8 initially feed entirely on the resource (plankton and other small things). From about the size of 1g (which is roughly 4-5 cm) they start eating larvae of other fish.\nThe diet composition we see in the plot is shaped by two things: the predation kernel (the size preference in the feeding of the predator) and the relative abundances of prey at different sizes. First, a predator will only eat food that is within the predation kernel size range. But once in this size range the relative proportion of different species or resource consumed will simply depend on their relative biomass. So if, for example, 80% of biomass in a specific prey size class consists of resource, 15% of species 1 and 5% of species 2, then the diet of the predator feeding in that size class will consist of 80% resource, 15% of species 1 and 5% of species 2.\nIn our example model, resource abundance at small size classes is very high compared to abundance of fish. So when a predator feeds in those size classes, naturally most of the diet will consist of resource. This is what we see in the diet plot.\nOf course, when we build a model for a real-world ecosystem we will have some knowledge about the biology of the species and their food preferences. Perhaps one species is actively selecting fish out of the resource, or predating on specific species only? This is where the interaction matrix comes in that we will discuss in the next section.\nNote, that it is very important to explore diets of species in your model, so, like the plotDeath() function, the plotDiet() function is very useful.\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nNow, check what the diets of other species look like. Start from species 1 (smallest one) and go all the way to species 11.\nWhich of the following statements is true in this trait-based model? (In the statements we refer to the species as “lower” or “higher” based on their number, i.e., species “3” we say is lower than species “4”.)\n\nAll species eat all other species.\nThe reason that the diet plot for higher species covers a larger interval on the x-axis is because higher species have a larger asymptotic size.\nSometimes the contribution of a prey species to the diet of a higher species increases with predator size and then decreases again. This is because as predators grow larger they prefer to eat larger prey.\nSometimes the contribution of a prey species to the diet of a higher species increases with predator size and then decreases again. This is because as predators grow larger they start eating species that are the most abundant.\nThroughout its lifetime even a predator from the higher species (species 8-10) feeds almost entirely on the resource.\nAll species are cannibalistic.\nLower species can eat higher species.\n\nYou will be prompted for your answer in the worksheet for this tutorial."
  },
  {
    "objectID": "understand/species-interactions.html#interaction-matrix",
    "href": "understand/species-interactions.html#interaction-matrix",
    "title": "Species interactions",
    "section": "Interaction matrix",
    "text": "Interaction matrix\nNow we arrive to an interesting and challenging aspects of multi-species modelling - setting up parameters for species and resource interactions. By default, mizer assumes that all species in the model can access all other species and resource equally and the amount of different prey consumed just depends on their relative abundance in the predator’s feeding size range. So the default interaction matrix of the species in our model looks very simple\n\ngetInteraction(mp)\n\n        prey\npredator 1 2 3 4 5 6 7 8 9 10 11\n      1  1 1 1 1 1 1 1 1 1  1  1\n      2  1 1 1 1 1 1 1 1 1  1  1\n      3  1 1 1 1 1 1 1 1 1  1  1\n      4  1 1 1 1 1 1 1 1 1  1  1\n      5  1 1 1 1 1 1 1 1 1  1  1\n      6  1 1 1 1 1 1 1 1 1  1  1\n      7  1 1 1 1 1 1 1 1 1  1  1\n      8  1 1 1 1 1 1 1 1 1  1  1\n      9  1 1 1 1 1 1 1 1 1  1  1\n      10 1 1 1 1 1 1 1 1 1  1  1\n      11 1 1 1 1 1 1 1 1 1  1  1\n\n\nThe matrix has all values set at 1 and shows that all predators can access all prey species with the same probability.\nIn reality we might have some knowledge about predators’ diet preferences, or about prey vulnerability to predation. This knowledge should be incorporated in the interaction matrix. Perhaps we know that some predators cannot or do not eat certain prey. For example some species in our system might only feed on resource and never ever eat any fish. In this case we will set all values in the row for that predator equal to 0. Alternatively, we might know that some prey is less available to predation due to some anti-predation behaviour or defence mechanisms. In this case we would decrease all values in the prey column to something < 1.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nIt is important to note that you should not set an entry in the interaction matrix to 0 just because a particular prey is never recorded in the stomach of a predator. It may well be that the predator species consumes the larvae of the prey species at some stage of their life and these larvae are simply not recorded in the stomach content.\n\n\n\nSometimes the interaction matrix is used to encode spatial overlap of species in a large ecosystem, as in this application of mizer to the North Sea. In this case the interaction matrix might be estimated from spatial surveys assessing species spatial overlap. The interaction matrix can encode lots of effects.\nSo let’s go ahead and change one value in the interaction matrix.\n\n# We get the interaction matrix and assign it to a variable.\ninteraction_modified <- getInteraction(mp)\n# We change row 11 (predator species 11) and column 2 (prey species 2) \n# to a smaller value\ninteraction_modified[11, 2] <- 0.2\n# and save the MizerParams object with the new interaction matrix \n# in a new variable\nmp_modified <- setInteraction(mp, interaction_modified)\n# check that it looks correct\ngetInteraction(mp_modified)\n\n        prey\npredator 1   2 3 4 5 6 7 8 9 10 11\n      1  1 1.0 1 1 1 1 1 1 1  1  1\n      2  1 1.0 1 1 1 1 1 1 1  1  1\n      3  1 1.0 1 1 1 1 1 1 1  1  1\n      4  1 1.0 1 1 1 1 1 1 1  1  1\n      5  1 1.0 1 1 1 1 1 1 1  1  1\n      6  1 1.0 1 1 1 1 1 1 1  1  1\n      7  1 1.0 1 1 1 1 1 1 1  1  1\n      8  1 1.0 1 1 1 1 1 1 1  1  1\n      9  1 1.0 1 1 1 1 1 1 1  1  1\n      10 1 1.0 1 1 1 1 1 1 1  1  1\n      11 1 0.2 1 1 1 1 1 1 1  1  1\n\n\nNow let’s compare the source of mortality for species 2 in the two models.\n\nplotDeath(mp, species = 2)\nplotDeath(mp_modified, species = 2)\n\n\n\n\n\nOriginal\n\n\n\n\n\n\nModified\n\n\n\n\n\n\nYou will see a reduction of the contribution of species 11 to the mortality of species 2.\nNext let us compare diets of species 11 in the two models.\n\nplotDiet(mp, species = 11)\nplotDiet(mp_modified, species = 11)\n\n\n\n\n\nOriginal\n\n\n\n\n\n\nModified\n\n\n\n\n\n\nYou will see a reduction in the contribution of species 2 to the diet of species 11. By setting the entry in row 11 and column 2 of the interaction matrix to 0.2 we simply reduced the availability of prey species 2 for predator species 11 by a factor of 5. The entries in the interaction matrix simply serve as multipliers on the available prey biomass.\nResource interactions\nThe interaction coefficients between the fish species as consumers and the resource as food, which one could have expected to find in an additional column in the interaction matrix, is instead saved as a species parameter.\n\nspecies_params(mp)$interaction_resource\n\n [1] 1 1 1 1 1 1 1 1 1 1 1\n\n\nWe see that the default value for all these interaction coefficients is also 1.\nNow we might want to reduce the availability of resource to some predators. Perhaps we know that certain species much prefer to feed on other fish rather than on similar sized plankton. Let us look at an example where species 8 through 11 have a 20% reduction in their interaction with resource.\n\n# We make a copy of the model\nmp_lessRes <- mp\n# and set the resource interaction to 0.8 for species 8 to 11\nspecies_params(mp_lessRes)$interaction_resource[8:11] <- 0.8\n# We print out the result to check\nspecies_params(mp_lessRes)$interaction_resource\n\n [1] 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.8 0.8 0.8 0.8\n\n\nNow we can look at the diet of for example species 9 and compare it with the previous model\n\nplotDiet(mp, species = 9)\nplotDiet(mp_lessRes, species = 9)\n\n\n\n\n\nOriginal\n\n\n\n\n\n\nModified\n\n\n\n\n\n\nThe change seems small enough. However, now that we changed the availability of resources, which is so important for larval stages, these four species will experience a much reduced growth rate during their juvenile stage. We can see that effect by recalculating the single-species spectra with\n\nmp_lessRes_sss <- singleSpeciesSteady(mp_lessRes)\n\nand then ploting the spectra\n\nplotSpectra(mp_lessRes_sss, power = 2)\n\n\n\n\nWe can see the drastic reduction in the abundances of species 8 to 11.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nIt is very important to understand that the above picture does not represent what will actually happen in the multi-species model. The above picture represents single-species thinking. We changed something for species 8 to 11 and then calculated the effect that change has on those species assuming they stayed in the same environment with the same prey and predator abundances. But of course the rest of the ecosystem will react, as we will now investigate."
  },
  {
    "objectID": "understand/species-interactions.html#trophic-cascades",
    "href": "understand/species-interactions.html#trophic-cascades",
    "title": "Species interactions",
    "section": "Trophic cascades",
    "text": "Trophic cascades\nAs we just discussed, the above picture does does not show a steady state of the ecosystem. Species now find themselves with a different abundance of predators and prey and this will change their mortality and their growth and hence their size spectra.\nThe easiest way to find the new steady state that the ecosystem will settle into is to simulate the full multi-species dynamics forward in time. Mizer refers to this simulation to find the future state of the ecosystem as “projecting”. We can use the function projectToSteady() to project forward in time far enough so the system has settled down again close to the new steady state.\n\nmp_lessRes_steady <- projectToSteady(mp_lessRes)\n\nConvergence was achieved in 24 years.\n\n\n\nplotSpectra2(mp_lessRes_steady, name1 = \"less resource\", \n             mp, name2 = \"original\", \n             total = TRUE, power = 2, ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\nThere is much to see in this graph. We can see how the reduction in the abundance of large individuals leads to undulations in fish and resource size spectra, compared to the original model.\nPerhaps you would prefer to plot the above graph with power = 1, which will show the biomass density in weight instead of the Sheldon spectrum. Different people find different options more intuitive.\n\nplotSpectra2(mp_lessRes_steady, name1 = \"less resource\", \n             mp, name2 = \"original\", \n             total = TRUE, power = 1, ylim = c(1e-8, NA), wlim = c(1e-3, NA))\n\n\n\n\nFishing-induced cascades\nLet’s investigates these trophic cascades a bit more. This time we can look at how fishing large fish will affect the ecosystem.\nThe model has been set up with a knife-edge fishing gear that selects all individuals above 1kg, irrespective of species. To use that gear we just have to set a non-zero fishing effort. We create a new model mp_fishing with a very high fishing effort of 2 (note that in fishing mortality values in mizer are not the same as fishing mortality values in age-based or similar stock assessment models, but this is a separate topic).\n\nmp_fishing <- mp\ninitial_effort(mp_fishing) <- 2\n\nWe can plot the resulting fishing mortality:\n\nplotFMort(mp_fishing)\n\n\n\n\nThis is not a realistic gear and mizer can do much better, as we will see in week 3. But it serves our current purpose, because it will impose a fishing mortality that only impacts the larger species that actually grow to sizes above 1kg. As we did in the section on fishing mortality in the previous tutorial, we can visualise the direct effect that this fishing mortality has on individual species:\n\nmp_fishing_sss <- singleSpeciesSteady(mp_fishing)\nplotSpectra(mp_fishing_sss, power = 2)\n\n\n\n\nAs expected, the largest species have their abundances reduced above 1kg if they are fished, and if they continue to encounter the same amount of prey and are exposed to the same amount of predation mortality.\nAgain the important point is that the above picture does does not show a steady state of the ecosystem.\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nProject the mp_fishing model to its steady state and then make a plot comparing it to the steady state of the un-fished system. By looking at the resulting graph, determine which of the following statements is true.\n\nFishing strongly reduces abundances of fish above 1 kg of weight.\nAdult (after maturation size) abundance of intermediate fish (species 5-8) increases due to fishing.\nIn fact, adult abundances of all fish lower than 9 increases due to fishing.\nEntire community size spectrum is severely truncated above 1kg fish size - all due to fishing.\nIf adult biomasses for some species increase due to fishing, then for the same species larval biomasses (below the size of 1 g) will decrease.\nFishing does not only create undulations and trophic cascades in the individual fish spectra, but also in the total community spectrum.\n\nYou will be prompted for your answer in the worksheet for this tutorial."
  },
  {
    "objectID": "understand/species-interactions.html#summary-and-recap",
    "href": "understand/species-interactions.html#summary-and-recap",
    "title": "Species interactions",
    "section": "Summary and recap",
    "text": "Summary and recap\n\nWhen using mizer models it is very important to investigate who eats whom and where mortality comes from. We do this with the functions plotDeath() and plotDiet().\nThe contribution of different species to the diet of a predator depends on the abundances of the species in the size range preferred by the predator.\nThe species interaction matrix defines availability of each species to predation by other species. By changing the interaction matrix we can make our models more realistic and more complex.\nTrophic cascades are one of the coolest things in multi-species models and the reason we build these models. We want to understand how changes in one species and its sizes will affect the ecosystem and, in turn, the same species. Mizer has many ways how we can explore such trophic cascades."
  },
  {
    "objectID": "understand/single-species-spectra.html",
    "href": "understand/single-species-spectra.html",
    "title": "Single species spectra",
    "section": "",
    "text": "At the end of the previous tutorial we plotted single-species size spectra from our dataset and observed that they were a bit of a mess. In this tutorial we will use the mizer model to gain an understanding of what determines the shape of a species size spectrum.\nIn this tutorial you are also going to start using mizer functions. When you want to learn more about any of the functions that we use in the examples, simply click on the function name. This will open the function’s help page in a new browser window.\nFirst, load some required packages with the following commands:\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")\nlibrary(mizerExperimental)\nlibrary(tidyverse)\n\nNote how for the mizerExperimental package we also call remotes::install_github(). This will reinstall the package only if it has changed on GitHub since you last installed it. If nothing has changed, the command will just issue a message to reassure you of that fact. So for packages that improve as frequently as mizerExperimental, it is always a good idea to call remotes::install_github() frequently.\nYou will be doing your own work for this tutorial in the accompanying worksheet file “worksheet2-single-species-spectra.Rmd”. You will find this file in the worksheet repository for this week that you already used during the previous tutorial."
  },
  {
    "objectID": "understand/single-species-spectra.html#single-species-model",
    "href": "understand/single-species-spectra.html#single-species-model",
    "title": "Single species spectra",
    "section": "Single-species model",
    "text": "Single-species model\nIn this and the next tutorial we want to keep the size-spectrum aspects of the mizer model separate from the multi-species aspects, in order to not have to think about too many things at once. So we will explore a model where a single species lives in a non-dynamical background community that we will set to a Sheldon power-law abundance. Only in the fourth tutorial of this week exploring species interactions will we start to consider the interesting multi-species phenomena that arise in mizer models.\nIn this tutorial we will only be interested in the shape of the size spectrum, i.e., in how the total number of individuals is distributed over the different sizes. We are not yet interested in the overall abundance of the species. The overall abundance would be influenced by the total rate of reproduction and recruitment for the species. This in turn would be influenced by the size spectrum, because that determines how many of the individuals are mature. This dynamic feedback will of course become important when we build real-world models in week 2 and use them in week 3. But for now we have enough on our plate without thinking also about this.\nMizer collects all the parameters describing a size-spectrum model into one object of class MizerParams. You do not need to set up this object by hand because there are several wrapper functions in mizer that create the object for you for various types of models, and also many functions for changing specific parameters in a model. We will use the newSingleSpeciesParams() function to set up a model describing a single fish species living in an ecosystem whose community size spectrum is given by a power-law.\nThe newSingleSpeciesParams() function has many arguments that allow you to specify parameters for the fish species as well as for the community, but all these arguments have default values, so we can simply call the function without specifying those arguments. We will only specify the power-law exponent lambda of the background community. Note that in mizer the size spectrum exponent refers to the number density and is therefore expected to be around 2.\n\nparams <- newSingleSpeciesParams(lambda = 2.05)\n\nThe function returns a MizerParams object and we have assigned that to the variable params. We will be explaining more about this model as we go along."
  },
  {
    "objectID": "understand/single-species-spectra.html#steady-state-spectrum",
    "href": "understand/single-species-spectra.html#steady-state-spectrum",
    "title": "Single species spectra",
    "section": "Steady state spectrum",
    "text": "Steady state spectrum\nAs a final simplification in this and the next two tutorials, we will only consider the steady state size spectra. The steady state is the state where in each size class the inflow of individuals through growth exactly balances the outflow of individuals through growth and death. This means that the size spectrum is in equilibrium. You might have heard that models are often “initialised” from some initial species abundances and then ran to equilibrium until species biomasses and size distributions stop changing. However, we can calculate what sort of initial abundance we need to ensure that a species is in an equilibrium and this is what mizer does. The initial size spectra in the params object that we created with newSingleSpeciesParams() have already been set to the steady state size spectra.\nWe can plot the size spectrum with the plotSpectra() function.\n\nplotSpectra(params, power = 0)\n\n\n\n\nThe power = 0 argument to the plotSpectra() function specifies that we want to plot the number density, rather than for example the biomass density. We’ll discuss this more below in the section on other representations.\nThe green line represents the number density of the background community, labelled as “Resource” in the plot legend, in which our foreground species finds itself. The green line is a straight line with slope lambda = -2.05. Thus the number density of the background community is proportional to w^{-2.05}. It is important to understand that a power-law curve looks like a straight line when plotted on logarithmic axes and the slope of the line is the exponent in the power law. If this does not sound familiar, please revisit the section in the previous tutorial where we fitted a power-law to the community spectrum.\nThe other line represents the number density of our single species, which by default is just named unimaginatively “Target species”. We see that it is a straight line initially, but then has a bump before declining rapidly at large sizes. We will discuss in a short while what causes that shape.\nRemember what these size spectra plots indicate? They show the number density of individuals as a function of size. The initial slope of the target species’ number density is negative, which vaguely means that there are fewer larger fish than smaller fish. That is of course understandable: lots of fish die while they are growing up, so there tend to be fewer fish in larger size classes.\nIt is now time to do the first exercise of this tutorial. To complete the exercise, go to your copy of this week’s worksheet repository and open the file “worksheet2-single-species-spectra.Rmd” in RStudio. There you will find the following first exercise:\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nCreate a MizerParams object describing a single species in a power-law background where the Sheldon exponent is 2.1. Then plot the number density as a function of weight."
  },
  {
    "objectID": "understand/single-species-spectra.html#numbers",
    "href": "understand/single-species-spectra.html#numbers",
    "title": "Single species spectra",
    "section": "Numbers",
    "text": "Numbers\nWhile the plotSpectra() function gives us a plot of the number density, it would be nice if we could get at the actual numerical values. We can access them with the initialN() function. Let us assign this to a variable n:\n\nn <- initialN(params)\n\nAs you can see in the “Environment” pane in RStudio, n is a matrix with 1 row and 101 columns.\n\nThe one row corresponds to the one species. In a multispecies model there would be one row for each species, holding the number density for that species. The 101 columns are for the number densities in each of the 101 size classes. By default mizer uses 100+1 size clases (or size bins), although you can easily change that. In fact, n is a named array, i.e., each row and each column has names. These we can extract with the dimnames() function.\n\ndimnames(n)\n\n$sp\n[1] \"Target species\"\n\n$w\n  [1] \"0.001\"   \"0.00112\" \"0.00126\" \"0.00141\" \"0.00158\" \"0.00178\" \"0.002\"  \n  [8] \"0.00224\" \"0.00251\" \"0.00282\" \"0.00316\" \"0.00355\" \"0.00398\" \"0.00447\"\n [15] \"0.00501\" \"0.00562\" \"0.00631\" \"0.00708\" \"0.00794\" \"0.00891\" \"0.01\"   \n [22] \"0.0112\"  \"0.0126\"  \"0.0141\"  \"0.0158\"  \"0.0178\"  \"0.02\"    \"0.0224\" \n [29] \"0.0251\"  \"0.0282\"  \"0.0316\"  \"0.0355\"  \"0.0398\"  \"0.0447\"  \"0.0501\" \n [36] \"0.0562\"  \"0.0631\"  \"0.0708\"  \"0.0794\"  \"0.0891\"  \"0.1\"     \"0.112\"  \n [43] \"0.126\"   \"0.141\"   \"0.158\"   \"0.178\"   \"0.2\"     \"0.224\"   \"0.251\"  \n [50] \"0.282\"   \"0.316\"   \"0.355\"   \"0.398\"   \"0.447\"   \"0.501\"   \"0.562\"  \n [57] \"0.631\"   \"0.708\"   \"0.794\"   \"0.891\"   \"1\"       \"1.12\"    \"1.26\"   \n [64] \"1.41\"    \"1.58\"    \"1.78\"    \"2\"       \"2.24\"    \"2.51\"    \"2.82\"   \n [71] \"3.16\"    \"3.55\"    \"3.98\"    \"4.47\"    \"5.01\"    \"5.62\"    \"6.31\"   \n [78] \"7.08\"    \"7.94\"    \"8.91\"    \"10\"      \"11.2\"    \"12.6\"    \"14.1\"   \n [85] \"15.8\"    \"17.8\"    \"20\"      \"22.4\"    \"25.1\"    \"28.2\"    \"31.6\"   \n [92] \"35.5\"    \"39.8\"    \"44.7\"    \"50.1\"    \"56.2\"    \"63.1\"    \"70.8\"   \n [99] \"79.4\"    \"89.1\"    \"100\"    \n\n\nThe names of the columns are the weight in grams at the start of each size class. Notice how R displays long vectors by breaking them across many lines and starting each line with a number in brackets. That number is the index of the first value in that row. So for example we see that the 61st size class starts at 1 gram. The number density in the size class between 1 gram and 1.12 grams (the start of the next size class) is\n\nn[1, 61]\n\n[1] 0.0003282314\n\n\nIt is important to realise that this is not the number of fish in the size class, but the average number density in the size class. To get the number of fish we have to multiply the number density by the width of the size class. Those widths can be obtained with the dw() function. So the number of fish in each size class is obtained with\n\nnumbers <- n * dw(params)\n\nThe number of individuals in the size class between 1 gram and 1.12 grams is\n\nnumbers[1, 61]\n\n[1] 4.005029e-05\n\n\nYou may be surprised by the small number if you interpret it as the number of fish between 1 gram and 1.12 gram in the entire ocean. However it looks more reasonable if it is the average number per square meter of sea. For more of a discussion of this issue of working with numbers per area, numbers per volume or numbers for the entire system see https://sizespectrum.org/mizer/reference/setParams.html#units-in-mizer\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nDetermine the total number of fish in the model with sizes between 10 grams and 20 grams. You can use the sum() function to add together contributions from the various size classes.\n\n\n\nAgain, you should complete this exercise in the worksheet in which you already completed exercise 1."
  },
  {
    "objectID": "understand/single-species-spectra.html#other-representations",
    "href": "understand/single-species-spectra.html#other-representations",
    "title": "Single species spectra",
    "section": "Other representations",
    "text": "Other representations\nWe have seen in the previous tutorial on observed size spectra that the size spectrum can be represented in various ways. Besides the number density N(w) we introduced the biomass density B(w), the number density in log weight N_{\\log}(w) and the biomass density in log weight B_{\\log}(w). These were related to each other by multiplication by different powers of w:\nB(w) = N_{\\log}(w) = w N(w) \\text{ and } B_{\\log}(w) = w^2 N(w).\nWe can use the power argument of the plotSpectra() function to determine which of these densities to plot. Above we plotted the number density by setting power = 0. Without the power argument (or with power = 1 which is the default) the plotSpectra() function plots the biomass density as a function of weight, which is also the number density as a function of log weight:\n\nplotSpectra(params)\n\n\n\n\nNow the green line representing the biomass density of the background has a slope of -1.05 and not the -2.05 number density slope that we actually set when creating the params object.\nThe initial slope of the species biomass density is also negative, meaning that the biomass density in the species decreases with size.\nWe can also plot the biomass density in log weight, i.e., the Sheldon spectrum, by supplying the argument power = 2 to plotSpectra().\n\nplotSpectra(params, power = 2)\n\n\n\n\nThis now shows an approximately constant background biomass density in log weight (the slope of the green line is -0.05). The biomass density of the species in log size initially increases. So if binned in logarithmically-sized bins the biomass in each bin will initially increase, until it starts decreasing close to the maximum size of the species.\nThis latest plot seems to indicate that most of the biomass of the species is concentrated at larger sizes of around 30 grams, whereas the previous plot seemed to indicate that most of the biomass is at the smallest sizes. So which one is true? Please think about this question, because it really highlights the importance of not confusing biomass density with biomass. Questions about the amount of biomass at a size do not make sense. Instead you have to ask about biomass in a size range.\nSo for example, we might want to consider the prey biomass available to two different predators of our species, one small and one large. Assume that the smaller predator feeds on prey in the size range from 1g to 2g. The other predator, which we assume is 10 times larger, feeds on prey in the size range from 10g to 20g. These feeding intervals have the same width on the logarithmic weight axis. Therefore we should look at the plot of the biomass density in log weight to see that the larger predator has a lot more prey biomass from our species available to it than the smaller one. This is in spite of the fact that the plot of biomass density in weight tells us that the biomass density is lower at 10g than at 1g.\nIt may have been a bit confusing that we displayed the same size spectrum in three different ways. But it is important to be aware of this because in the literature you will see all different conventions being used, so if you see a plot of a size spectrum you always need to ask yourself exactly which density is being shown."
  },
  {
    "objectID": "understand/single-species-spectra.html#biomass",
    "href": "understand/single-species-spectra.html#biomass",
    "title": "Single species spectra",
    "section": "Biomass",
    "text": "Biomass\nAs we did for numbers above, let us also look at how to extract biomasses from the model.\nWe already said above that we can obtain the biomass density in a size class from the number density by multiplying the number density by the weight of the individuals in the size class. To obtain the appropriate weights, we use the function w() that returns the weights at the start of each size class. So we calculate\n\nbiomass_density <- n * w(params)\n\nWe obtain the total biomass in each size class by multiplying the biomass density in each size class by the width of each size class\n\nbiomass <- biomass_density * dw(params)\n\nFor example the biomass of fish between 1 gram and 1.12 grams is\n\nbiomass[61]\n\n[1] 4.005029e-05\n\n\nLet us briefly present yet another way to represent the size distribution. When we talk about size spectra, we always have the representation in terms of densities in mind. You may already be familiar with the concept of a densities from probability theory, where you can describe a probability distribution in terms of its probability density function. But perhaps you also know that there is an alternative description of the probability distribution in terms of the cumulative distribution function. We can similarly describe the size distribution of the biomass by a cumulative biomass distribution function, which gives the total biomass of all sizes up to a specific size.\n\n# Initialise an array with the right dimensions\ncumulative_biomass <- biomass\n# Calculate the cumulative sum of all biomasses in previous bins\ncumulative_biomass[] <- cumsum(biomass)\n# Normalise this so that it is given as a percentage of the total biomass\ncdf <- cumulative_biomass / cumulative_biomass[1, 101] * 100\n# Melt the array to a data frame and then plot\np_biomass_cdf <- ggplot(melt(cdf), aes(x = w, y = value)) +\n    geom_line() + \n    labs(x = \"Weight [g]\",\n         y = \"% of total biomass\")\np_biomass_cdf\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nMizer likes to work with arrays instead of data frames. Our variables n, biomass, cumulative_biomass and cdf are all arrays. I hope you noticed the magic how R can do calculations with all entries of an array in one go.\nggplot2 on the other hand likes to work with data frames instead of arrays. The function melt() allows us to convert the mizer arrays into data frames suitable for ggplot(). You will see this discussed again later.\n\n\n\nThis plot shows us for example that 50% of the individuals are smaller than 12.5g and only a very small percentage is larger than 75g.\nThe biomass density is the slope of this graph. We can also plot the cumulative biomass distribution function on a logarithmic weight axis:\n\np_biomass_cdf +\n    scale_x_log10()\n\n\n\n\nThis graph contains exactly the same information as the previous graph, just showing more detail at smaller sizes and less detail at larger sizes. We can see for example that about 20% of individuals are less than 1g, which was difficult to see in the previous graph. The slope of this graph is the biomass density in log weight."
  },
  {
    "objectID": "understand/single-species-spectra.html#allometric-rates",
    "href": "understand/single-species-spectra.html#allometric-rates",
    "title": "Single species spectra",
    "section": "Allometric rates",
    "text": "Allometric rates\nThe first striking feature of the species size-spectrum, independently of which density you plot, is that for small fish (larvae and juveniles) it is given by a straight line. This is due to the allometric scaling of the physiological rates that our model is assuming and which we will discuss in this section. The other striking feature is the bulge at around maturity size, which we will discuss in the section on the shape of the adult spectrum.\nWe will assume that the metabolic rate, i.e., the rate at which an organism expends energy on its basic metabolic needs, scales as a power of the organism’s body size, and the power is about p = 3/4.\nBecause this energy needs to be supplied by consumption of food, it is natural to assume that also the consumption rate scales allometrically with a power of n = 3/4. When the consumption is greater than the metabolic cost then the excess leads to growth. Hence the growth rate too scales allometrically with power 3/4.\nIn a multi-species mizer model the mortality is an emergent property that depends on the abundance of predators. In this single species model the mortality rate is set to the one that would emerge if all the species in the fixed background community predated with the same ferocity as the target species. This leads to a mortality rate that scale allometrically with a power of n - 1 = 3/4 - 1 = -1/4. This means that the death rate experienced by larger individuals is smaller than that of small individuals.\nIt is a result of the mathematics that if the growth and death rates scale allometrically with exponents p and 1-p respectively, for some metabolic exponent p, that the number density at steady state is also a power law, i.e., a straight line on the log-log plot.\nLet us check that in our model the physiological rates are indeed power laws, at least for the small sizes. We can get the growth rate with the getEGrowth() function. We assign the result to a variable that we name growth_rate.\n\ngrowth_rate <- getEGrowth(params)\n\nYou can again see in the “Environment” pane that this is a matrix with one row for the one species and 101 columns for the 101 size classes. So for example the growth rate at size 1 gram is\n\ngrowth_rate[1, 61]\n\n[1] 8.26968\n\n\n(because we had seen that the 61st size class starts at 1 gram). This is the instantaneous per-capita growth rate, measured in grams per year. Note that in mizer all rates are measured in units of 1/year, but for many people daily values are easier to understand. Since growth rate here is an instantaneous rate we can simply divide it by 365 to get a daily rate (although note that mizer does not simulate processes on daily time steps). This gives us a growth rate in grams per day for a 1g sized fish of\n\ngrowth_rate[1, 61] / 365\n\n[1] 0.02265666\n\n\nWe would like to make a log-log plot of the growth rate against size to check that it gives a straight line. We will use ggplot() for that purpose. ggplot() likes to work with data frames instead of named matrices, so we first convert the matrix into a data frame with the melt() function.\n\ngrowth_rate_frame <- melt(growth_rate)\n\nYou can see in the “Environment” pane that the new variable that we called growth_rate_frame is a data frame with 101 observations of 3 variables. The 101 observations correspond to the 101 size classes. The 3 variables have names\n\nnames(growth_rate_frame)\n\n[1] \"sp\"    \"w\"     \"value\"\n\n\nThey are the species sp, the size w, and the value which contains the growth_rate. This data frame we can pass to ggplot().\n\np <- ggplot(growth_rate_frame) +\n    geom_line(aes(x = w, y = value)) +\n    scale_x_log10(name = \"Weight [g]\") +\n    scale_y_log10(name = \"Growth rate [g/year]\")\np\n\n\n\n\nNote how we linked the x axis to the w variable and the y axis to the value variable and specified that both axes should be on a logarithmic scale.\nWe see that at least up to a size of a few grams the line is straight. Let’s isolate the growth rate for those smaller sizes\n\ng_small_fish <- filter(growth_rate_frame, w <= 10)\n\nand fit a linear model\n\nlm(log(g_small_fish$value) ~ log(g_small_fish$w))\n\n\nCall:\nlm(formula = log(g_small_fish$value) ~ log(g_small_fish$w))\n\nCoefficients:\n        (Intercept)  log(g_small_fish$w)  \n              2.113                0.750  \n\n\nThe slope of the line is indeed 0.75 = 3/4. In fact, the above shows that for juveniles \\log(g(w)) \\approx 2.113 + \\frac34 \\log(w) and thus g(w) = g_0\\ w^p \\approx \\exp(2.113)\\  w^{3/4}\\approx 8.27\\  w^{3/4}.\nOf course in a real model, the growth rate would not so exactly follow a power law, because growth rate would vary depending on food availability, for example. In this example food is the background resource and its abundance is fixed, so food abundance does not vary.\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\nUse the methods you have just seen to make a log-log plot of the mortality rate. You can get the mortality rate with the getMort() function. While adjusting the code to this new task, you need to take into account that the name of the size-dimension of the array returned by getMort() is \"w_prey\" instead of \"w\".\nThen fit a linear model to determine the slope and and intercept and thus the allometric exponent r and the coefficient \\mu_0 for the mortality rate \\mu(w) = \\mu_0 w^r."
  },
  {
    "objectID": "understand/single-species-spectra.html#slope-of-juvenile-spectrum",
    "href": "understand/single-species-spectra.html#slope-of-juvenile-spectrum",
    "title": "Single species spectra",
    "section": "Slope of juvenile spectrum",
    "text": "Slope of juvenile spectrum\nWe have seen that for juvenile fish the growth rate and the death rate are both power laws with exponents p=3/4 and r=p-1=-1/4 respectively. By solving a differential equation we can derive that the juvenile spectrum also follows a power law: N(w) = N_0\\ w^{-\\mu_0/g_0 - p}.\nI won’t do the maths here with you (and you probably don’t want me to anyway), but we can see that the result makes sense. It tells us that the number density drops of faster with size if the mortality rate coefficient \\mu_0 is higher or if the growth rate coefficient g_0 is smaller, which is what we would expect.\nWe can also check this claim numerically. Let’s look at the spectrum of individuals up to 10 grams. By now we know how to do this. We first convert the number density matrix n into a dataframe and then filter out all observations that do not have w\\leq 10. The resulting data frame we pass to ggplot() and ask it to plot a line on log-log axes.\n\nnf <- melt(n) %>% \n  filter(w <= 10)\n\nggplot(nf) +\n  geom_line(aes(x = w, y = value)) +\n  scale_x_log10(name = \"Weight [g]\") +\n  scale_y_log10(name = \"Number density [1/g]\")\n\n\n\n\nThat confirms what we had seen earlier, that for fish less than 10 grams the number density is a power law. To determine the exponent of the power law we need the slope of that straight line in the log-log plot, and the easiest way to do that is to fit a linear model to the log variables:\n\nlm(log(nf$value) ~ log(nf$w))\n\n\nCall:\nlm(formula = log(nf$value) ~ log(nf$w))\n\nCoefficients:\n(Intercept)    log(nf$w)  \n     -8.022       -1.682  \n\n\nThe linear model fit says that the exponent is -1.682. The mathematics claimed that the exponent should be -\\mu_0 / g_0 - p. We have already observed that g_0 \\approx 8.27 and you have determined \\mu_0 in Exercise 3, so we get\n\n-m0 / g0 - 3/4\n\n[1] -1.6777\n\n\nThat is not quite the result of the linear model fit, but that is the nature of numerical calculations: one gets discretisation errors and rounding errors. Anyway it is close enough. And it is also amazing how we can calculate expected numbers of fish from basic assumptions and rules. Of course natural ecosystems never look like that, but if we have theoretical expectations derived from clear assumptions (about growth and mortality rate and food availability), we can start asking questions about which processes in natural ecosystems deviate from these generic assumptions, why this happens and how it should affect the observed size spectra."
  },
  {
    "objectID": "understand/single-species-spectra.html#shape-of-adult-spectrum",
    "href": "understand/single-species-spectra.html#shape-of-adult-spectrum",
    "title": "Single species spectra",
    "section": "Shape of adult spectrum",
    "text": "Shape of adult spectrum\nNow that we understand the shape of the size spectrum for the juvenile fish, let us try to understand the shape of the adult spectrum. Here is the plot of the biomass density again, but with the w axis restricted to weights above 10g:\n\nplotSpectra(params, wlim = c(10, NA))\n\n\n\n\nThe increase of abundance that we see at around the maturity size of our species is due to a drop in growth rate at that size. This in turn is due to the fact that the mature fish invests some of its energy into reproduction. So the details of the shape of the adult spectrum will be influenced both by food intake, maintenance and mortality (like in juveniles), but also by how adults split their energy income between growth and reproduction.\nInvestment into reproduction\nLet us look at a plot of the proportion of the available energy that is invested into reproduction as a function of the size. This is the product of the proportion of individuals that are mature (obtained with the function maturity() and the proportion of their energy income that a mature fish invests into reproduction (obtained with the function repro_prop().\n\nreprod_proportion <- maturity(params) * repro_prop(params)\n# Convert the array to a data frame for ggplot\npsi <- melt(reprod_proportion)\n\np <- ggplot(psi) +\n    geom_line(aes(x = w, y = value)) +\n    labs(x = \"Weight [g]\",\n         y = \"Proportion invested into reproduction\")\np\n\n\n\n\nHow was this maturity curve specified? You can find the details in the mizer documentation. There are four species parameters involved:\n\nthe maturity size w_mat at which 50% of the individuals are mature.\nthe size w_mat25 at which 25% of the individuals are mature.\nthe asymptotic size w_inf at which an organism invests 100% of its income into reproduction and thus growth is zero.\nan exponent m that determines how the proportion that an individual invests into reproduction scales with its size.\n\nSuch species parameters are contained in a data frame inside the params object that we can access with the species_params() function.\n\nspecies_params(params)\n\n\n\n  \n\n\n\nAs you can see, there are a lot of other species parameters, some of which we will talk about later. For now let’s just select the 4 parameters we are interested in.\n\nselect(species_params(params), w_mat, w_mat25, w_inf, m)\n\n\n\n  \n\n\n\nAnd with this knowledge of parameter we can improve the plot for clarity and add a vertical line at 25% and 50% maturation weight\n\nmaturation_weight50 <- species_params(params)$w_mat\nmaturation_weight25 <- species_params(params)$w_mat25\n\np + geom_vline(xintercept = maturation_weight50, lty = 2) +\n    geom_vline(xintercept = maturation_weight25, lty = 2, col = \"grey\")\n\n\n\n\nChange in maturity curve\nLet us investigate what happens when we change the maturity curve. Let’s assume the maturity size is actually 40 grams and the size at which 25% of individuals is mature is 30 grams. Let us change the values in the species_params data frame. But first we make a copy of the params object so that we can keep the old version around unchanged.\n\nparams_changed_maturity <- params\n\nIn this copy we now change the species parameters\n\nspecies_params(params_changed_maturity)$w_mat <- 40\nspecies_params(params_changed_maturity)$w_mat25 <- 30\nselect(species_params(params_changed_maturity), w_mat, w_mat25, w_inf, m)\n\n\n\n  \n\n\n\nNow the maturity curve has changed, which we can verify by plotting it\n\npsi_changed_maturity <- melt(maturity(params_changed_maturity) * \n                                 repro_prop(params_changed_maturity))\n\nggplot(psi_changed_maturity) +\n    geom_line(aes(x = w, y = value)) +\n    geom_vline(xintercept = species_params(params_changed_maturity)$w_mat, \n               lty = 2) +\n    geom_vline(xintercept = species_params(params_changed_maturity)$w_mat25, \n               lty = 2, col = \"grey\") + \n    labs(x = \"Weight [g]\",\n         y = \"Proportion invested into reproduction\")\n\n\n\n\nTwo curves in one plot\nAt this point let’s take a little break and learn how to draw two curves in the same graph. How can we see the old maturity curve and the new maturity curve in the same plot? First we add an extra column to each dataframe describing it\n\npsi$type <- \"original\"\npsi_changed_maturity$type <- \"changed\"\n\nThen we bind the two data frames together\n\npsi_combined <- rbind(psi, psi_changed_maturity)\n\nand send that combined data frame first to ggplot(). We also run the plot through plotly::ggplotly() to make it interactive, but that is of course entirely optional.\n\np <- ggplot(psi_combined) +\n    geom_line(aes(x = w, y = value, colour = type)) +\n    labs(x = \"Weight [g]\",\n         y = \"Proportion invested into reproduction\")\nplotly::ggplotly(p)\n\n\n\n\n\nThis change in the maturity curve of course implies a change in the growth rates.\n\n\n\n\n\n\nExercise 4\n\n\n\n\n\nMake a plot showing the growth rates of the original model and of the model with the changed maturity curve.\n\n\n\nEffect of changed maturity\nNext let us look at how the change in the maturity parameters and the resulting change in the growth rate affects the steady state spectrum. First we need to calculate the new steady state using the function singleSpeciesSteady().\n\nparams_changed_maturity <- singleSpeciesSteady(params_changed_maturity)\n\nThen we can use the function plotSpectra2() to plot the old size spectrum and the new size spectrum on the same graph.\n\nplotSpectra2(params, name1 = \"Early maturity\",\n             params_changed_maturity, name2 = \"Late maturity\",\n             power = 2, resource = FALSE, wlim = c(10, NA))\n\n\n\n\nAs expected, the bump happens later due to the larger maturity size and it is less steep, because the maturity curve is less steep. This means that fish do not suddenly start investing most of their energy into reproduction, but still keep growing while they are maturity. Since they are still growing they will be moving from one size class to another and fewer individuals will accumulate in one size class.\nThis was our first investigation of how the shape of a species size spectrum changes as model parameters are changed. We will do much more in this direction in the next tutorial in which we discuss how growth and mortality are determined through predation."
  },
  {
    "objectID": "understand/single-species-spectra.html#summary-and-recap",
    "href": "understand/single-species-spectra.html#summary-and-recap",
    "title": "Single species spectra",
    "section": "Summary and recap",
    "text": "Summary and recap\n1) The steady state is the state where the system has reached an equilibrium in which the rate at which individuals grow into each size class is equal to the rate at which individuals either grow out of the size class or die in the size class.\n2) Mizer stores the size spectrum in the form of the number density in size classes. To get the numbers in a size class we need to multiply the number density by the width of the size class (dw). To get total biomass in each size class we further multiple this value by the weight of this size class (w).\n3) Allometric scaling of physiological rates with size plays a big role in a mizer model and shapes the size spectrum.\n4) We studied a single species living in a fixed background community with a power-law spectrum. In this simple case we can determine the steady state spectrum and find that the juvenile spectrum is given by a power law whose exponent is determined by the ratio of mortality to growth and is different from the community spectrum power law.\n5) As fish mature they start investing some of their energy into reproduction and hence their growth slows. This leads to a bump in the size spectrum. We saw how changes in the parameters describing the maturity ogive change the shape of that bump."
  },
  {
    "objectID": "understand/predation-growth-and-mortality.html",
    "href": "understand/predation-growth-and-mortality.html",
    "title": "Predation, growth and mortality",
    "section": "",
    "text": "It is now time to discuss the important issue of predation. It is through predation that a fish obtains the energy it needs to maintain its metabolism, to grow and to invest in reproduction. But also a large proportion of the natural mortality of fish comes from predation by their predators. So it is important how mizer models predation. While you can also read about the details in the description of the general mizer size-spectrum model, in this tutorial we will approach the topic in a more hands-on experimental fashion, using the mizer package itself to help us build intuition.\nAs in the previous tutorials, we load the mizerExperimental and tidyverse packages and create a single-species model with a power-law background with exponent -2.05.\nYou will be doing your own work for this tutorial in the accompanying worksheet file “worksheet3-predation-growth-and-mortality.Rmd”. You will find this file in the worksheet repository for this week that you already used in previous tutorials."
  },
  {
    "objectID": "understand/predation-growth-and-mortality.html#growth",
    "href": "understand/predation-growth-and-mortality.html#growth",
    "title": "Predation, growth and mortality",
    "section": "Growth",
    "text": "Growth\nEffect of prey availability\nThe energy income for a fish comes from predation on its prey. If there is less prey, the fish consumes less and its growth rate will decrease. Let us investigate this by artificially removing some prey. Because in our simple single-species model we work with a fixed community spectrum that is under our control, we can do that.\nBelow we decrease the community spectrum by a factor of 10 in the size range from 1mg to 10mg.\n\n# Create a new parameter object to be able to keep the old one around unchanged.\nparams_starved <- params\n\n# Create logical vector identifying the size bins we want to change. \n# Here w_full is a mizer vector for all size bins including community and \n# modelled species\nsize_range <- w_full(params) > 10^-3 & w_full(params) < 10^-2\n\n# Divide the abundances in those size bins by 10\ninitialNResource(params_starved)[size_range] <- \n    initialNResource(params)[size_range] / 10\n\nLet’s make a plot to check that this did what we intended:\n\n# The `species = FALSE` means that we will only plot the background\nplotSpectra(params_starved, power = 2, species = FALSE)\n\n\n\n\nThe plot shows the big drop in the background abundance in our selected size range. This reduced availability of prey in that size range will lead to a drop in the growth rate in the fish that feed in that size range. We can see the slow-down in growth by comparing the growth rates in the original model and the new model. We will use the method that we saw at the end of the previous tutorial in the section “Two curves in one plot”.\n\ngf_original <- melt(getEGrowth(params))\ngf_original$Model <- \"Original\"\ngf_starved <- melt(getEGrowth(params_starved))\ngf_starved$Model <- \"Reduced prey\"\ngf <- rbind(gf_original, gf_starved)\ngrowth_rates_plot <- ggplot(gf, aes(x = w, y = value, linetype = Model)) +\n    geom_line() +\n    scale_x_log10(\"Weight [g]\") +\n    scale_y_log10(\"Growth rate [g/year]\")\ngrowth_rates_plot\n\n\n\n\nThe slow-down occurs at a size that is about a factor of 100 larger than the size at which food is reduced. Why this is we will discuss in the next section.\nThe dip in the growth rate may not seem very significant in the above plot, but it has a dramatic effect on the steady state size distribution of our species. We know from the previous tutorial that we can set the abundances in the single-species model to the steady state value with\n\nparams_starved <- singleSpeciesSteady(params_starved)\n\nWe can now visualise the difference in the size spectra with the plotSpectra2() function:\n\nspectra_plot <- plotSpectra2(params, name1 = \"Original\",\n                             params_starved, name2 = \"Reduced prey\",\n                             power = 2)\nspectra_plot\n\n\n\n\nThe lack of food and the resulting slow-down in growth leads to a traffic jam: a peak in the biomass density and then low density on the other side of the traffic jam. Because fish do not get enough food and do not grow into the next size class, they are stuck in smaller size classes for a long time and are affected by mortality, which is higher for small size classes.\nOne may think that the drop in abundance is at sizes where the predator encounters fewer prey than before and thus has lower growth rate. This is what classic predator-prey thinking would suggest: low prey abundance leads to low predator abundance. Size spectrum dynamics is different. To drive this point home we will display the growth rate plots and the spectrum plots directly above each other\n\n\n\ngrowth_rates_plot\nspectra_plot\n\n\n\n\n\n\n\n\n\nWe see that where the growth starts slowing down, the abundance actually increases. This is because a decrease in the growth rate leads to a pile-up of individuals. You know this phenomenon from traffic jams. Where the speed of the cars decreases on a motorway, their density increases. Then when the speed increases again on the other side of the traffic jam, the density of cars drops and you wonder what caused the traffic jam in the first place. We see the same phenomenon in size spectrum dynamics. We see from the graphs above: it is where the growth rate starts growing faster again that the density goes down.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThe above shows that size spectrum dynamics is very different from predator-prey dynamics.\n\n\n\nThe reduction of prey has led to a significant reduction in the overall abundance of the species. This is in spite of the fact that we have kept the abundance constant at the lowest size, i.e. we assumed that recruitment of new fish is not affected by what happens in larger size classes. In reality, the drastic reduction of spawning stock biomass will lead to a reduction in the number of eggs as well, so the effect will be even more dramatic.\nHere we hand over to you to investigate what happens when the prey abundance is increased instead of decreased. Please open the worksheet named “worksheet3-predation-growth-and-mortality.Rmd” in your worksheet repository, where you will find the following exercise:\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nMake a single plot, similar to the one above, comparing the steady state biomass density in log weight in the original model with that when the community abundance is increased by a factor of 10 in the size range from 1mg to 10mg."
  },
  {
    "objectID": "understand/predation-growth-and-mortality.html#how-predation-is-modelled",
    "href": "understand/predation-growth-and-mortality.html#how-predation-is-modelled",
    "title": "Predation, growth and mortality",
    "section": "How predation is modelled",
    "text": "How predation is modelled\nThe easiest case in which to understand predation is to imagine a filter feeding fish, swimming around with its mouth open. Clearly the amount of food it takes in is determined by four things:\n\nthe density of prey in the water,\nhow much volume of water the fish is able to filter, which will depend on how fast it swims as well as on its gape size.\nwhat sizes of prey the fish is able to filter out of the water, which will be limited by its gape size and by how fine its gill rakers are,\nhow fast it can digest the food. If it can filter the prey faster than it can digest, it will have to start letting prey go uneaten.\n\nFor a more active hunter the situation will be similar. The rate at which it predates will depend on four things:\n\nthe density of prey in the water\nthe volume of water that the fish patrols and in which it will be able to seek out its prey. This may depend on things like radius of vision.\nwhich of this detected prey the fish is able to catch, which will depend on its mouth size but also on its agility and skill as well as on the defensive mechanisms of the prey.\nhow fast it can digest the food.\n\nOf these four factors, we have already been discussing the density of prey. In the next section we will discuss the ability to filter out or catch prey of particular sizes, which we model via the predation kernel. In the section after that we will discuss the search volume and then in the following section the maximum consumption rate.\nThe predation kernel\nFish will be particularly good at catching prey in a specific range of sizes, smaller than themselves. This is encoded in the size-spectrum model by the predation kernel. Let us take a look at the predation kernel in our model. We can obtain it with the function getPredKernel().\n\npred_kernel <- getPredKernel(params)\n\nThis is a large three-dimensional array (predator species x predator size x prey size). We extract the kernel of a predator of size 10g (using that we remember that this is in size class 81)\n\npred_kernel_10 <- pred_kernel[, 81, , drop = FALSE]\n\nThe drop = FALSE option is there to prevent R from dropping any of the array dimensions. We can now plot this as usual\n\nggplot(melt(pred_kernel_10)) +\n  geom_line(aes(x = w_prey, y = value)) +\n  scale_x_log10()\n\n\n\n\nWe see that the predator of size 10g likes to feed on prey that is about the size of 0.1g, which is about 100 times smaller than itself. But it also feeds on other sizes, just with reduced preference. The preferred predator/prey size ratio is determined by the species parameter beta and the width of the feeding kernel, i.e., how fussy the predator is regarding their prey size, is determined by the species parameter sigma. beta is the preferred predator prey mass ratio or PPMR. Larger PPMR values mean that the predator prefers to feed on a relatively smaller prey (larger ratio). In our model these have the values\n\nselect(species_params(params), beta, sigma)\n\n\n\n  \n\n\n\nLet us change the preferred predator prey mass ratio from 100 to 1000. As usual, we first create a copy of the parameter object, then we make the change in that copy.\n\nparams_pk <- params\nspecies_params(params_pk)$beta <- 1000\n\nLet’s make a plot to see that the predation kernel has indeed changed.\n\ngetPredKernel(params_pk)[, 81, , drop = FALSE] %>% \n  melt() %>% \n  ggplot() +\n  geom_line(aes(x = w_prey, y = value)) +\n  scale_x_log10()\n\n\n\n\nIf we now again reduce the prey in the size range from 1mg to 10mg as before, we now expect this to produce a peak in the biomass spectrum somewhere between 1g and 10g. Let’s check.\n\n# Put reduced resource abundance values into params_pk \ninitialNResource(params_pk) <- initialNResource(params_starved)\n# Find the new steady state, because conditions have changed.\nparams_pk <- singleSpeciesSteady(params_pk)\n\nplotSpectra2(params_starved, name1 = \"beta = 100\",\n             params_pk, name2 = \"beta = 1000\",\n             power = 2)\n\n\n\n\nThe dip is indeed happening later.\nYou can see another phenomenon in the above plot: Initially the biomass density in log weight is increasing faster in the model with the larger PPMR. Can you explain why? This is something worth discussing at one of the online meetings this week.\n\n\n\n\n\n\nLinks to documentation\n\n\n\n\n\nFor details of how beta and sigma parametrise the predation kernel, see https://sizespectrum.org/mizer/reference/lognormal_pred_kernel.html#details. For information on how to change the predation kernel, see https://sizespectrum.org/mizer/reference/setPredKernel.html#setting-predation-kernel\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nDo not confuse the prey preference with the diet. Just because a predator might prefer to feed on prey of a particular size if it had free choice does not mean that it actually feeds predominantly on such prey. The actual diet of the fish depends also on the availability of prey. Because smaller prey are more abundant, the realised predator prey mass ratio in the diet will be smaller than the preferred predator prey mass ratio. This is particularly important when estimating the predation kernel from stomach data.\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nChange the parameters of the predation kernel to beta = 50 and sigma = 2 and plot the predation kernel of a predator of size 1g. What do you observe?\nNext, plot the steady state arising with this feeding kernel when the prey abundance is artificially reduced by a factor of 10 in the size range between 1mg and 10mg as in previous examples. What do you observe? Are you surprised?\n\n\n\nSearch volume\nNext we consider the factor that models the volume of water a filter feeder is able to filter in a certain amount of time, or the volume of water a predatory fish is able to patrol in a certain amount of time. This is difficult to model from first principles, although people have tried to argue in terms of swimming speeds of fish. We assume that this search volume rate is also an allometric rate. Let \\gamma(w), also called gamma, denote this rate for a predator of size w. Thus we assume that \\gamma(w) = \\gamma_0\\ w^q for some exponent q. We know that a fish needs to consume prey at a rate that scales with its body size to the power n, with n about 3/4. We also know that the prey density will be approximately described by a power law, i.e., that N(w) \\approx N_0\\ w^{-\\lambda}. A bit of maths then says that q = 2 - \\lambda + n. The formula is based on observations about size distributions and the fact that in the real world, evolution had made sure that the fish have developed a feeding strategy that allows it to cover its metabolic costs. Together this would have led to that search volume exponent of approximately q=2-\\lambda+n but of course in reality there is quite a bit of variability.\nThis is one of many powerful aspects about strong theoretical basis behind size based models. We can of course disagree with this assumption if we have evidence and data, but at least there is a basic assumption to base the discussion on.\nMost people using mizer rarely modify the default assumptions about the body scaling exponents and focus on more on the coefficients. So let us see what effect changing the coefficient \\gamma_0 in the search volume rate has. Its current value in our model is\n\nspecies_params(params)$gamma\n\n[1] 4067.903\n\n\nWe change that to 2000 and find the new steady state.\n\nparams_new_gamma <- params\nspecies_params(params_new_gamma)$gamma <- 2000\nparams_new_gamma <- singleSpeciesSteady(params_new_gamma)\n\nWe can see the effect in the growth curve of our species.\n\ngf_original <- plotGrowthCurves(params, return_data = TRUE)\ngf_original$Model <- \"Original\"\ngf_new <- plotGrowthCurves(params_new_gamma, return_data = TRUE)\ngf_new$Model <- \"Reduced search volume\"\n\nggplot(rbind(gf_original, gf_new), aes(x = Age, y = value, colour = Model)) +\n    geom_line()\n\n\n\n\nAs expected, the smaller search volume leads to a slower growth due to slower feeding rate.\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\nWhat effect will this change in growth rate have on the slope of the juvenile spectrum? Will it be steeper or shallower? Make the plot of the spectrum to see.\n\n\n\nFeeding level\nIn mizer we assume that feeding rate follows a Holling type II feeding curve. This means that feeding rate is increasing fast at low prey densities, but then reaches a maximum or satiation level. So a predator will not be able to utilise food at a faster rate than its maximum intake rate. Of course in practice it will not feed at the maximum intake rate because of limited availability of prey. We describe this by the feeding level which is the proportion of its maximum intake rate at which the predator is actually taking in prey.\nIn our simple model this feeding level is constant across all fish body sizes (this is rarely the case in more realistic models, as you will see later).\n\nplotFeedingLevel(params) + theme(text = element_text(size = 20))\nplotFeedingLevel(params_new_gamma) + theme(text = element_text(size = 20))\n\n\n\n\n\nOriginal\n\n\n\n\n\n\nModified\n\n\n\n\n\n\nIn the model with the reduced search volume the feeding level is lower, as one would expect.\nThe feeding level will depend on the maximum intake, search rate and food availability. The maximum intake rate scales with body size with the exponent n = 3/4 and is determined by the coefficient h. So the maximum intake rate at size h(w) is modelled as h(w) = h w^n. Again, if we want to modify the maximum intake rate we usually change the coefficient h. We will do that in later tutorials. The current value of the coefficient h is\n\nspecies_params(params)$h\n\n[1] 59.06914\n\n\nand is measured in g of food per g^-n of predator weight per year (remember, maximum consumption scales with fish weight with the power of n)."
  },
  {
    "objectID": "understand/predation-growth-and-mortality.html#mortality",
    "href": "understand/predation-growth-and-mortality.html#mortality",
    "title": "Predation, growth and mortality",
    "section": "Mortality",
    "text": "Mortality\nPredation mortality\nOf course feeding of the predator is only one aspect of predation. The other is the death of the prey. Feeding and mortality are coupled. Increased feeding and growth of one class of individuals will necessitate increased death of another. There is no free lunch.\nOnce we have specified the predation parameters, these parameters determine both the growth of predators but also the mortality rate of prey. So we don’t have to introduce new parameters for death from predation. Of course with a one species model we cannot easily demonstrate this predation. We will explore predation more thoroughly in future tutorials.\nBackground and external mortality\nIn more realistic multi-species models mortality component also includes a baseline, size-independent mortality. This is also often called background mortality and it accounts for processes that are not related to predation, for example disease. This background mortality in mizer is assumed to depend on the maximum body size of a species, as you will see later.\nIn addition, mizer allows you to include other sources of external mortality. This could be predation from animals that we have not included in our model, like sea birds or mammals, death from old age (senescent death) and so on.\nFishing mortality\nThe cause of mortality that is most under our control is mortality from fishing. We discuss more how fishing is set up in mizer in week 3 of this course when we study the consequences of changes in fishing rates. Here we only look at a simple example: we introduce fishing on our species only for fish above 30 grams. All fish greater than 30 grams will be exposed to the same fishing mortality. We call this kind of fishing selectivity “knife_edge” selectivity. Mizer can of course also deal with more general selectivity curves, like sigmoidal or doubly sigmoidal.\n\nparams_fishing <- params\ngear_params(params_fishing)$sel_func <- \"knife_edge\"\ngear_params(params_fishing)$knife_edge_size <- 30\n\nWe also need to specify the fishing effort or fishing mortality, which we set as an annual instantaneous fishing mortality rate. Now we can then plot the resulting fishing mortality. For illustration we will set a rate of 1 per year.\n\ninitial_effort(params_fishing) <- 1\nplotFMort(params_fishing)\n\n\n\n\nWe can now see how fishing affects the adult size spectrum.\n\n# We find the new steady state with fishing mortality imposed \nparams_fishing <- singleSpeciesSteady(params_fishing)\n\nplotSpectra2(params, name1 = \"No Fishing\",\n             params_fishing, name2 = \"Knife-edge\",\n             power = 2, wlim = c(10, NA))\n\n\n\n\nThe difference may not seem to be very big, but note that we are using a logarithmic scale on the y axis. At large sizes the biomass densities differ almost by a factor of 10."
  },
  {
    "objectID": "understand/predation-growth-and-mortality.html#summary-and-recap",
    "href": "understand/predation-growth-and-mortality.html#summary-and-recap",
    "title": "Predation, growth and mortality",
    "section": "Summary and recap",
    "text": "Summary and recap\n1) In a mizer model the growth curve is not fixed but instead the growth rate of an individual changes as the prey abundance changes. This makes it important to understand how fish choose their prey.\n2) A size spectrum model reacts differently to low prey abundance than a predator-prey model. In a size spectrum model when the growth rate of a predator slows down due to lack of prey, the abundance of predators of that size increases.\n3) A fish is assumed to have a feeding preference for prey in a range of sizes at a certain fraction of its own size. So as the fish grows up, its preference shifts to larger sizes, so that the preferred predator prey mass ratio \\beta (beta) stays the same.\n4) The search rate of a species determines the rate at which it can find food and thus influences its growth rate. In mizer this search rate is an allometric rate with exponent q which by default is set as q=2-\\lambda+n so that at least in the larval stage the growth rate scales with exponent n = 3/4.\n5) Fish have a maximum intake rate that scales with body size with exponent n = 3/4. Due to scarcity of prey they will only feed at a proportion of their maximum intake rate. This proportion is called the feeding level.\n6) Species size spectra depend strongly on mortality rates and in a realistic model this mortality rate will depend on the abundance of predators. We will explore this in greater detail in the next tutorials. Here we just looked at the effect of fishing mortality on the size spectrum."
  },
  {
    "objectID": "understand/observed-size-spectra.html",
    "href": "understand/observed-size-spectra.html",
    "title": "Observed size spectra",
    "section": "",
    "text": "In this tutorial you will take observational data and plot the resulting size spectra for the community and for individual species. This will give you a concrete understanding of what size spectra are. There are various different ways of how size spectra can be represented, and this is a common source of confusion. Hence this tutorial is quite long, so let us start by giving a summary. We’ll then repeat the summary at the end of the tutorial by which time the points in the summary will hopefully make perfect sense to you."
  },
  {
    "objectID": "understand/observed-size-spectra.html#summary",
    "href": "understand/observed-size-spectra.html#summary",
    "title": "Observed size spectra",
    "section": "Summary",
    "text": "Summary\n1) It is very useful to know how many organisms of different sizes there are. This is what size spectra show.\n2) We can represent size spectra in different ways. One is to bin the data and plot histograms. The drawback is that the height of the bars in a histogram depend on our choice of bins. A bin from 1 to 2g will have fewer individuals than a bin from 1 to 10g.\n3) To avoid the dependence on bin sizes, we use densities, where the total number of individuals or the total biomass of individuals in each bin are divided by the width of the bin. We refer to these as the number density or the biomass density respectively.\n3) The number density looks very different from the biomass density. There will be a lot of very small individuals, so the number density at small sizes will be large, but each individual weighs little, so their total biomass will not be large.\n5) Community size spectra are approximately power laws. When displayed on log-log axes, they look like straight lines. The slope of the number density is approximately -2, the slope of the biomass density is approximately -1.\n6) When we work with a logarithmic weight axis, then it is natural to use densities in log weight, where the numbers of individuals in each bin are divided by the width of the bin on the log axis. We refer to these as the number density in log weight or the biomass density in log weight respectively. The slope of the number density in log weight is approximately -1 and the slope of the biomass density in log weight is approximately 0, i.e., the biomass density in log weight is approximately constant. The latter is called the Sheldon spectrum.\n7) Unlike the community spectrum, the individual species size spectra are not approximately power laws and thus do not look like straight lines on log-log axes. The approximate power law only emerges when we add all the species spectra together."
  },
  {
    "objectID": "understand/observed-size-spectra.html#introduction",
    "href": "understand/observed-size-spectra.html#introduction",
    "title": "Observed size spectra",
    "section": "Introduction",
    "text": "Introduction\nWe will start the introduction into size spectra using text from Ken H Andersen’s book “Fish Ecology, Evolution, and Exploitation” (2019):\n\nWhat is the abundance of organisms in the ocean as a function of body size? If you take a representative sample of all life in the ocean and organize it according to the logarithm of body size, a remarkable pattern appears: the total biomass of all species is almost the same in each size group. The sample of marine life does not have to be very large for the pattern to appear. … What is even more surprising is that the pattern extends beyond the microbial community sampled by plankton nets—it persists up to the largest fish, and even to large marine mammals.\n\n\nThis regular pattern is often referred to as the Sheldon spectrum in deference to R. W. Sheldon, who first described it in a ground-breaking series of publications. Sheldon had gotten hold of an early Coulter counter that quickly and efficiently measured the size of microscopic particles in water. Applying the Coulter counter to microbial life in samples of coastal sea water, he observed that the biomass was roughly independent of cell size among these small organisms (Sheldon and Parsons, 1967). And he saw the pattern repeated again and again when he applied the technique to samples from around the world’s oceans. Mulling over this result for a few years, he came up with a bold conjecture (Sheldon et al., 1972): the pattern exists not only among microbial aquatic life, but it also extends all the way from bacteria to whales.\n\nYou can read more about this work in the references below:\nSheldon, R. W., and T. R. Parsons (1967). “A Continuous Size Spectrum for Particulate Matter in the Sea.” Journal Fisheris Research Board of Canada 24(5): 909–915.\nSheldon, R.W., A. Prakash, andW. H. Sutcliffe (1972). “The Size Distribution of Particles in the Ocean.” Limnology and Oceanography 17(3): 327–340\nBlanchard, J. L., Heneghan, R. F., Everett, J. D., Trebilco, R., & Richardson, A. J. (2017). From bacteria to whales: using functional size spectra to model marine ecosystems. Trends in ecology & evolution, 32(3), 174-186.\nK.H. Andersen, N.S. Jacobsen and K.D. Farnsworth (2016): The theoretical foundations for size spectrum models of fish communities. Canadian Journal of Fisheries and Aquatic Science 73(4): 575-588.\nK.H. Andersen (2019): Fish Ecology, Evolution, and Exploitation - a New Theoretical Synthesis. Princeton University Press.\nAnd in many other references listed in the sizespectrum.org publications page."
  },
  {
    "objectID": "understand/observed-size-spectra.html#example-code",
    "href": "understand/observed-size-spectra.html#example-code",
    "title": "Observed size spectra",
    "section": "Example code",
    "text": "Example code\nThese tutorials contain a lot of working R code, because learning R coding for mizer is best done by looking at example code. The content of these tutorials is also contained in the corresponding tutorial worksheet in this week’s worksheet repository. That makes it easy for you to re-run the code yourself. After a while we hope that you will start experimenting with making modifications to the code. This is further encouraged by the exercises that you will find dotted throughout the tutorials. The tutorial worksheets contain more information on how to work through those exercises and commit your work.\n\n\n\n\n\n\nNote\n\n\n\nIf you have not yet cloned your worksheet repository to your computer, please go back to the index page for this week where you will find a video explaining what you need to do.\n\n\nTo analyse and plot the data we will be making use of the tidyverse package, in particular dplyr and ggplot2. If you are not familiar with these, you can learn what is needed just by studying the example code in this tutorial. Before we can use a package we need to load it in from the package library with the library() function:\n\nlibrary(tidyverse)\n\nWhen you hover over any function name in the R code in these tutorials, you will notice that they are links. If you click on them this will open the function’s help page in a new browser window. Thus you can always easily read more information about the functions we are using.\n\n\n\n\n\n\nImportant\n\n\n\nYou will find explanations of the code if you expand the “R details” sections located below many of the code chunks. In order not to annoy the R experts among you, these sections are collapsed initially. To expand an explanation section, just click on the “Expand for R details”."
  },
  {
    "objectID": "understand/observed-size-spectra.html#the-data",
    "href": "understand/observed-size-spectra.html#the-data",
    "title": "Observed size spectra",
    "section": "The data",
    "text": "The data\nSo let’s see if we can find Sheldon’s pattern ourselves. First we load the data.\n\nsize_data <- readRDS(\"size-data.rds\")\nstr(size_data)\n\n'data.frame':   925594 obs. of  3 variables:\n $ species: chr  \"Cod\" \"Cod\" \"Cod\" \"Cod\" ...\n $ weight : num  52.77 56.37 6.14 5.66 5.89 ...\n $ length : num  17.41 17.8 8.5 8.27 8.38 ...\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nThe readRDS() function loads the file “size-data.rds” which contains the data frame with the size data. We assign this data frame to the variable size_data for use below and then, to get an impression of what is in the data frame, we use the str() function.\n\n\n\nThe data consists of measurements of the length in centimetres of 925594 fish of various species. The species included are\n\nunique(size_data$species)\n\n[1] \"Cod\"       \"Whiting\"   \"Haddock\"   \"Saithe\"    \"Herring\"   \"Sandeel\"  \n[7] \"Nor. pout\" \"Plaice\"    \"Sole\"     \n\n\nThis data was assembled by Ken Andersen at DTU Aqua in Copenhagen. The length in centimetres was converted to weight in grams using the standard allometric relationship\n \\mathrm{weight} = a\\, \\mathrm{length} ^ b,\nwhere the coefficient a and the exponent b are species-specific parameters (we’ll discuss how to find such species parameters in a later tutorial).\nThe reason we like to work with weight as the measure of a fish’s size is that there are well-known allometric relationships between weight w and physiological rates. For example, metabolic rate is generally expected to scale as w^{3/4} and mortality to scale as w^{-1/4}, as we will be discussing in the section on allometric rates in the next tutorial.\n\n\n\n\n\n\nNote\n\n\n\nWhen not otherwise specified, all lengths are given in centimetres [cm] and all weights are given in grams [g]."
  },
  {
    "objectID": "understand/observed-size-spectra.html#histogram",
    "href": "understand/observed-size-spectra.html#histogram",
    "title": "Observed size spectra",
    "section": "Histogram",
    "text": "Histogram\nTo get an impression of the size distribution of the fish, we plot a histogram of the fish weights.\n\np <- ggplot(size_data) +\n    geom_histogram(aes(weight), fill = \"blue\", colour = \"black\") +\n    labs(x = \"Weight [g]\",\n         y = \"Number of fish\")\np\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nWe have used the ggplot2 package, included in the tidyverse package, to make the plot. It is much more powerful and convenient than the base plot commands. It implements the “grammar of graphics”. If you are not already using ggplot2 it is worth your time to familiarise yourself with it. However for the purpose of this tutorial, you can simply pick up the syntax from the examples we give.\nIn the above we first specify with ggplot(size_data) that the graph shall be based on the data frame size_data that we loaded previously. We then add features to the graph with the +.\nFirst geom_histogram() specifies that we want a histogram plot. The argument specifies the variable to be represented. Note how this is wrapped in a call to aes(). Don’t ask why, that is the way the grammar of graphics likes it. The specification of how the variables are tied to the aesthetics of the graph will always be given withing the aes() function.\nWe then specify that we want the bars in the histogram to be blue (fill = \"blue\") with a black border (colour = \"black\"). Such tuning of the appearance is of course totally optional. By the way: one has to admire how the ggplot2 package accepts both colour and color, so that our US friends can use color = \"black\".\nThen we add our own labels to the axes with labs().\nWe assign the resulting plot to the variable p because that way we can manipulate the plot further below. Because the assignment operator in R does not display any result, we added another line with just the variable name p which will display the plot.\n\n\n\nThe plot is not very informative. It just tells us that most fish are very small but there is a small number of very large fish. We can not see much detail. We will apply three methods to improve the graph.\nLogarithmic y axis\nThe first way to improve the plot is to plot the y-axis on a logarithmic scale. That has the effect of stretching out the small values and squashing the large values, revealing more detail.\n\np + scale_y_log10()\n\nWarning: Transformation introduced infinite values in continuous y-axis\n\n\nWarning: Removed 2 rows containing missing values (`geom_bar()`).\n\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nWe get a warning because there were bins that contained no fish, and taking the log of 0 is not allowed. We can ignore these warnings because the empty bins will simply not be given a bar in the resulting plot.\nUnfortunately by default R uses the engineering notation where for example 1e+03 stands for 1000 or 10^3. You can change that by changing scale_y_log10() to scale_y_log10(labels = scales::comma). Try that to see if you prefer it.\nNote that the y axis still gives the number of fish, not the logarithm of the number of fish. We have only changed the scale on the axis. We have not changed which variable we are plotting.\n\n\n\nLogarithmically sized bins\nThe second way to deal with the fact that there are so many more small fish than large fish, is to make the bin widths different. At the moment all bins are the same width, but we can make bin widths larger at larger sizes and smaller at smaller sizes. For example we could make the smallest bin go from 1 gram to 2 gram, the next bin to go from 2 gram to 4 gram, and so on, with each next bin twice the size of the previous. This means that for large fish bins will be very wide and a lot more individuals will fall into these bins. So let’s create the break points between these bins:\n\nlog_breaks <- seq(from = 0, to = 11, by = 1)\nlog_breaks\n\n [1]  0  1  2  3  4  5  6  7  8  9 10 11\n\nbin_breaks <- 2 ^ log_breaks\nbin_breaks\n\n [1]    1    2    4    8   16   32   64  128  256  512 1024 2048\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nWe had decided that we wanted the breaks between the bins to be located at powers of 2. We first create the vector log_breaks with the exponents. The seq() function creates a vector of numbers starting at from and going up to to in steps of size by. You do not need to give the names of the arguments because they can also be identified by their position. So you could also have written seq(0, 11, 1). Such integer sequences are used so often that there is the even shorter notation 0:11 giving the same sequence.\nThe second line above creates a vector containing the powers of 2 with the exponents we just created in the vector log_breaks. Note how R can perform calculations for all entries of a vector at once, without the need for a loop.\n\n\n\nNow we use these logarithmically-spaced bins in the histogram while also keeping the logarithmic y-axis:\n\np2 <- ggplot(size_data) +\n    geom_histogram(aes(weight), fill = \"blue\", colour = \"black\",\n                   breaks = bin_breaks) +\n    labs(x = \"Weight [g]\",\n         y = \"Number of fish\") +\n    scale_y_log10()\np2\n\n\n\n\nThe heights are now slightly more even among the bins, because the largest bin is so wide.\nIt is very important that you break up your reading of the tutorials with some hands-on work that builds on what you have just learned. Therefore you will find exercises throughout the tutorials. You have now reached the first exercise. You will find that it can be accomplished using the R functions you have already learned about. Please do your work in the worksheet that accompanies this tutorial and that you will find in this week’s worksheet repository.\n::: {.callout-important} If you have not yet created this week’s worksheet repository, you may want to the “Worksheets” section on the index page for this week where you find instructions.\nYou will find the worksheet for this tutorial in the file “worksheet1-observed-size-spectra.Rmd” in your worksheet repository for this week. In that worksheet you will find the following first exercise:\n\n\n\n\n\n\nExercise 1\n\n\n\n\n\nNow you want to double the number of logarithmically-sized bins used, in order to get a more detailed picture of the size spectrum. So instead of using 11 bins to cover the range from 1g to 2048g, where each bin is twice as large as the previous, you want to use 22 bins to cover the same size range, where each bin is larger than the previous one by a factor of \\sqrt{2}.\nCreate the vector with the breaks between the bins and then use that when you plot the histogram. From this new histogram, please read off the height of the bar at 2kg and compare it to what the earlier histogram in the tutorial showed.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you compare your new histogram from the exercise with the one in the tutorial above, you will see that not only do you have more bins but also the height of each bar is smaller than previously. So the height of the bars in a histogram depend on our arbitrary choice of the bin width. We will fix that when we switch to plotting densities instead of histograms below.\n\n\nLogarithmic w axis\nThe third thing we can do to get a better-looking plot is to also display the weight axis on a logarithmic scale:\n\np2 + scale_x_log10()\n\n\n\n\nNote how on the logarithmic axis the logarithmically-sized bins all have the same width."
  },
  {
    "objectID": "understand/observed-size-spectra.html#density-in-size",
    "href": "understand/observed-size-spectra.html#density-in-size",
    "title": "Observed size spectra",
    "section": "Density in size",
    "text": "Density in size\nWe noticed that the height of the bars changed as we changed how we bin the data. That is obvious. If we make a bin twice as large, we expect twice as many fish in that bin. We now want to get rid of this dependence on the choice of the bin width. We can do this if we divide the height of each bar by its width.\nThis idea is familiar to you in a different context. Assume you want to describe the spatial distribution of individuals. You would then divide your area into small squares and count the number of individuals in each of these squares. Then you divide the number of individuals in each square by the area of that square to obtain the average density of individuals in that square. That is a density in space. The only difference now is that instead of dividing space into squares we have divided the size axis into intervals (which we call bins) and to obtain the average density in size we divide the numbers by the lengths of the intervals.\nIn fact, thinking of the weight axis in a similar way to how you think about space will generally be helpful when thinking about size-spectrum modelling.\nBecause it is important to understand this concept of density in size, we will calculate the number density by hand below, even though ggplot has a built-in function geom_density() that we could use instead. We first bin the data by hand, and then we calculate and plot the densities."
  },
  {
    "objectID": "understand/observed-size-spectra.html#binning",
    "href": "understand/observed-size-spectra.html#binning",
    "title": "Observed size spectra",
    "section": "Binning",
    "text": "Binning\nTo understand better what the histogram did and to improve the plots further, we bin the data ourselves. We do this by first adding a bin number to each observation, which indicates in which bin the weight of the fish lies.\n\ndata_with_bins <- size_data |>\n    mutate(bin = cut(weight, breaks = bin_breaks, right = FALSE,\n                     labels = FALSE))\nhead(data_with_bins)\n\n\n\n  \n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nWe used the pipe operator |> that simply pipes the output of the code preceeding it into the first argument of the function following it. So the above code is equivalent to\n\ndata_with_bins <- mutate(size_data, bin = cut(weight, breaks = bin_breaks, \n                                         right = FALSE, labels = FALSE))\n\nThe pipe operator becomes really useful only if you do a longer sequence of operations on data. You will see examples of its use later.\nThe mutate() function can add new columns to a data frame or modify existing columns. In the above example it adds a new column bin. The entries in that column are here calculated by the function cut that returns the label of the bin into which an observation falls. We specify the bin boundaries with the breaks = bin_breaks to be the boundaries we have calculated above. The right = FALSE means that in case an observation falls exactly on a right bin boundary, it is not included in that bin but instead in the next bin. The labels = FALSE means that the bins are not labelled by the intervals but simply by integer codes.\n\n\n\nWe then group the data by bin and calculate the number of fish in each bin.\n\nbinned_numbers <- data_with_bins |> \n    group_by(bin) |> \n    summarise(Number = n())\nbinned_numbers\n\n\n\n  \n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nAfter we have grouped together all the observations with the same bin number with the group_by(bin), the summarize() function creates a new data frame with one row for each group, which in this case means one row for each bin. That data frame will always have one column specifying the group and then we specified that we want an extra column Number that just counts the number of observations in the group with the n() function. Note that the species is ignored in this calculation.\nIn the above code you see the pipe operator |> being quite convenient, because it allows us to write the functions in the order in which they are applied, rather than having to write summarize(group_by(...)).\n\n\n\nThe numbers in each bin give us the heights of the bars in the histogram above."
  },
  {
    "objectID": "understand/observed-size-spectra.html#number-density",
    "href": "understand/observed-size-spectra.html#number-density",
    "title": "Observed size spectra",
    "section": "Number density",
    "text": "Number density\nThe values for Number of course depend on the size of the bins we have chosen. Wider bins will have more fish in them. We now divide these numbers by the bin widths to get the average number density in the bins.\n\nbinned_numbers <- binned_numbers |> \n    mutate(bin_start = bin_breaks[-length(bin_breaks)],\n           bin_end = bin_breaks[-1],\n           bin_width = bin_end - bin_start,\n           Number_density = Number / bin_width)\nbinned_numbers\n\n\n\n  \n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nHere we are using the mutate() function to add four columns to our binned_numbers data frame. bin_start and bin_end hold the start and end point of each bin and bin_width holds its width. Then when we calculate the entries for the Number_density column by dividing the Number column by the bin_width column.\n\n\n\nLet’s make a plot of the number density against weight. Note that we only calculated the average the number density within each bin. When we make our plot we want to plot this average value at the midpoint of the bin on the logarithmic axis. In between these values the plot then interpolates by straight lines to produce a continuous curve.\n\nbinned_numbers <- binned_numbers |>\n    mutate(bin_midpoint = exp((log(bin_start) + log(bin_end)) / 2))\n\np_number_density <- ggplot(binned_numbers) +\n    geom_line(aes(x = bin_midpoint, y = Number_density)) +\n    labs(x = \"Weight [g]\", y = \"Number density [1/g]\")\np_number_density\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nYou will by now already be able to read this code. The only subtle bit is that to calculate the midpoint on the logarithmic axis we first need to take the log, then the average and then exponentiate again.\n\n\n\nAgain the graph tells us that most of the individuals are very small, but we can not see any of the details. We therefore plot the density on log-log axes:\n\np_number_density + \n    scale_x_log10() + \n    scale_y_log10()\n\n\n\n\nIt is time for your second exercise of the course. Go back to your week 1 exercise project in RStudio, and do Exercise 2 in worksheet 1:\n\n\n\n\n\n\nExercise 2\n\n\n\n\n\nEarlier you increased the number of bins from 11 to 22. Because the same number of observed fish was then spread over this larger number of bins, all the bars in the histogram were accordingly less high. By going to the number density we have corrected for this. The density plot created with the 22 bins will of course not look exactly the same as the one created with 11 bins. It will look more ragged because it exposes the noise in the data more.\nCreate the plot of the number density using the 22 logarithmically sized bins from exercise 1."
  },
  {
    "objectID": "understand/observed-size-spectra.html#fitting-a-power-law",
    "href": "understand/observed-size-spectra.html#fitting-a-power-law",
    "title": "Observed size spectra",
    "section": "Fitting a power law",
    "text": "Fitting a power law\nThe number density in the above log-log plot is described approximately by a straight line. We can approximate the slope and intercept of that straight line by fitting a linear model\n\nmodel <- lm(log(Number_density) ~ log(bin_midpoint), data = binned_numbers)\nmodel\n\n\nCall:\nlm(formula = log(Number_density) ~ log(bin_midpoint), data = binned_numbers)\n\nCoefficients:\n      (Intercept)  log(bin_midpoint)  \n           14.563             -2.241  \n\n\nThis tells us that the straight-line approximation has a slope of about -2.24. We can also ask ggplot to put this line into the plot, together with its 95% confidence interval:\n\nggplot(binned_numbers, aes(x = bin_midpoint, y = Number_density)) +\n    geom_line() + \n    scale_x_log10(name = \"Weight [g]\") + \n    scale_y_log10(name = \"Number density [1/g]\") +\n    geom_smooth(method = 'lm')\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nThe linear regression line is produced by geom_smooth(method='lm'). Note how we moved the call to aes() into the call to ggplot(). That is then used automatically for both the geom_line() and the geom_smooth(), so that we did not have to specify the information twice.\nWe also have put the text for the axis labels into the calls to scale_x_log10() and scale_y_log10() instead of putting it into a separate labs() function as we have done so far. The two are identical. As always in R, there are many different ways to achieve the same outcome.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nA straight line on a log-log plot indicates a power-law relationship between the variables with the slope of the line being the exponent in the power law.\n\n\nIf we denote the number density at weight w by N(w), then the above tells us that \\log(N(w)) \\approx 14.6 -2.24 \\log(w).\nIf we exponentiate both sides to get rid of the logarithms this gives\n\nN(w) \\approx \\exp(14.6) w^{-2.24} = N(1) w^{-\\lambda}\n\nwith \\lambda \\approx 2.24.\nThe term lambda or \\lambda is widely used in size spectrum terminology and it denotes the size spectrum slope. A steeper slope (larger \\lambda value) means that there are relatively fewer large fish compared to small fish. A more shallow slope (smaller \\lambda) indicates a relatively larger number of large fish. Now you know how these slopes are calculated.\nOf course the approach we took above of estimating the exponent in the power law from the binned data is not ideal. If one has access to unbinned data, as we have here, one should always use that unbinned data. So the better way to estimate the slope or exponent from our data would be to ask: “If we view our set of observed fish sizes as a random sample from the population described by the power law, for which exponent would our observations be the most likely”. In other words, we should do a maximum likelihood estimation of the exponent. We’ll skip the mathematical details and just tell you the result that the maximum likelihood estimate for the power-law exponent \\lambda is\n\\lambda = 1+\\frac{n}{\\sum_{i=1}^n\\log\\frac{w_i}{w_{min}}},\nwhere n is the number of observed fish, w_i is the weight of the ith fish and w_{min} is the weight of the smallest fish. For our data this gives\n\nn <- nrow(size_data)\nw_min <- min(size_data$weight)\nlambda <- 1 + n / sum(log(size_data$weight / w_min))\nlambda\n\n[1] 1.709584\n\n\nYou can see that this approach, which gives equal weight to each observation rather than giving equal weight to each bin, gives a lower value for \\lambda, namely \\lambda \\approx 1.71 instead of \\lambda \\approx 2.24. This is quite a big difference. But this is still not the end of the story, because we did not take measurement error into account. We assumed that we sampled perfectly. But in reality, small individuals are much easier to miss than large ones, so our data is almost certainly under-reporting the number of small individuals, which leads to a smaller \\lambda or more shallow size spectra. Also, in many ecosystems large fish have been removed by fishing, so we might also be missing them. This would lead to steeper slopes and larger \\lambda. The removal of large individuals leads to steeper slopes and hence larger \\lambda.\n\n\n\n\n\n\nImportant\n\n\n\nThe value reported for a community size-spectrum exponent depends strongly on the methodology used to obtain it. You need to be aware of this when comparing exponents from different papers."
  },
  {
    "objectID": "understand/observed-size-spectra.html#biomass-density",
    "href": "understand/observed-size-spectra.html#biomass-density",
    "title": "Observed size spectra",
    "section": "Biomass density",
    "text": "Biomass density\nAbove, we first calculated the number of fish in each weight bin and then divided by the width of each bin to obtain the average number density in each bin. Exactly analogously to that, we can calculate the biomass of all the fish in each weight bin and divide that by the width of each bin to obtain the average biomass density in each bin. So in the code below we will now sum weight and not numbers.\n\nbinned_biomass <- data_with_bins |> \n    group_by(bin) |> \n    summarise(Biomass = sum(weight)) |>\n    mutate(bin_start = bin_breaks[-length(bin_breaks)],\n           bin_end = bin_breaks[-1],\n           bin_width = bin_end - bin_start,\n           bin_midpoint = exp((log(bin_start) + log(bin_end)) / 2),\n           Biomass_density = Biomass / bin_width)\n\nggplot(binned_biomass, aes(x = bin_midpoint, y = Biomass_density)) +\n    geom_line() + \n    scale_x_log10(name = \"Weight [g]\") + \n    scale_y_log10(name = \"Biomass density\") +\n    geom_smooth(method = 'lm')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nFitting a linear model to the binned biomass density data now gives\n\nlm(log(Biomass_density) ~ log(bin_midpoint), data = binned_biomass)\n\n\nCall:\nlm(formula = log(Biomass_density) ~ log(bin_midpoint), data = binned_biomass)\n\nCoefficients:\n      (Intercept)  log(bin_midpoint)  \n           14.615             -1.265  \n\n\nNote that number density and biomass density have very different slopes, because even though there are lots of fish, each of them contributes little biomass while the fewer large fish each contribute a large biomass. The slope is -1.265 for the biomass density whereas it was -2.24 for the number density.\nIn formulas, if we denote the biomass density by B(w) then B(w) = w N(w). Therefore if the number density scales with the exponent \\lambda as N(w) \\propto w^{-\\lambda} then the biomass density will scale as B(w)\\propto w^{1-\\lambda}."
  },
  {
    "objectID": "understand/observed-size-spectra.html#densities-in-log-weight",
    "href": "understand/observed-size-spectra.html#densities-in-log-weight",
    "title": "Observed size spectra",
    "section": "Densities in log weight",
    "text": "Densities in log weight\nSo far we found evidence of decreasing biomass densities with size. Yet, the tutorial started with a reference to Sheldon’s observation about equal biomass across sizes. How is this consistent with what we found?\nAbove, we calculated densities by dividing the total number or total biomass in each bin by the width that the bin has on the linear weight (w) axis. Instead, we could divide by the width of the bin on the logarithmic weight axis.\nIf we divide the number of fish in each bin by the width of the size bin in log weight we get what we denote as the number density in log weight. Similarly if we divide the biomass in each bin by the width of the size bin on a logarithmic axis we get the biomass density in log weight, which is the Sheldon density.\nLet us create a new data frame that contains all these densities:\n\nbinned_data <- \n    left_join(binned_numbers, binned_biomass,\n              by = c(\"bin\", \"bin_start\", \"bin_end\", \"bin_width\", \n                     \"bin_midpoint\")) |>\n    mutate(bin_width_log_w = log10(bin_end) - log10(bin_start),\n           Number_density_log_w = Number / bin_width_log_w,\n           Biomass_density_log_w = Biomass / bin_width_log_w)\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nThe left_join() function combines the columns of the two data frames. The columns listed in the by = argument are those that are common between the two data frames. We end up with a data frame that contains in addition to those common columns also the columns Number, Number_density, Biomass and `Biomass_density.\nThen we add three further columns: bin_width_log_w holds the width of each bin on the logarithmic axis. This is then used to calculate Number_density_log_w and Biomass_density_log_w. We use the logarithm to base 10 because that is what ggplot2 and mizer like to use. It does not really matter because using a different base would simply multiply the densities by a constant.\n\n\n\nWe next create a plot that shows all these four densities together.\n\nlong_data <- binned_data |>\n    pivot_longer(cols = contains(\"density\"),\n                 names_to = \"Type\", values_to = \"Density\")\n\nggplot(long_data, aes(x = bin_midpoint, y = Density, colour = Type)) +\n    geom_line() + \n    scale_x_log10(name = \"Weight [g]\") + \n    scale_y_log10(name = \"Density\") +\n    geom_smooth(method = 'lm', se = FALSE)\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nggplot() needs the data frame in what is called the ‘long’ format where instead of having one column for each density, all the values for the densities are in a single column and the type of the density is noted in a second column. pivot_longer() effects this transformation. The cols = contain(\"density\") identifies the four columns that hold the densities (because these all contain the string \"density\" in their name). The other two arguments choose the names for the two new columns.\nSimply by including colour = Type in the aes() call we tell ggplot() to plot a separate curve for each type of density, to use a different colour for each curve and to add a legend explaining this.\nWe added the se = FALSE argument to geom_smooth() to avoid plotting the confidence bands which would have made the plot too confusing.\n\n\n\nWe see that the number density in log weight has the same slope as the biomass density. The biomass density in log weight has the smallest slope.\nThe different densities have different units. One should be explicit about units when plotting quantities with different units on the same axis because the height (but not the slope) of the curves depends on the units chosen. The units of the densities we plotted are determined by two factors: 1) Biomass is measured in grams whereas Numbers are dimensionless and 2) bin widths are measured in grams whereas bin widths in log weight are dimensionless. The densities, obtained by dividing either Biomass or Numbers by either bin widths or bin widths in log weight, have the following units:\n\n\nN(w) has unit 1/grams,\n\nB(w) and N_{\\log w}(w) are dimensionless,\n\nB_{\\log w}(w) has unit grams.\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\n\nUse the lm() function to determine the slope of the straight-line fit to the biomass density in log weight in this log-log plot."
  },
  {
    "objectID": "understand/observed-size-spectra.html#sheldons-observation",
    "href": "understand/observed-size-spectra.html#sheldons-observation",
    "title": "Observed size spectra",
    "section": "Sheldon’s observation",
    "text": "Sheldon’s observation\nAll the four density curves are alternative ways of representing the size spectrum. We introduce the notation N_{\\log w}(w) for the number density in log weight and B_{\\log w}(w) for the biomass density in log weight (Sheldon’s density). We have the following relations among the various densities:\nB_{\\log w}(w) = w\\, B(w) \\propto w\\, N_{\\log}(w) = w^2 N(w).\nSo Sheldon’s observation that B_{\\log w}(w) is approximately constant over a large range of sizes w from bacteria to whales can also be stated in terms of the other densities:\n\n\n\n\n\n\nImportant\n\n\n\nThe slope of the number density is approximately -2, the slope of the biomass density and the number density in log weight is approximately -1, and the slope of the biomass density in log weight is approximately 0, i.e., the biomass density in log weight is approximately constant."
  },
  {
    "objectID": "understand/observed-size-spectra.html#size-spectra-of-individual-species",
    "href": "understand/observed-size-spectra.html#size-spectra-of-individual-species",
    "title": "Observed size spectra",
    "section": "Size spectra of individual species",
    "text": "Size spectra of individual species\nSo far we have looked at the community spectrum, where we ignored the species identity of the fish. We will now look at the spectra of the individual species. We’ll plot them all on the same graph and display them with plotly so that you can hover over the resulting graph to see which line corresponds to which species. We also include the community size spectrum in black for comparison. The lines look smoother than earlier because now we use kernel density estimation rather than binning to estimate the densities.\n\np <- ggplot(size_data) +\n    geom_density(aes(weight, stat(count), colour = species), adjust = 4) +\n    geom_density(aes(weight, stat(count)), colour = \"black\", lwd = 1.2, adjust = 4) +\n    scale_x_continuous(trans = \"log10\", name = \"Weight [g]\") +\n    scale_y_continuous(trans = \"log10\", limits = c(1, NA), name = \"Number density in log w\")\n\nplotly::ggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nExpand for R details\n\n\n\n\n\nBinning the data is useful but is not the only way to approximate the densities. In reality you don’t need to bin the data by hand or bin it at all. One can also use the kernel density estimation method and ggplot2 even has that built in to its geom_density().\nBy default, geom_density() would normalise the density so that the integral under the density curve is 1. We use stat(count) to tell it that we want the number density, so that the integral under the curve is the total number, not normalised to 1.\nThe kernel density method works by placing a small Gaussian (bell curve) at each data point and then adding up all these little Gaussians. The adjust = 4 means that the width of these Gaussians is 4 times wider than geom_density() would choose by default. This leads to a smoother density estimate curve. This plays a similar role as the bin width does in histograms.\nNote how easy it was to ask ggplot to draw a separate line for each species. We only had to add the colour = species to geom_density(). ggplot automatically chose some colours for the species and added a legend to the plot.\nWe have replaced scale_x_log10() by scale_x_continuous(trans = \"log10\") which does exactly the same thing. But the latter form is more flexible, which we used in scale_y_continuous(trans = \"log10\", limits = c(1, NA)) to also specify limits for the y axis. We chose to plot densities above 1 only because at smaller values there is only noise. We did not want to set an upper limit, hence the NA.\nWe then did not display the plot p but instead fed it to plotly::ggplotly(). The ggplotly() function takes a plot created with ggplot and converts it into a plot created with plotly. plotly plots are more interactive. We called the ggplotly() function with plotly::ggplotly() because that way we did not need to load the plotly package first, i.e., we did not need to do library(plotly).\n\n\n\nThere are three messages you should take away from this plot:\n\nDifferent species have very different size spectra.\nThe estimates of the species size spectra are not very reliable because we do not have very good data.\nThe community size spectrum looks more regular than the species size spectra.\n\nWe will discuss species size spectra more in the next tutorial, where we will look at them with the help of the mizer model."
  },
  {
    "objectID": "understand/observed-size-spectra.html#summary-and-recap",
    "href": "understand/observed-size-spectra.html#summary-and-recap",
    "title": "Observed size spectra",
    "section": "Summary and recap",
    "text": "Summary and recap\n1) It is very useful to know how many organisms of different sizes there are. This is what size spectra show.\n2) We can represent size spectra in different ways. One is to bin the data and plot histograms. The drawback is that the height of the bars in a histogram depend on our choice of bins. A bin from 1 to 2g will have fewer individuals than a bin from 1 to 10g.\n3) To avoid the dependence on bin sizes, we use densities, where the total number of individuals or the total biomass of individuals in each bin are divided by the width of the bin. We refer to these as the number density or the biomass density respectively.\n3) The number density looks very different from the biomass density. There will be a lot of very small individuals, so the number density at small sizes will be large, but each individual weighs little, so their total biomass will not be large.\n5) Community size spectra are approximately power laws. When displayed on log-log axes, they look like straight lines. The slope of the number density is approximately -2, the slope of the biomass density is approximately -1.\n6) When we work with a logarithmic weight axis, then it is natural to use densities in log weight, where the numbers of individuals in each bin are divided by the width of the bin on the log axis. We refer to these as the number density in log weight or the biomass density in log weight respectively. The slope of the number density in log weight is approximately -1 and the slope of the biomass density in log weight is approximately 0, i.e., the biomass density in log weight is approximately constant. The latter is called the Sheldon spectrum.\n7) Unlike the community spectrum, the individual species size spectra are not approximately power laws and thus do not look like straight lines on log-log axes. The approximate power law only emerges when we add all the species spectra together."
  },
  {
    "objectID": "index.html#free-registration",
    "href": "index.html#free-registration",
    "title": "mizer course",
    "section": "Free registration",
    "text": "Free registration\nParticipation is free. If you would like to participate in this course, please register.\nIf you have any questions, email me at gustav.delius@gmail.com"
  },
  {
    "objectID": "index.html#tutorials-and-worksheets",
    "href": "index.html#tutorials-and-worksheets",
    "title": "mizer course",
    "section": "Tutorials and worksheets",
    "text": "Tutorials and worksheets\nThe course has three week-long sections:\n\nWeek 1: Understand\nYou will gain an understanding of size spectra and their dynamics by exploring simple example systems hands-on with mizer.\nWeek 2: Build\nFollowing our example, you will build your own multi-species mizer model for the Celtic sea. We will collect the models from all participants to create an ensemble of models. You can also create a model for your own area of interest.\nWeek 3: Use\nWe will use the new ensemble of mizer models for the Celtic sea that you all helped to create in the previous week to explore the effects of changes in fishing and changes in resource dynamics. You will run your own model scenarios.\n\nThe course is organised into several tutorials each week. Each tutorial is associated with a worksheet in which you perform the exercises that are dotted throughout the tutorials. You will work through these tutorials and worksheets at times that are convenient for you."
  },
  {
    "objectID": "index.html#on-line-meetings",
    "href": "index.html#on-line-meetings",
    "title": "mizer course",
    "section": "On-line meetings",
    "text": "On-line meetings\nThere will be an online zoom meeting at 3pm UK time (GMT) on every workday during the course. The purpose of these meetings is to add a social dimension to the course. Joining the meetings is optional. Each meeting will start with a brief walk-through of one of the course tutorials that will also be recorded and posted on the course website after the meeting. The rest of the meeting is for questions and exchange of experiences among the course participants, either among all participants or within breakout rooms.\nThe meetings are scheduled to last for one hour but you should feel free to join and leave meetings at any time, according to what you feel is useful to you. In fact, the zoom link works also outside the timetabled slots, so you can use it for extended discussions whenever you like.\nYou will receive an invitation to the zoom meetings before the start of the course once you have registered.\n\nThis course is organised as a part of the Pyramids of Life, funded by UK Research and Innovation via the Sustainable Management of Marine Resources fund."
  },
  {
    "objectID": "use/index.html",
    "href": "use/index.html",
    "title": "Week 3: Use mizer models",
    "section": "",
    "text": "Lecture\nThis week’s contributor is Julia Blanchard. Her lecture provides a broad overview of the different ways in which mizer is being used to help understand the consequences of change in aquatic ecosystems. There are a lot of ways! The material describes how you can set model simulations to study change, some of which are explored in this week’s tutorials.\n\n\n\n\n\n\n\n\n\nTutorials\nUsing examples, the tutorials are designed to help you develop your own model simulation experiments:\n\nTune the resilience to fishing First, we will explore how sensitive your model is to the effects of fishing. We will show how the reproduction levels influence the resilience of the species. We make adjustments to the reproduction levels to produce realistic responses to fishing intensity.\nSimulate fishing scenarios\nOnce the resilience to fishing is tuned, we can assess how the model responds to changes in fishing through time. This step involves looking closer at the fishing parameters in mizer and setting up different fishing scenarios.\nChange resources\nNext we will look at the resource spectrum and how changes in three main resource parameters can affect our ecosystem. We will also show an example of how to use external data on resource time series to force the mizer model.\nExplore further scenarios\nThis tutorial provides extra material, prepared by Julia Blanchard using another system (Patagonian toothfish fishery) as an example. Here you can learn on how to set time series of fishing changes and more.\n\nThis week you can continue to work in the worksheet repository you created last week at https://classroom.github.com/a/gS1LgX3B"
  },
  {
    "objectID": "use/tune-resilience.html",
    "href": "use/tune-resilience.html",
    "title": "Tune resilience",
    "section": "",
    "text": "In the previous week we tuned our model parameters so that the steady state of the model agrees with observed growth rates, average observed biomasses and with observed catches. We did not yet tune how sensitively our model reacts to changes away from its steady state. In particular, we did not tune how resilient the species are to fishing. We will do that in this tutorial."
  },
  {
    "objectID": "use/tune-resilience.html#in-preparation",
    "href": "use/tune-resilience.html#in-preparation",
    "title": "Tune resilience",
    "section": "In preparation",
    "text": "In preparation"
  },
  {
    "objectID": "use/change-resources.html",
    "href": "use/change-resources.html",
    "title": "Change resources",
    "section": "",
    "text": "Mizer can be used to explore the consequences of climate change on aquatic ecosystems and fisheries. One of the major effects that climate change is having on aquatic ecosystems is a change in resource abundance and size structure. However, responses in resources are highly uncertain and variable and predictions are difficult. For plankton we can use satellite observations of chlorophyll A and earth system models to assess past changes and aim to predict the future. We might want to explore the potential effect of these changes on the rest of aquatic food webs and on our fisheries. This is what we are going to do in this tutorial."
  },
  {
    "objectID": "use/change-resources.html#in-preparation",
    "href": "use/change-resources.html#in-preparation",
    "title": "Change resources",
    "section": "In preparation",
    "text": "In preparation"
  },
  {
    "objectID": "use/further-scenarios.html",
    "href": "use/further-scenarios.html",
    "title": "Explore further scenarios",
    "section": "",
    "text": "This final tutorial gives some examples from another mizer model, tuned to a different system and used to explore different questions. It is always useful to see alternative ways of using mizer and get examples of code to setup different analyses. This tutorial is contributed by Julia Blanchard. Here we will explore an example model of longline fishery that consists of targeting a single species, Patagonian toothfish."
  },
  {
    "objectID": "use/further-scenarios.html#a-look-at-the-model",
    "href": "use/further-scenarios.html#a-look-at-the-model",
    "title": "Explore further scenarios",
    "section": "A look at the model",
    "text": "A look at the model\nAs usual, we need to have some packages installed.\n\ntry(unload(\"mizerExperimental\"), silent = TRUE)\nremotes::install_github(\"sizespectrum/mizerExperimental\", quiet = TRUE)\nlibrary(mizerExperimental)\nlibrary(tidyverse)\n\nThen we load the model and explore its various properties.\n\nparams <- readParams(\"toothfish/toothfish_model.rds\")\n\nWe look at the growth curves,\n\nplotGrowthCurves(params, species_panel = TRUE)\n\n\n\n\nthe spectra,\n\nplotlySpectra(params, power = 2, total = TRUE)\n\n\n\n\n\nthe feeding levels,\n\nplotFeedingLevel(params)\n\n\n\n\nand toothfish diet.\n\nplotDiet(params, species = \"D.ele\")\n\n\n\n\nFor this model, we had the following main criteria for our project:\n\nModelled biomasses were within +/- 10-20% of the observed biomasses.\nUnfished normalised biomass size spectrum slope that is negative and close to -1.\nGrowth curves approximated the von Bertalanffy growth curves for each species.\nToothfish diet captured dietary changes with body size and became more piscivorous at larger sizes.\nRecruitment parameters ensured single-species yield curves were dome-shaped, as expected by theory.\nThe modeled catches through time captured the trends in the reported catches through time.\n\nWe can see from these plots that we still have more work to do with refining the model. The size at age for some species seem much higher than the empirical parameters, feeding level is near satiation for all species and the biomass of some species is much higher than the data. However size-at-age data are typically highly variable. So, let’s set some of those issues aside for now. However with what you have already learned in this course you will probably be able to easily fix some of these issues. Feel free to do that and see how it impacts the remainder of this tutorial.\nLet’s take a look at how fishing is set up in this model.\n\ngear_params(params)\n\n\n\n  \n\n\n\nCurrently we can see there is one gear - longline - which has a knife_edge selectivity function that starts fishing at very large sizes of toothfish only (knife_edge_size = 2722 g). The size selectivity was derived from the length distribution of catches from the long-line fisheries data. To explore further how to setup your fishing parameters and use gear_params() function you can look at the example here. The catchability has been set to a very low number: 7e-07. The initial effort is:\n\ninitial_effort(params)\n\nlongline \n6787.953 \n\n\nThis shows that the model has been calibrated with a very low level of fishing mortality (multiply effort by catchability).\nLet’s look at the reproduction levels and the yield curve for toothfish:\n\ngetReproductionLevel(params)\n\n    D.ele     C.gun     C.rhi     L.squ     M.cam     B.eat     B.irr     G.acu \n0.9998035 0.9994817 0.9991013 0.9426729 0.8279399 0.9999131 0.9996038 0.9996273 \n    B.mur \n0.9777815 \n\nplotYieldVsF(params, species = \"D.ele\", no_steps = 30, F_max = 2)\n\n\n\n\nThey generally look good and the curve is dome-shaped."
  },
  {
    "objectID": "use/further-scenarios.html#comparing-ecosystem-states-effects-of-fishing-relative-to-an-unfished-state",
    "href": "use/further-scenarios.html#comparing-ecosystem-states-effects-of-fishing-relative-to-an-unfished-state",
    "title": "Explore further scenarios",
    "section": "Comparing ecosystem states: effects of fishing relative to an unfished state",
    "text": "Comparing ecosystem states: effects of fishing relative to an unfished state\nTo be able to assess the wider ecosystem impacts of fishing in the community we need to understand how changes compare to an unfished state. We can use the above model to simulate an unfished steady state with effort = 0 and then explore this state using some ecological indicators.\nLet’s compare the current size spectra (with fishing) to the unfished size spectra to assess whether there is any evidence of a size-structured trophic cascade due to fishing.\n\nsim0 <- project(params, effort = 0, t_max = 20)\nplotSpectraRelative(sim0, params)\n\n\n\n\nHere we can see the effect of the reduction in large sized individuals of heavily fished species on the other sizes and species in the model, relative to the unfished steady state.\nThe abundance of some (but not all) of the smaller to medium sizes of prey are a lot higher when their larger predators are removed (note the logarithmic scale). This is because when toothfish are removed via fishing, they have less predation mortality and no fishing inflicted upon them."
  },
  {
    "objectID": "use/further-scenarios.html#fishing-through-time-past-time-series",
    "href": "use/further-scenarios.html#fishing-through-time-past-time-series",
    "title": "Explore further scenarios",
    "section": "Fishing through time: past time series",
    "text": "Fishing through time: past time series\nMizer can also be used to carry out projections with changes in fishing effort. We will start by reading in a time series of catch and effort. We will read in the effort data for this fishery. Note: these are not the correct effort values, they are only for illustration in this example. Then we plot effort and catch through time.\n\ndat <- readRDS(\"toothfish/longline.rds\")\nplot_dat <- melt(dat, \"Year\")\n\nggplot(plot_dat, aes(x = Year, y = value)) +\n    geom_point() +\n    facet_wrap(~variable, nrow = 2, scales = \"free\")\n\n\n\n\nWe can see from the data that there have been big changes in effort and catches through time. The first plot shows relative effort per area (please note that these data are not correct and are only being used for illustration in this example). Catches are in tonnes per square km fished. They have changed a lot over the years.\nPreviously we assumed effort was 1 and we worked with catchability as the variable. Real effort data can come in all sorts of different units (hours or days fished, kilowatt days, number of vessels all per unit time). The key to using this in our model is that the catchability is the fraction of the available (that is also selected by the gear) stock caught per unit of any effort that is included.\nOften, we have used fishing mortality rates from stock assessment to drive changes in effort through time, assuming Q*E = F at maximally selected sizes (as in this paper and others). But in many cases this information is not available. It also could be misleading as those fishing mortality rates are estimated using very different single-species models (but sometimes that is the best we have to work with, and as with all of the assumptions we make the limitations just need to be clear).\nHow do we incorporate the effort data into the model? First, we have to re-arrange the data so it can be read into the params object.\n\neffort_time <- array(c(rep(0,13), dat$EffortPerArea), \n                     dim = c(length(1990:2020), 1),\n                     dimnames = list(\"time\" = 1990:2020, \n                                     \"gear\" = params@gear_params$gear[1]))\n\nNext we use the effort data to project the model forwards from it’s steady state. But wait - we did not set up the model for the first year of the data, when fishing only just began. It may make more sense to use a steady state without fishing as the initial values for our projection.\n\n#project to zero fishing rate \nparams <- projectToSteady(params, effort = 0)\n\nConvergence was achieved in 1.5 years.\n\n#project with fishing effort\nsimf <- project(params, effort = effort_time)\n\nplotYieldGear(simf) + \n    geom_point(data = dat, shape = 1, size = 1, \n               mapping = aes(x = Year, y = CatchPerArea))\n\n\n\n\nHere we can see that the modeled catch time series fall within the scatter of the observed catch data (reassuring), but the trends are different. It seems there is a sharp decline in modeled catches towards the end of the time series. While we should not expect the exact up and down fluctuations to be captured by our model (we don’t have anything forcing the changes through time other than fishing!), we could examine further how changing the reproduction parameters affects how well the model captures stock decline (and later, recovery), relative to the trends in the data. It may also be that our estimates of catchability and effort are way off (they are). And that other factors could be influencing observed changes not accounted for by our model."
  },
  {
    "objectID": "use/further-scenarios.html#what-if-we-only-have-catch-data",
    "href": "use/further-scenarios.html#what-if-we-only-have-catch-data",
    "title": "Explore further scenarios",
    "section": "What if we only have catch data?",
    "text": "What if we only have catch data?\nWhat if there was no effort data and only catch data? This is the case for many data-poor fisheries or for fisheries where there is only restricted access to effort data.\nMany fisheries develop through time according to phases: an exponential growth period, following either a peak and subsequent decline and a plateau, if stocks drop below sustainable levels and management kicks in (see here for example). These different types of development can be represented by a function, logistic_effort(), and can be used to help estimate the fishing parameters given the the model parameters and data you may have. This is the approach used here. Here, we will use this function to explore effort through time.\n\nlogistic_effort <- function(effort_array,\n                            gear = \"longline\",\n                            time = 1990:2020,\n                            Fmax = 1.5,\n                            steepness = 0.2,\n                            midpoint = 2005) {\n    effort_array[, gear] <- Fmax / (1 + exp(-steepness*(time - midpoint)))\n    return(effort_array)\n}\n\nAfter using the above function we can scale the effort up to the effort units we used in our base model. We do this by setting the Fmax in the logistic equation to the desired level of fishing mortality rate (e.g. 0.005 was used above but for this example we will plug in a different value to explore heavier fishing). We then divide Fmax by our estimated catchability coefficient (which was estimated to be a very small number) to get effort in the correct ballpark and units as the data we used above. If you want to run the model directly with fishing mortality rate as the “effort” driver, you would need to set the catchability coefficient to 1 in this example. If no effort exists for your system, we would need to estimate the catchability coefficient (either by hand tuning or statistical time-series fitting).\n\nneweffort <- logistic_effort(effort_time, time = 1990:2020, Fmax = 0.5,\n                             steepness = 0.9, midpoint = 2005)\n\n#rescale to get effort in same units as our example\nneweffort <- neweffort / gear_params(params)$catchability[1]\n\n# or if you want to just use fishing mortality only in your model, \n# overwrite the catchability to 1:\n# gear_params(params)$catchability[1] <- 1\n\nyear = 1990:2020\nqplot(year, neweffort, ylab = \"effort\", xlab = \"\")\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\nNow you can run the same model above using this effort and then plot effort and biomass dynamics through time.\n\nparams3 <- setInitialValues(params, sim0)\nsimf3 <- project(params3, effort = neweffort)\n\nplotYieldGear(simf3) + \n    geom_point(data = dat, shape = 1, size = 1, \n               mapping = aes(x = Year, y = CatchPerArea)) + \n    xlim(2000, 2020)\n\nWarning: Removed 10 rows containing missing values (`geom_line()`).\n\n\n\n\nplotBiomass(simf3)\n\n\n\n# If you like you can save the output for further analyses \n#saveRDS(simf3, \"toothfish/simf3.rds\")\n\nWe can see here as effort develops towards a plateau of Fmax = 0.5 through time, catches initially increase, reach a peak around 2006, and then decline. The biomass trajectories also show that toothfish starts declining slightly before this."
  },
  {
    "objectID": "use/further-scenarios.html#fishing-through-time-projecting-into-the-future",
    "href": "use/further-scenarios.html#fishing-through-time-projecting-into-the-future",
    "title": "Explore further scenarios",
    "section": "Fishing through time: projecting into the future",
    "text": "Fishing through time: projecting into the future\nNow let’s see what happens if we change fishing in the future. To do this we set up two scenarios, one where the model starts with the last time step of the fished scenario and continues into the future (the “status quo”). The other will be designed to explore a “more sustainable” scenario.\n\n# Use the parameters from the last simulation\nparams <- getParams(simf3)\nparams <- setInitialValues(params, simf3)\n\nThe setInitialValues() function has set the initial spectra and the initial effort in the params object to the final values from simf3, i.e., to the values from 2020. The effort was\n\ninitial_effort(params)\n\nlongline \n714284.7 \n\n\nLet’s start a new simulation that begins with the effort from 2020 and projects forward for 50 years. We will apply a linear decrease in effort for toothfish to a target value (here assumed for simplicity to be F = 0.2). To do this we need to work the effort array again (time x gear) to enable changes in effort through time.\n\nproj_effort_scen1 <- matrix(initial_effort(params), nrow = 50, ncol = 1, byrow = TRUE)\ndimnames(proj_effort_scen1) <- \n    list(time = 2021:2070, gear = unique(gear_params(params)$gear))\n# check it\nqplot(x = 2021:2070, y = proj_effort_scen1, ylab = \"effort\", xlab = \"\")\n\n\n\n\nThat was Scenario 1 (“status quo”), now let’s set up Scenario 2, the “more sustainable” option we wish to explore. Again, if we are working in the same units as the effort above we can change the F below to scale effort to be consistent with a value of F=0.2. So we need to set effort= catchability/targetF. Otherwise if you assume targetF= catchability*E, and set catchability to 1, you can just use targetF=0.2 directly for Scenario 2.\n\nproj_effort_scen2 <- proj_effort_scen1\ntargetF <- 0.2 / gear_params(params)$catchability[1]\nselect_gear <- \"longline\"\n# reach target by 10 years\nproj_effort_scen2[1:10,select_gear] <- \n    seq(from = proj_effort_scen2[1], to = targetF, length = 10)\n# then hold at target\nproj_effort_scen2[11:50, select_gear] <- targetF\n# check it\nqplot(x = 2021:2070, y = proj_effort_scen2, ylab = \"effort\", xlab = \"\")\n\n\n\n\nNow we want to run the simulation forward using the project() function.\n\n# run the simulations forward, both using the 2020 abundances as initial values\nsim_scen1 <- project(params, effort = proj_effort_scen1, t_max = 50)\nsim_scen2 <- project(params, effort = proj_effort_scen2, t_max = 50)\n\nHow has this affected the catches and the biomass of other species in the system relative to fishing levels in 2020?\n\n#set the scenario to examine relative to 2020 levels\nscen <- sim_scen2\nplotYield(scen)\n\n\n\n# plot change in biomass under each scenario relative to current values\nB_current <- getBiomass(scen)[1, ]\nBrel_scen <- melt(sweep(getBiomass(scen), 2, B_current, \"/\"))\ncolnames(Brel_scen)[2] <- \"Species\"\nlegend_levels <- intersect(names(scen@params@linecolour), Brel_scen$Species)\nggplot(Brel_scen) + \n  geom_line(aes(x = time,y = value,color = Species), size = 1) + \n  geom_hline(yintercept = 1, linetype = 1, colour = \"grey\", size = 0.75) +\n  scale_y_continuous(name = \"Relative biomass\") +\n  scale_color_manual(values = params@linecolour[legend_levels]) +\n  theme(legend.key = element_rect(fill = \"white\")) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nRelative to 2020 values, reducing Fmsy to 0.2 has increased toothfish biomass and has affected the other species in the system too.\nTo compare the status of the stock across the two scenarios we need to express the changes relative to the unfished state according to the model. This will provide us with a rough indicator of the level of depletion. Generally, we would consider a stock to be collapsed if biomass was <0.1 of the unfished levels. Some data-poor single species fisheries management strategies seek for depletion to be around or above 0.5 of unfished levels.\nLet’s take a look at the relative exploitation status of the stocks using the projected values for 2050. We will put the y-axis scale is log10 to better visualise the differences across species.\n\n# plot change in biomass under each scenario relative to unfished values\n# get saved values from steady state without fishing that we generated earlier \nsim0 <- readRDS(\"toothfish/sim0.rds\")\n# get the unfished biomasses\nB_unfished <- getBiomass(sim0)[1, ]\n#scen 1\nBrel_scen1_2050 <- getBiomass(sim_scen1)[\"2050\", ] / B_unfished\n\n#scen 2\nBrel_scen2_2050 <- getBiomass(sim_scen2)[\"2050\", ] / B_unfished\n\nBrel_scens <- rbind(data.frame(species = names(Brel_scen1_2050),\n                               value = Brel_scen1_2050, scen = \"scen1\"),\n                    data.frame(species = names(Brel_scen2_2050),\n                               value = Brel_scen2_2050, scen = \"scen2\"))\n\n# barplot comparing the 2 scenarios by 2050\nggplot(Brel_scens, aes(fill = scen, y = value, x = species)) + \n    geom_bar(position = \"dodge\", stat = \"identity\") + \n     geom_hline(yintercept = 0.1, linetype = 2, colour = \"red\", size = 0.5) + \n    scale_y_log10(name = \"log10(Biomass/Biomass Unfished)\")\n\n\n\n# to save:\n#saveRDS(sim_scen2, \"toothfish/sim_scen2.rds\")\n\nSpecies with B/B_unfished values that are below the red dashed line imply the stock is still collapsed.\nWe can see that when we decrease fishing to the targetF under scenario 2 this greatly improves the relative biomass compared to the status quo. This is consistent with our expectations from the equilibrium Fmsy that we tuned. Another thing to note is that, relative to the unfished community, there are several species that increase less under this fishing scenario - this is what happens when account for food web interactions in models!"
  },
  {
    "objectID": "use/further-scenarios.html#set-up-your-own-fishing-scenario-simpler-comparison-of-steady-states",
    "href": "use/further-scenarios.html#set-up-your-own-fishing-scenario-simpler-comparison-of-steady-states",
    "title": "Explore further scenarios",
    "section": "Set up your own fishing scenario: simpler comparison of steady states",
    "text": "Set up your own fishing scenario: simpler comparison of steady states\nRather than an entire time-series, we can also simply examine differences between two time-averaged states under different fishing regimes.\nWe can alter the fishing parameters using a function called gear_params() and by changing the effort input.\nLet’s take a look at the fishing parameters.\nWe can group species together according to the gears they are caught by. Initially let’s just add another gear - a trawler targeting icefish (C.gun).\n\n# allocate species to gear types\ngear_params(params) <- data.frame(\n    gear = c(\"longline\", \"trawler\"),\n    species = c(\"D.ele\", \"C.gun\"),\n    catchability = c(1, 1),\n    sel_fun = c(\"knife_edge\", \"knife_edge\"),\n    knife_edge_size = c(2722, 52)\n    )\n#check it\ngear_params(params)\n\n\n\n  \n\n\n\nNote that catchability is set to 1. This is because the fishing “effort” was here assumed to be the fishing mortality rate of fully selected sizes (see here setFishing).\n\nparams <- setFishing(params, initial_effort = 0.1)\n\nNow let’s run two simulations, one with light fishing mortality (F = 0.2) and one heavy fishing (F = 1.5).\n\nsim_unfished <- projectToSteady(params, effort = 0, t_max = 500)\n\nConvergence was achieved in 69 years.\n\nplot(sim_unfished)\n\n\n\nparams_longline_trawl <- params\nsim_longline_trawl <- projectToSteady(params_longline_trawl, \n                                      effort = 0.1, t_max = 500)\n\nConvergence was achieved in 34.5 years.\n\nparams_longline <- params\ngear_params(params_longline)$catchability[2] <- 0\nsim_longline <- projectToSteady(params_longline, effort = 0.1, t_max = 500)\n\nConvergence was achieved in 34.5 years.\n\n\n\n# plot change in biomass under each scenario relative to unfished values\n# get the unfished biomasses\nB_unfished <- getBiomass(sim_unfished)\n#scen 1\nBrel_longline <- getBiomass(sim_longline) / B_unfished\n\n#scen 2\nBrel_longline_trawl <- getBiomass(sim_longline_trawl) / B_unfished\n\nBrel_scens <- rbind(data.frame(species = names(Brel_longline),\n                               value = Brel_longline, \n                               scen = \"longline\"),\n                    data.frame(species = names(Brel_longline_trawl),\n                               value = Brel_longline_trawl, \n                               scen = \"longline_trawl\"))\n\n# barplot comparing the 2 scenarios by 2050\nggplot(Brel_scens, aes(fill = scen, y = value, x = species)) + \n    geom_bar(position = \"dodge\", stat = \"identity\") + \n    geom_hline(yintercept = 0.1, linetype = 2, colour = \"red\", size = 0.5)  + \n    scale_y_log10(name = \"log10(Biomass/Biomass Unfished)\")\n\n\n\n\nThe impact of the combined trawl and longline appears to have more of an effect on C.gun and the biomass of D.ele is slightly more depleted relative to the unfished state."
  },
  {
    "objectID": "use/further-scenarios.html#further-exploration",
    "href": "use/further-scenarios.html#further-exploration",
    "title": "Explore further scenarios",
    "section": "Further Exploration",
    "text": "Further Exploration\nThe above plots provide you with a way to compare different modelling scenarios. You may wish to explore different levels of fishing mortality in the above example or add completely different gears to the fishery."
  },
  {
    "objectID": "prepare/use-git-and-github.html",
    "href": "prepare/use-git-and-github.html",
    "title": "Use Git and GitHub",
    "section": "",
    "text": "In this course we will collaborate via Git and GitHub. This means that if you have not used these tools before, then you will have to learn some new concepts and get used to a particular workflow. The investment of your time will more than pay off. Developing your research code with Git and GitHub has great advantages, and it’ll be great if this course gets you hooked on these tools. The use we make of Git and GitHub in this course is relatively simple, so it may be the perfect gateway drug.\nWe’ll start by first introducing some of the ideas theoretically, but then we will also show what the workflow looks like in practice. We will only scratch the surface, if you want to go deeper then Happy Git and GitHub for the useR is a useful resource."
  },
  {
    "objectID": "prepare/use-git-and-github.html#theory",
    "href": "prepare/use-git-and-github.html#theory",
    "title": "Use Git and GitHub",
    "section": "Theory",
    "text": "Theory\nGit\nGit is a distributed version control system. So we will start by explaining the “version control” and the “distributed”. We’ll typeset typical Git terminology in bold.\nVersion control means that while you are working on your code or data files you can keep track of all the changes you are making. You can then later review the history of changes and, if necessary, revert to earlier versions. You may say that any cloud storage service like Google Drive or Dropbox does that as well, but there are important differences that we will now discuss.\n\nGit keeps the repository with all your changes on your local computer. The version control does not rely on an internet connection.\nYou explicitly say when you want a batch of changes to be stored in the repository. Saving changes to the files in your local file area does not yet modify the repository. You have to make a so-called commit to commit the changes you want to the repository.\nTypically you will add a commit message that summarises briefly what the changes are about. This makes it much easier to understand the development of your code later on.\n\nSo Git provides you full control over creating points at which you want to save your code and documents to your repository. The commit messages you add can be very detailed or short. Their goal is for you and your collaborators to know what has been changed between different commit steps.\nDistributed means that the repository typically does not reside only on a single computer. There can be clones of the repository on many other computers. For example, you might want your collaborators to have a copy of the repository for a common project that you are working on jointly. They can make commits to their clone of the repository in the same way you can make commits to yours.\nEven if you only intend to work on your code alone, you may want to have copies of it on all the computers you occasionally work at and you will then want to be able to commit changes from any of those computers and pick up those changes from any other computer. So below when we speak of your “collaborator”, that collaborator could be yourself on another computer.\nFrom time to time you will want to merge the changes from one clone to another to have a new common version that incorporates changes by all collaborators. For that there needs to be some communication via the internet, facilitated by a Git server.\nGitHub\nGitHub is a service that hosts a clone of your repository on your account and runs a Git server, so that you and your collaborators do not have to run your own Git servers. Instead you can push any commits that you made into your local Git repository to the GitHub clone and then your collaborators can pull those changes from there into their own clones.\nSo with Git and GitHub we have a very different workflow than what you get when you collaborate using for example a Google Drive folder. There are more steps before your collaborator sees your changes, namely:\n\nyou save your code changes on your computer to the directory that is associated with the git repository,\nyou select or stage which of your changed code files you want to commit to your local repository,\nyou commit those selected changes to your repository with a commit message,\nyou push your commits to your online GitHub repository,\nyour collaborators pull your commits from GitHub,\nthese commits automatically get merged into their clone,\nthe changed files are checked out from their clone into the corresponding directory on their local computer drive.\n\nThere are circumstances where the standard workflow fails. If you attempt to pull commits from GitHub that change files that you have also modified locally but not yet committed, then the pull will fail with an error message.\nIf you and a collaborator independently made commits to your respective clones that touched the same lines of code then there may be merge conflicts that need to be resolved. If something like this happens to you then congratulations: you have arrived in more advanced Git territory than we will discuss in this tutorial. If at some point during the course something like this happens to you, let us know by posting a comment and we or some git-savy participant will give advice.\nThis more involved workflow takes a bit of getting used to, but is definitely the best way to work on code and data. If you follow the guidelines about committing your code changes regularly you will easily go back to earlier versions of your code if you need to, work with multiple people on the same code development, return to old coding projects that need reviewing, and be a part of open and reproducible science. So next you will get to try this out in practice."
  },
  {
    "objectID": "prepare/use-git-and-github.html#practice",
    "href": "prepare/use-git-and-github.html#practice",
    "title": "Use Git and GitHub",
    "section": "Practice",
    "text": "Practice\nFor each week of this course you will get a Git repository with worksheets for you to complete. This repository will be set up for you on GitHub. You will clone that repository to your computer at the start of each week. Then during the week you will commit your work to that repository and push it back to GitHub. This gives me a chance to see your work and to comment on it. These repositories will be private repositories, visible only to you and me, unless you yourself give others access to it. Below you will get a preparatory repository (also private) on which you can practice the workflow.\nIf you do not yet have an account on GitHub, please go there now and sign up. If you do have an account, please also go there and sign in.\nConnect RStudio to GitHub\nWe will be interacting with Git and GitHub via RStudio. This just requires some initial setup but will be very convenient from then on. Of course, if you are already using GitHub from within RStudio, then you can skip the steps below that you have gone through on your computer in the past.\nRStudio needs a personal access token for accessing GitHub. The following command will bring you to the GitHub webpage that creates that personal access token:\n\nusethis::create_github_token()\n\n\n\n\n\nYou can edit the Note to something like “mizer course” or whatever will remind you later what this was for. You can leave the rest of the form as it is and scroll down to the bottom and press the “Generate token” button. That will lead you to a page that displays your new token:\n\n\n\n\nCopy the token to your clipboard (using the button circled in the above screenshot). Switch to RStudio and issue the command\n\ngitcreds::gitcreds_set()\n\nThis will prompt you to enter your token. Paste in that token from your clipboard and press Enter. That completes the set-up. You will not have to do this again on this computer, but if you switch to a new computer, you will need the token again. Therefore it is a good idea to save this token somewhere safe. But you can also always create new tokens in the same way as described above.\nIf you run into difficulties with the above, please post about it in the comments section at the bottom of this page. If you want to dig in deeper yourself, you can take a look at the troubleshooting section in “Happy Git and GitHub for the useR”. But even if you manage to solve some problem yourself, please let us know about it in the comments.\nCreate repository\nTo create your practice repository, please follow the following link:\nhttps://classroom.github.com/a/z51vdBgM\nOnce you are logged into GitHub, this should bring you to a screen asking you to accept an assignment.\n\n\n\n\nPlease click on “Accept the assignment”. This will first tell you that your repository is being prepared and that you should refresh the page in your browser.\n\n\n\n\nWhen you hit the refresh button on your browser after just a short moment, you should see a page with a URL for your new repository on GitHub.\n\n\n\n\nPlease follow that URL to your repository’s home page. This page displays the README at the bottom. There you for example find a points bar where you accumulate points as you complete the exercises in the worksheet. We are now interested in the big green “Code” button which, when clicked, will give a popup with the URL for cloning your repository.\n\n\n\n\nClone repository\nNow we can use RStudio to clone this repository to your computer. For this you create a new RStudio project by clicking on the project drop-down menu at the top-right of the RStudio window and selecting “New Project…”.\n\n\n\n\nThat will open a dialog where you first choose “Version Control” and then choose “Git”.\n\n\n\n\n\n\n\n\n\n\nIn the resulting dialog window you paste in the repository URL that you copied from GitHub. You also specify the directory in your file area where you want the project directory to be saved. To do that click the “Browse…” button and find a location that is convenient for you. You may want to create a dedicated directory for this mizer course and then select that. But avoid creating a directory path that is too long. We have seen problems arise for people who used pathnames longer than 100 characters.\n\n\n\n\nThen click “Create Project”. RStudio now communicates with GitHub to download a clone of the repository and it also checks out all the files contained in the repository to the newly created directory. You can see them in the “Files” tab in RStudio.\n\n\n\n\nContinue in worksheet\nIn the Files tab you will in particular see a file called “worksheet-use-git-and-github.Rmd”. That is the worksheet for this tutorial. Please click on the file name in the Files tab of RStudio to open this worksheet in the RStudio editor. The editor has a “Source” mode and a “Visual” mode. Try out both and see which one you prefer.\n\n\n\n\n\n\n\n\n\n\nNow just follow the instructions in that worksheet. This will guide you through the process of performing your first commits to your repository and pushes to GitHub.\nAs you work through the exercises, you will get some automatic feedback. You can also always ask for personal feedback from me. The details are described in the worksheet. But if you run into a problem that you think might be of interest to others as well, please post in the comments below."
  },
  {
    "objectID": "prepare/index.html",
    "href": "prepare/index.html",
    "title": "Prepare for the mizer course",
    "section": "",
    "text": "While the course only starts on Monday the 7th of November, if you like you can already start preparations:\n1) You can introduce yourself and your interests to your fellow participants.\n2) You can install the tools that we will use in the course.\n3) You can familiarise yourself with how we will be using Git and GitHub in this course for collaboration and feedback on your coursework.\n4) The course assumes that you are familiar with the basics of R programming. There are plenty of free resources to learn R. Some possible starting points are given at RStudio Education. If you find particularly nice tutorials or resources, why not post about them in the comments below?\nThat will allow for a flying start to the course."
  },
  {
    "objectID": "prepare/index.html#watch-video-introducing-mizer",
    "href": "prepare/index.html#watch-video-introducing-mizer",
    "title": "Prepare for the mizer course",
    "section": "Watch video introducing mizer”",
    "text": "Watch video introducing mizer”\nIn this video Ken Andersen introduces many of the concepts that we will be discussing in this course. However don’t feel that you have to take it all in at once. We will come back to these topics (and others) during the course where we hope to make them concrete by working hands-on with mizer."
  },
  {
    "objectID": "prepare/install-tools.html",
    "href": "prepare/install-tools.html",
    "title": "Install tools",
    "section": "",
    "text": "For this course you will need access to a machine with an installation of R, Git, RStudio and some important R packages, including, of course, mizer itself and mizerExperimental. Below we give the necessary information to allow you to install these tools.\nIf you run into difficulties, please make a post in the Comments section below. It is quite likely that someone else on the course has encountered similar difficulties and that someone has ideas on how to solve them.\nIf you already have some of these tools installed, please make sure that the version you have is recent."
  },
  {
    "objectID": "prepare/install-tools.html#r",
    "href": "prepare/install-tools.html#r",
    "title": "Install tools",
    "section": "R",
    "text": "R\nMizer is compatible with R versions 3.1 and later. However in this course we will assume that you have a version newer than 4.0. So if you are still using 3.x, now is the time to upgrade. You can install or upgrade R on your computer by following the instructions at https://cran.r-project.org/ for your particular platform. In fact, upgrading follows the same procedure as installing from scratch.\nAlternatively, if you can not or do not want to install R on your computer, you can also work with R and RStudio in your internet browser by creating yourself a free account at https://rstudio.cloud. There you can then install mizer as described above. Running mizer in the RStudio Cloud may be slightly slower than running it locally on your machine, but the speed is usually quite acceptable."
  },
  {
    "objectID": "prepare/install-tools.html#rstudio",
    "href": "prepare/install-tools.html#rstudio",
    "title": "Install tools",
    "section": "RStudio",
    "text": "RStudio\nThis course assumes that you will be using RStudio to work with R. There is really no reason not to use RStudio and it makes a lot of things much easier.\nRStudio develops rapidly and adds useful features all the time and so it is best if you install the latest version. This course was written with version 2022.07.2. If you already have RStudio installed but it is an older version, the way to upgrade is to just install the newest version. The old version will automatically be replaced by the new.\nIf you are new to RStudio, the video on the RStudio IDE homepage is well worth watching."
  },
  {
    "objectID": "prepare/install-tools.html#r-packages",
    "href": "prepare/install-tools.html#r-packages",
    "title": "Install tools",
    "section": "R Packages",
    "text": "R Packages\nR packages extend the functionality of R. mizer itself is such an R package. There is a central repository for R packages called CRAN which hosts all of the packages needed for this course, except for the mizerExperimental package. To install them on your computer just start RStudio and then in the console issue the command\n\ninstall.packages(c(\"mizer\", \"tidyverse\", \"plotly\", \"remotes\", \"usethis\",\n                   \"rmarkdown\", \"rstudioapi\"))\n\nThe mizerExperimental package is for code that is still experimental and thus changes frequently. Therefore it is hosted in a GitHub repository. You install it with\n\nremotes::install_github(\"sizespectrum/mizerExperimental\")"
  },
  {
    "objectID": "prepare/install-tools.html#git",
    "href": "prepare/install-tools.html#git",
    "title": "Install tools",
    "section": "Git",
    "text": "Git\nGit is a distributed version control system that we will use in this course. We will discuss that more on the page Use Git and GitHub.\nGit may already be installed on your system. If you are in RStudio, then you can issue the following command in the “Terminal” tab:\ngit --version\nIf that comes back with a version number, then git is already installed. The current Git version is 2.25.1. If you have an older version then keep this in mind and if you should at some point notice that Git is not behaving the same for you as for others, then you might want to install the latest version. Or simply install the latest version now to be on the safe side.\nTo install Git follow the links at https://git-scm.com/downloads for your operating system. You do not need a GUI client for Git because you will be using Git from within RStudio. After you have installed Git, you may want to restart RStudio.\nFinally, you should tell Git about yourself by running the following command in the RStudio Console, where of course you change the name and email address to your own:\n\nusethis::use_git_config(user.name = \"Jane Doe\", \n                        user.email = \"jane@example.org\")"
  },
  {
    "objectID": "prepare/install-tools.html#issues",
    "href": "prepare/install-tools.html#issues",
    "title": "Install tools",
    "section": "Issues",
    "text": "Issues\nAs with all computer-related things, unexpected problems are likely to crop up. Be sure to post about them below. Alternatively you can also report issues by clicking on the “Report an issue” link that you find at the bottom of the right side-bar. That will create an entry in the GitHub issue tracker.\nIf you have a correction to this page or want to suggest an edit, use the “Edit this page” link. Don’t worry: we will need to approve your edits before they go live, so you can feel free to edit as much as you like.\nThis course should be a collaborative experience. You will find the “Edit this page” and “Report an issue” links on every tutorial page and you will find a comments section on every page of the course website. Never hesitate to use them."
  },
  {
    "objectID": "prepare/introduce-yourself.html",
    "href": "prepare/introduce-yourself.html",
    "title": "Introduce yourself",
    "section": "",
    "text": "When you post a comment you will be asked to log in to GitHub. You will probably already have an account on GitHub. If not, please create one for yourself. You will need it to participate in this course. The page Use Git and GitHub explains how we will use GitHub in this course.\nYou can use Markdown syntax in your post. For example to see how to include a link to your homepage, see the section on Links.\nThe comments you post on this course website will also appear in the Comments section of the GitHub discussions for the course repository. Even after posting a comment you can go and edit the post on GitHub and it will be updated on this website as well.\nThe comments are threaded discussions. Please post your introduction as a new comment rather than as a reply to someone else’s introduction. You can use the replies if you want to respond to someone’s introduction for follow-ups.\nYou will find a comment section at the bottom of each course webpage. Please use it a lot to share your questions, thoughts and experiences as you go through the course."
  }
]